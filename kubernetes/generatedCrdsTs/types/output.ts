// *** WARNING: this file was generated by crd2pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import { input as inputs, output as outputs } from "../types";

import * as utilities from "../utilities";

import {ObjectMeta} from "../meta/v1";

export namespace acme {
    export namespace v1 {
        export interface ChallengeSpec {
            /**
             * The URL to the ACME Authorization resource that this challenge is a part of.
             */
            authorizationURL: string;
            /**
             * dnsName is the identifier that this challenge is for, e.g. example.com. If the requested DNSName is a 'wildcard', this field MUST be set to the non-wildcard domain, e.g. for `*.example.com`, it must be `example.com`.
             */
            dnsName: string;
            /**
             * References a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
             */
            issuerRef: outputs.acme.v1.ChallengeSpecIssuerref;
            /**
             * The ACME challenge key for this challenge For HTTP01 challenges, this is the value that must be responded with to complete the HTTP01 challenge in the format: `<private key JWK thumbprint>.<key from acme server for challenge>`. For DNS01 challenges, this is the base64 encoded SHA256 sum of the `<private key JWK thumbprint>.<key from acme server for challenge>` text that must be set as the TXT record content.
             */
            key: string;
            /**
             * Contains the domain solving configuration that should be used to solve this challenge resource.
             */
            solver: outputs.acme.v1.ChallengeSpecSolver;
            /**
             * The ACME challenge token for this challenge. This is the raw value returned from the ACME server.
             */
            token: string;
            /**
             * The type of ACME challenge this resource represents. One of "HTTP-01" or "DNS-01".
             */
            type: string;
            /**
             * The URL of the ACME Challenge resource for this challenge. This can be used to lookup details about the status of this challenge.
             */
            url: string;
            /**
             * wildcard will be true if this challenge is for a wildcard identifier, for example '*.example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * References a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
         */
        export interface ChallengeSpecIssuerref {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Contains the domain solving configuration that should be used to solve this challenge resource.
         */
        export interface ChallengeSpecSolver {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.acme.v1.ChallengeSpecSolverDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.acme.v1.ChallengeSpecSolverHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.acme.v1.ChallengeSpecSolverSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ChallengeSpecSolverDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.acme.v1.ChallengeSpecSolverDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.acme.v1.ChallengeSpecSolverDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.acme.v1.ChallengeSpecSolverDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.acme.v1.ChallengeSpecSolverDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.acme.v1.ChallengeSpecSolverDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.acme.v1.ChallengeSpecSolverDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.acme.v1.ChallengeSpecSolverDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.acme.v1.ChallengeSpecSolverDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.acme.v1.ChallengeSpecSolverDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AcmednsAccountsecretref;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AcmednsAccountsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AkamaiAccesstokensecretref;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AkamaiClientsecretsecretref;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AkamaiClienttokensecretref;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiAccesstokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClienttokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01AzurednsClientsecretsecretref;
            /**
             * name of the Azure environment (default AzurePublicCloud)
             */
            environment?: string;
            /**
             * name of the DNS zone that should be used
             */
            hostedZoneName?: string;
            /**
             * managed identity configuration, can not be used at the same time as clientID, clientSecretSecretRef or tenantID
             */
            managedIdentity?: outputs.acme.v1.ChallengeSpecSolverDns01AzurednsManagedidentity;
            /**
             * resource group the DNS zone is located in
             */
            resourceGroupName: string;
            /**
             * ID of the Azure subscription
             */
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ChallengeSpecSolverDns01AzurednsClientsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * managed identity configuration, can not be used at the same time as clientID, clientSecretSecretRef or tenantID
         */
        export interface ChallengeSpecSolverDns01AzurednsManagedidentity {
            /**
             * client ID of the managed identity, can not be used at the same time as resourceID
             */
            clientID?: string;
            /**
             * resource ID of the managed identity, can not be used at the same time as clientID
             */
            resourceID?: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01ClouddnsServiceaccountsecretref;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01ClouddnsServiceaccountsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01CloudflareApikeysecretref;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01CloudflareApitokensecretref;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ChallengeSpecSolverDns01CloudflareApikeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ChallengeSpecSolverDns01CloudflareApitokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01DigitaloceanTokensecretref;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01DigitaloceanTokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1])Â ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01Rfc2136Tsigsecretsecretref;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ChallengeSpecSolverDns01Rfc2136Tsigsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. Cannot be set when SecretAccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * The SecretAccessKey is used for authentication. If set, pull the AWS access key ID from a key within a Kubernetes Secret. Cannot be set when AccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyIDSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01Route53Accesskeyidsecretref;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01Route53Secretaccesskeysecretref;
        }

        /**
         * The SecretAccessKey is used for authentication. If set, pull the AWS access key ID from a key within a Kubernetes Secret. Cannot be set when AccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ChallengeSpecSolverDns01Route53Accesskeyidsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * The SecretAccessKey is used for authentication. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ChallengeSpecSolverDns01Route53Secretaccesskeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ChallengeSpecSolverHttp01 {
            /**
             * The Gateway API is a "sig-network community API that models service networking in Kubernetes (https"://gateway-api.sigs.k8s.io/). The Gateway solver will create HTTPRoutes with the specified labels in the same namespace as the challenge. This solver is experimental, and fields / behaviour may change in the future.
             */
            gatewayHTTPRoute?: outputs.acme.v1.ChallengeSpecSolverHttp01Gatewayhttproute;
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.acme.v1.ChallengeSpecSolverHttp01Ingress;
        }

        /**
         * The Gateway API is a "sig-network community API that models service networking in Kubernetes (https"://gateway-api.sigs.k8s.io/). The Gateway solver will create HTTPRoutes with the specified labels in the same namespace as the challenge. This solver is experimental, and fields / behaviour may change in the future.
         */
        export interface ChallengeSpecSolverHttp01Gatewayhttproute {
            /**
             * Custom labels that will be applied to HTTPRoutes created by cert-manager while solving HTTP-01 challenges.
             */
            labels?: {[key: string]: string};
            /**
             * When solving an HTTP-01 challenge, "cert-manager creates an HTTPRoute. cert-manager needs to know which parentRefs should be used when creating the HTTPRoute. Usually, the parentRef references a Gateway. See: https"://gateway-api.sigs.k8s.io/v1alpha2/api-types/httproute/#attaching-to-gateways
             */
            parentRefs?: outputs.acme.v1.ChallengeSpecSolverHttp01GatewayhttprouteParentrefs[];
            /**
             * Optional service type for Kubernetes solver service. Supported values are NodePort or ClusterIP. If unset, defaults to NodePort.
             */
            serviceType?: string;
        }

        /**
         * ParentRef identifies an API object (usually a Gateway) that can be considered a parent of this resource (usually a route). The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources, such as HTTPRoute. 
         *  The API object must be valid in the cluster; the Group and Kind must be registered in the cluster for this reference to be valid. 
         *  References to objects with invalid Group and Kind are not valid, and must be rejected by the implementation, with appropriate Conditions set on the containing object.
         */
        export interface ChallengeSpecSolverHttp01GatewayhttprouteParentrefs {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * challengeSpecSolverHttp01GatewayhttprouteParentrefsProvideDefaults sets the appropriate defaults for ChallengeSpecSolverHttp01GatewayhttprouteParentrefs
         */
        export function challengeSpecSolverHttp01GatewayhttprouteParentrefsProvideDefaults(val: ChallengeSpecSolverHttp01GatewayhttprouteParentrefs): ChallengeSpecSolverHttp01GatewayhttprouteParentrefs {
            return {
                ...val,
                group: (val.group) ?? "gateway.networking.k8s.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ChallengeSpecSolverHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges.
             */
            ingressTemplate?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressIngresstemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges.
             */
            podTemplate?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplate;
            /**
             * Optional service type for Kubernetes solver service. Supported values are NodePort or ClusterIP. If unset, defaults to NodePort.
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges.
         */
        export interface ChallengeSpecSolverHttp01IngressIngresstemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressIngresstemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressIngresstemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ChallengeSpecSolverHttp01IngressPodtemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ChallengeSpecSolverSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        export interface ChallengeStatus {
            /**
             * presented will be set to true if the challenge values for this challenge are currently 'presented'. This *does not* imply the self check is passing. Only that the values have been 'submitted' for the appropriate challenge mechanism (i.e. the DNS01 TXT record has been presented, or the HTTP01 configuration has been configured).
             */
            presented?: boolean;
            /**
             * Used to denote whether this challenge should be processed or not. This field will only be set to true by the 'scheduling' component. It will only be set to false by the 'challenges' controller, after the challenge has reached a final state or timed out. If this field is set to false, the challenge controller will not take any more action.
             */
            processing?: boolean;
            /**
             * Contains human readable information on why the Challenge is in the current state.
             */
            reason?: string;
            /**
             * Contains the current 'state' of the challenge. If not set, the state of the challenge is unknown.
             */
            state?: string;
        }

        export interface OrderSpec {
            /**
             * CommonName is the common name as specified on the DER encoded CSR. If specified, this value must also be present in `dnsNames` or `ipAddresses`. This field must match the corresponding field on the DER encoded CSR.
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS names that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            dnsNames?: string[];
            /**
             * Duration is the duration for the not after date for the requested certificate. this is set on order creation as pe the ACME spec.
             */
            duration?: string;
            /**
             * IPAddresses is a list of IP addresses that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            ipAddresses?: string[];
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
             */
            issuerRef: outputs.acme.v1.OrderSpecIssuerref;
            /**
             * Certificate signing request bytes in DER encoding. This will be used when finalizing the order. This field must be set on the order.
             */
            request: string;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
         */
        export interface OrderSpecIssuerref {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        export interface OrderStatus {
            /**
             * Authorizations contains data returned from the ACME server on what authorizations must be completed in order to validate the DNS names specified on the Order.
             */
            authorizations?: outputs.acme.v1.OrderStatusAuthorizations[];
            /**
             * Certificate is a copy of the PEM encoded certificate for this Order. This field will be populated after the order has been successfully finalized with the ACME server, and the order has transitioned to the 'valid' state.
             */
            certificate?: string;
            /**
             * FailureTime stores the time that this order failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
            /**
             * FinalizeURL of the Order. This is used to obtain certificates for this order once it has been completed.
             */
            finalizeURL?: string;
            /**
             * Reason optionally provides more information about a why the order is in the current state.
             */
            reason?: string;
            /**
             * State contains the current state of this Order resource. States 'success' and 'expired' are 'final'
             */
            state?: string;
            /**
             * URL of the Order. This will initially be empty when the resource is first created. The Order controller will populate this field when the Order is first processed. This field will be immutable after it is initially set.
             */
            url?: string;
        }

        /**
         * ACMEAuthorization contains data returned from the ACME server on an authorization that must be completed in order validate a DNS name on an ACME Order resource.
         */
        export interface OrderStatusAuthorizations {
            /**
             * Challenges specifies the challenge types offered by the ACME server. One of these challenge types will be selected when validating the DNS name and an appropriate Challenge resource will be created to perform the ACME challenge process.
             */
            challenges?: outputs.acme.v1.OrderStatusAuthorizationsChallenges[];
            /**
             * Identifier is the DNS name to be validated as part of this authorization
             */
            identifier?: string;
            /**
             * InitialState is the initial state of the ACME authorization when first fetched from the ACME server. If an Authorization is already 'valid', the Order controller will not create a Challenge resource for the authorization. This will occur when working with an ACME server that enables 'authz reuse' (such as Let's Encrypt's production endpoint). If not set and 'identifier' is set, the state is assumed to be pending and a Challenge will be created.
             */
            initialState?: string;
            /**
             * URL is the URL of the Authorization that must be completed
             */
            url: string;
            /**
             * Wildcard will be true if this authorization is for a wildcard DNS name. If this is true, the identifier will be the *non-wildcard* version of the DNS name. For example, if '*.example.com' is the DNS name being validated, this field will be 'true' and the 'identifier' field will be 'example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * Challenge specifies a challenge offered by the ACME server for an Order. An appropriate Challenge resource can be created to perform the ACME challenge process.
         */
        export interface OrderStatusAuthorizationsChallenges {
            /**
             * Token is the token that must be presented for this challenge. This is used to compute the 'key' that must also be presented.
             */
            token: string;
            /**
             * Type is the type of challenge being offered, e.g. 'http-01', 'dns-01', 'tls-sni-01', etc. This is the raw value retrieved from the ACME server. Only 'http-01' and 'dns-01' are supported by cert-manager, other values will be ignored.
             */
            type: string;
            /**
             * URL is the URL of this challenge. It can be used to retrieve additional metadata about the Challenge from the ACME server.
             */
            url: string;
        }
    }
}

export namespace argoproj {
    export namespace v1alpha1 {
        /**
         * AppProjectSpec is the specification of an AppProject
         */
        export interface AppProjectSpec {
            /**
             * ClusterResourceBlacklist contains list of blacklisted cluster level resources
             */
            clusterResourceBlacklist?: outputs.argoproj.v1alpha1.AppProjectSpecClusterresourceblacklist[];
            /**
             * ClusterResourceWhitelist contains list of whitelisted cluster level resources
             */
            clusterResourceWhitelist?: outputs.argoproj.v1alpha1.AppProjectSpecClusterresourcewhitelist[];
            /**
             * Description contains optional project description
             */
            description?: string;
            /**
             * Destinations contains list of destinations available for deployment
             */
            destinations?: outputs.argoproj.v1alpha1.AppProjectSpecDestinations[];
            /**
             * NamespaceResourceBlacklist contains list of blacklisted namespace level resources
             */
            namespaceResourceBlacklist?: outputs.argoproj.v1alpha1.AppProjectSpecNamespaceresourceblacklist[];
            /**
             * NamespaceResourceWhitelist contains list of whitelisted namespace level resources
             */
            namespaceResourceWhitelist?: outputs.argoproj.v1alpha1.AppProjectSpecNamespaceresourcewhitelist[];
            /**
             * OrphanedResources specifies if controller should monitor orphaned resources of apps in this project
             */
            orphanedResources?: outputs.argoproj.v1alpha1.AppProjectSpecOrphanedresources;
            /**
             * Roles are user defined RBAC roles associated with this project
             */
            roles?: outputs.argoproj.v1alpha1.AppProjectSpecRoles[];
            /**
             * SignatureKeys contains a list of PGP key IDs that commits in Git must be signed with in order to be allowed for sync
             */
            signatureKeys?: outputs.argoproj.v1alpha1.AppProjectSpecSignaturekeys[];
            /**
             * SourceRepos contains list of repository URLs which can be used for deployment
             */
            sourceRepos?: string[];
            /**
             * SyncWindows controls when syncs can be run for apps in this project
             */
            syncWindows?: outputs.argoproj.v1alpha1.AppProjectSpecSyncwindows[];
        }

        /**
         * GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
         */
        export interface AppProjectSpecClusterresourceblacklist {
            group: string;
            kind: string;
        }

        /**
         * GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
         */
        export interface AppProjectSpecClusterresourcewhitelist {
            group: string;
            kind: string;
        }

        /**
         * ApplicationDestination holds information about the application's destination
         */
        export interface AppProjectSpecDestinations {
            /**
             * Name is an alternate way of specifying the target cluster by its symbolic name
             */
            name?: string;
            /**
             * Namespace specifies the target namespace for the application's resources. The namespace will only be set for namespace-scoped resources that have not set a value for .metadata.namespace
             */
            namespace?: string;
            /**
             * Server specifies the URL of the target cluster and must be set to the Kubernetes control plane API
             */
            server?: string;
        }

        /**
         * GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
         */
        export interface AppProjectSpecNamespaceresourceblacklist {
            group: string;
            kind: string;
        }

        /**
         * GroupKind specifies a Group and a Kind, but does not force a version.  This is useful for identifying concepts during lookup stages without having partially valid types
         */
        export interface AppProjectSpecNamespaceresourcewhitelist {
            group: string;
            kind: string;
        }

        /**
         * OrphanedResources specifies if controller should monitor orphaned resources of apps in this project
         */
        export interface AppProjectSpecOrphanedresources {
            /**
             * Ignore contains a list of resources that are to be excluded from orphaned resources monitoring
             */
            ignore?: outputs.argoproj.v1alpha1.AppProjectSpecOrphanedresourcesIgnore[];
            /**
             * Warn indicates if warning condition should be created for apps which have orphaned resources
             */
            warn?: boolean;
        }

        /**
         * OrphanedResourceKey is a reference to a resource to be ignored from
         */
        export interface AppProjectSpecOrphanedresourcesIgnore {
            group?: string;
            kind?: string;
            name?: string;
        }

        /**
         * ProjectRole represents a role that has access to a project
         */
        export interface AppProjectSpecRoles {
            /**
             * Description is a description of the role
             */
            description?: string;
            /**
             * Groups are a list of OIDC group claims bound to this role
             */
            groups?: string[];
            /**
             * JWTTokens are a list of generated JWT tokens bound to this role
             */
            jwtTokens?: outputs.argoproj.v1alpha1.AppProjectSpecRolesJwttokens[];
            /**
             * Name is a name for this role
             */
            name: string;
            /**
             * Policies Stores a list of casbin formatted strings that define access policies for the role in the project
             */
            policies?: string[];
        }

        /**
         * JWTToken holds the issuedAt and expiresAt values of a token
         */
        export interface AppProjectSpecRolesJwttokens {
            exp?: number;
            iat: number;
            id?: string;
        }

        /**
         * SignatureKey is the specification of a key required to verify commit signatures with
         */
        export interface AppProjectSpecSignaturekeys {
            /**
             * The ID of the key in hexadecimal notation
             */
            keyID: string;
        }

        /**
         * SyncWindow contains the kind, time, duration and attributes that are used to assign the syncWindows to apps
         */
        export interface AppProjectSpecSyncwindows {
            /**
             * Applications contains a list of applications that the window will apply to
             */
            applications?: string[];
            /**
             * Clusters contains a list of clusters that the window will apply to
             */
            clusters?: string[];
            /**
             * Duration is the amount of time the sync window will be open
             */
            duration?: string;
            /**
             * Kind defines if the window allows or blocks syncs
             */
            kind?: string;
            /**
             * ManualSync enables manual syncs when they would otherwise be blocked
             */
            manualSync?: boolean;
            /**
             * Namespaces contains a list of namespaces that the window will apply to
             */
            namespaces?: string[];
            /**
             * Schedule is the time the window will begin, specified in cron format
             */
            schedule?: string;
            /**
             * TimeZone of the sync that will be applied to the schedule
             */
            timeZone?: string;
        }

        /**
         * AppProjectStatus contains status information for AppProject CRs
         */
        export interface AppProjectStatus {
            /**
             * JWTTokensByRole contains a list of JWT tokens issued for a given role
             */
            jwtTokensByRole?: {[key: string]: outputs.argoproj.v1alpha1.AppProjectStatusJwttokensbyrole};
        }

        /**
         * JWTTokens represents a list of JWT tokens
         */
        export interface AppProjectStatusJwttokensbyrole {
            items?: outputs.argoproj.v1alpha1.AppProjectStatusJwttokensbyroleItems[];
        }

        /**
         * JWTToken holds the issuedAt and expiresAt values of a token
         */
        export interface AppProjectStatusJwttokensbyroleItems {
            exp?: number;
            iat: number;
            id?: string;
        }

        /**
         * Operation contains information about a requested or running operation
         */
        export interface ApplicationOperation {
            /**
             * Info is a list of informational items for this operation
             */
            info?: outputs.argoproj.v1alpha1.ApplicationOperationInfo[];
            /**
             * InitiatedBy contains information about who initiated the operations
             */
            initiatedBy?: outputs.argoproj.v1alpha1.ApplicationOperationInitiatedby;
            /**
             * Retry controls the strategy to apply if a sync fails
             */
            retry?: outputs.argoproj.v1alpha1.ApplicationOperationRetry;
            /**
             * Sync contains parameters for the operation
             */
            sync?: outputs.argoproj.v1alpha1.ApplicationOperationSync;
        }

        export interface ApplicationOperationInfo {
            name: string;
            value: string;
        }

        /**
         * InitiatedBy contains information about who initiated the operations
         */
        export interface ApplicationOperationInitiatedby {
            /**
             * Automated is set to true if operation was initiated automatically by the application controller.
             */
            automated?: boolean;
            /**
             * Username contains the name of a user who started operation
             */
            username?: string;
        }

        /**
         * Retry controls the strategy to apply if a sync fails
         */
        export interface ApplicationOperationRetry {
            /**
             * Backoff controls how to backoff on subsequent retries of failed syncs
             */
            backoff?: outputs.argoproj.v1alpha1.ApplicationOperationRetryBackoff;
            /**
             * Limit is the maximum number of attempts for retrying a failed sync. If set to 0, no retries will be performed.
             */
            limit?: number;
        }

        /**
         * Backoff controls how to backoff on subsequent retries of failed syncs
         */
        export interface ApplicationOperationRetryBackoff {
            /**
             * Duration is the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
             */
            duration?: string;
            /**
             * Factor is a factor to multiply the base duration after each failed retry
             */
            factor?: number;
            /**
             * MaxDuration is the maximum amount of time allowed for the backoff strategy
             */
            maxDuration?: string;
        }

        /**
         * Sync contains parameters for the operation
         */
        export interface ApplicationOperationSync {
            /**
             * DryRun specifies to perform a `kubectl apply --dry-run` without actually performing the sync
             */
            dryRun?: boolean;
            /**
             * Manifests is an optional field that overrides sync source with a local directory for development
             */
            manifests?: string[];
            /**
             * Prune specifies to delete resources from the cluster that are no longer tracked in git
             */
            prune?: boolean;
            /**
             * Resources describes which resources shall be part of the sync
             */
            resources?: outputs.argoproj.v1alpha1.ApplicationOperationSyncResources[];
            /**
             * Revision is the revision (Git) or chart version (Helm) which to sync the application to If omitted, will use the revision specified in app spec.
             */
            revision?: string;
            /**
             * Source overrides the source definition set in the application. This is typically set in a Rollback operation and is nil during a Sync operation
             */
            source?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSource;
            /**
             * SyncOptions provide per-sync sync-options, e.g. Validate=false
             */
            syncOptions?: string[];
            /**
             * SyncStrategy describes how to perform the sync
             */
            syncStrategy?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSyncstrategy;
        }

        /**
         * SyncOperationResource contains resources to sync.
         */
        export interface ApplicationOperationSyncResources {
            group?: string;
            kind: string;
            name: string;
            namespace?: string;
        }

        /**
         * Source overrides the source definition set in the application. This is typically set in a Rollback operation and is nil during a Sync operation
         */
        export interface ApplicationOperationSyncSource {
            /**
             * Chart is a Helm chart name, and must be specified for applications sourced from a Helm repo.
             */
            chart?: string;
            /**
             * Directory holds path/directory specific options
             */
            directory?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceDirectory;
            /**
             * Helm holds helm specific options
             */
            helm?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceHelm;
            /**
             * Ksonnet holds ksonnet specific options
             */
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceKsonnet;
            /**
             * Kustomize holds kustomize specific options
             */
            kustomize?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceKustomize;
            /**
             * Path is a directory path within the Git repository, and is only valid for applications sourced from Git.
             */
            path?: string;
            /**
             * ConfigManagementPlugin holds config management plugin specific options
             */
            plugin?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourcePlugin;
            /**
             * RepoURL is the URL to the repository (Git or Helm) that contains the application manifests
             */
            repoURL: string;
            /**
             * TargetRevision defines the revision of the source to sync the application to. In case of Git, this can be commit, tag, or branch. If omitted, will equal to HEAD. In case of Helm, this is a semver tag for the Chart's version.
             */
            targetRevision?: string;
        }

        /**
         * Directory holds path/directory specific options
         */
        export interface ApplicationOperationSyncSourceDirectory {
            /**
             * Exclude contains a glob pattern to match paths against that should be explicitly excluded from being used during manifest generation
             */
            exclude?: string;
            /**
             * Include contains a glob pattern to match paths against that should be explicitly included during manifest generation
             */
            include?: string;
            /**
             * Jsonnet holds options specific to Jsonnet
             */
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceDirectoryJsonnet;
            /**
             * Recurse specifies whether to scan a directory recursively for manifests
             */
            recurse?: boolean;
        }

        /**
         * Jsonnet holds options specific to Jsonnet
         */
        export interface ApplicationOperationSyncSourceDirectoryJsonnet {
            /**
             * ExtVars is a list of Jsonnet External Variables
             */
            extVars?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceDirectoryJsonnetExtvars[];
            /**
             * Additional library search dirs
             */
            libs?: string[];
            /**
             * TLAS is a list of Jsonnet Top-level Arguments
             */
            tlas?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceDirectoryJsonnetTlas[];
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationOperationSyncSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationOperationSyncSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * Helm holds helm specific options
         */
        export interface ApplicationOperationSyncSourceHelm {
            /**
             * FileParameters are file parameters to the helm template
             */
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceHelmFileparameters[];
            /**
             * IgnoreMissingValueFiles prevents helm template from failing when valueFiles do not exist locally by not appending them to helm template --values
             */
            ignoreMissingValueFiles?: boolean;
            /**
             * Parameters is a list of Helm parameters which are passed to the helm template command upon manifest generation
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceHelmParameters[];
            /**
             * PassCredentials pass credentials to all domains (Helm's --pass-credentials)
             */
            passCredentials?: boolean;
            /**
             * ReleaseName is the Helm release name to use. If omitted it will use the application name
             */
            releaseName?: string;
            /**
             * SkipCrds skips custom resource definition installation step (Helm's --skip-crds)
             */
            skipCrds?: boolean;
            /**
             * ValuesFiles is a list of Helm value files to use when generating a template
             */
            valueFiles?: string[];
            /**
             * Values specifies Helm values to be passed to helm template, typically defined as a block
             */
            values?: string;
            /**
             * Version is the Helm version to use for templating (either "2" or "3")
             */
            version?: string;
        }

        /**
         * HelmFileParameter is a file parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationOperationSyncSourceHelmFileparameters {
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Path is the path to the file containing the values for the Helm parameter
             */
            path?: string;
        }

        /**
         * HelmParameter is a parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationOperationSyncSourceHelmParameters {
            /**
             * ForceString determines whether to tell Helm to interpret booleans and numbers as strings
             */
            forceString?: boolean;
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Value is the value for the Helm parameter
             */
            value?: string;
        }

        /**
         * Ksonnet holds ksonnet specific options
         */
        export interface ApplicationOperationSyncSourceKsonnet {
            /**
             * Environment is a ksonnet application environment name
             */
            environment?: string;
            /**
             * Parameters are a list of ksonnet component parameter override values
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourceKsonnetParameters[];
        }

        /**
         * KsonnetParameter is a ksonnet component parameter
         */
        export interface ApplicationOperationSyncSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        /**
         * Kustomize holds kustomize specific options
         */
        export interface ApplicationOperationSyncSourceKustomize {
            /**
             * CommonAnnotations is a list of additional annotations to add to rendered manifests
             */
            commonAnnotations?: {[key: string]: string};
            /**
             * CommonLabels is a list of additional labels to add to rendered manifests
             */
            commonLabels?: {[key: string]: string};
            /**
             * ForceCommonAnnotations specifies whether to force applying common annotations to resources for Kustomize apps
             */
            forceCommonAnnotations?: boolean;
            /**
             * ForceCommonLabels specifies whether to force applying common labels to resources for Kustomize apps
             */
            forceCommonLabels?: boolean;
            /**
             * Images is a list of Kustomize image override specifications
             */
            images?: string[];
            /**
             * NamePrefix is a prefix appended to resources for Kustomize apps
             */
            namePrefix?: string;
            /**
             * NameSuffix is a suffix appended to resources for Kustomize apps
             */
            nameSuffix?: string;
            /**
             * Version controls which version of Kustomize to use for rendering manifests
             */
            version?: string;
        }

        /**
         * ConfigManagementPlugin holds config management plugin specific options
         */
        export interface ApplicationOperationSyncSourcePlugin {
            /**
             * Env is a list of environment variable entries
             */
            env?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSourcePluginEnv[];
            name?: string;
        }

        /**
         * EnvEntry represents an entry in the application's environment
         */
        export interface ApplicationOperationSyncSourcePluginEnv {
            /**
             * Name is the name of the variable, usually expressed in uppercase
             */
            name: string;
            /**
             * Value is the value of the variable
             */
            value: string;
        }

        /**
         * SyncStrategy describes how to perform the sync
         */
        export interface ApplicationOperationSyncSyncstrategy {
            /**
             * Apply will perform a `kubectl apply` to perform the sync.
             */
            apply?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSyncstrategyApply;
            /**
             * Hook will submit any referenced resources to perform the sync. This is the default strategy
             */
            hook?: outputs.argoproj.v1alpha1.ApplicationOperationSyncSyncstrategyHook;
        }

        /**
         * Apply will perform a `kubectl apply` to perform the sync.
         */
        export interface ApplicationOperationSyncSyncstrategyApply {
            /**
             * Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
             */
            force?: boolean;
        }

        /**
         * Hook will submit any referenced resources to perform the sync. This is the default strategy
         */
        export interface ApplicationOperationSyncSyncstrategyHook {
            /**
             * Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
             */
            force?: boolean;
        }

        export interface ApplicationSetSpec {
            generators: outputs.argoproj.v1alpha1.ApplicationSetSpecGenerators[];
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecSyncpolicy;
            template: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplate;
        }

        export interface ApplicationSetSpecGenerators {
            clusterDecisionResource?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresource;
            clusters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusters;
            git?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGit;
            list?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsList;
            matrix?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrix;
            merge?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMerge;
            pullRequest?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequest;
            scmProvider?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmprovider;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresource {
            configMapRef: string;
            labelSelector?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceLabelselector;
            name?: string;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplate;
            values?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceLabelselector {
            matchExpressions?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsClusters {
            selector?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersSelector;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplate;
            values?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsClustersSelector {
            matchExpressions?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsClustersSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsClustersTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsGit {
            directories?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitDirectories[];
            files?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitFiles[];
            repoURL: string;
            requeueAfterSeconds?: number;
            revision: string;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplate;
        }

        export interface ApplicationSetSpecGeneratorsGitDirectories {
            exclude?: boolean;
            path: string;
        }

        export interface ApplicationSetSpecGeneratorsGitFiles {
            path: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsGitTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsList {
            elements: {[key: string]: any}[];
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplate;
        }

        export interface ApplicationSetSpecGeneratorsListTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsListTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrix {
            generators: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGenerators[];
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGenerators {
            clusterDecisionResource?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresource;
            clusters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusters;
            git?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGit;
            list?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsList;
            matrix?: {[key: string]: any};
            merge?: {[key: string]: any};
            pullRequest?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequest;
            scmProvider?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmprovider;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresource {
            configMapRef: string;
            labelSelector?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceLabelselector;
            name?: string;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplate;
            values?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceLabelselector {
            matchExpressions?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClusters {
            selector?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersSelector;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplate;
            values?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersSelector {
            matchExpressions?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsClustersTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGit {
            directories?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitDirectories[];
            files?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitFiles[];
            repoURL: string;
            requeueAfterSeconds?: number;
            revision: string;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitDirectories {
            exclude?: boolean;
            path: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitFiles {
            path: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsGitTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsList {
            elements: {[key: string]: any}[];
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsListTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequest {
            github?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestGithub;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestGithub {
            api?: string;
            labels?: string[];
            owner: string;
            repo: string;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestGithubTokenref;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestGithubTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsPullrequestTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmprovider {
            cloneProtocol?: string;
            filters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderFilters[];
            github?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGithub;
            gitlab?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGitlab;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderFilters {
            branchMatch?: string;
            labelMatch?: string;
            pathsExist?: string[];
            repositoryMatch?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGithub {
            allBranches?: boolean;
            api?: string;
            organization: string;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGithubTokenref;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGithubTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGitlab {
            allBranches?: boolean;
            api?: string;
            group: string;
            includeSubgroups?: boolean;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGitlabTokenref;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderGitlabTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixGeneratorsScmproviderTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMatrixTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMerge {
            generators: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGenerators[];
            mergeKeys: string[];
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMergeGenerators {
            clusterDecisionResource?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresource;
            clusters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusters;
            git?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGit;
            list?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsList;
            matrix?: {[key: string]: any};
            merge?: {[key: string]: any};
            pullRequest?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequest;
            scmProvider?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmprovider;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresource {
            configMapRef: string;
            labelSelector?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceLabelselector;
            name?: string;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplate;
            values?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceLabelselector {
            matchExpressions?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusterdecisionresourceTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClusters {
            selector?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersSelector;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplate;
            values?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersSelector {
            matchExpressions?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsClustersTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGit {
            directories?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitDirectories[];
            files?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitFiles[];
            repoURL: string;
            requeueAfterSeconds?: number;
            revision: string;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitDirectories {
            exclude?: boolean;
            path: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitFiles {
            path: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsGitTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsList {
            elements: {[key: string]: any}[];
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsListTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequest {
            github?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestGithub;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestGithub {
            api?: string;
            labels?: string[];
            owner: string;
            repo: string;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestGithubTokenref;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestGithubTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsPullrequestTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmprovider {
            cloneProtocol?: string;
            filters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderFilters[];
            github?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGithub;
            gitlab?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGitlab;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplate;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderFilters {
            branchMatch?: string;
            labelMatch?: string;
            pathsExist?: string[];
            repositoryMatch?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGithub {
            allBranches?: boolean;
            api?: string;
            organization: string;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGithubTokenref;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGithubTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGitlab {
            allBranches?: boolean;
            api?: string;
            group: string;
            includeSubgroups?: boolean;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGitlabTokenref;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderGitlabTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeGeneratorsScmproviderTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsMergeTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequest {
            github?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestGithub;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplate;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestGithub {
            api?: string;
            labels?: string[];
            owner: string;
            repo: string;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestGithubTokenref;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestGithubTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsPullrequestTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmprovider {
            cloneProtocol?: string;
            filters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderFilters[];
            github?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderGithub;
            gitlab?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderGitlab;
            requeueAfterSeconds?: number;
            template?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplate;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderFilters {
            branchMatch?: string;
            labelMatch?: string;
            pathsExist?: string[];
            repositoryMatch?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderGithub {
            allBranches?: boolean;
            api?: string;
            organization: string;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderGithubTokenref;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderGithubTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderGitlab {
            allBranches?: boolean;
            api?: string;
            group: string;
            includeSubgroups?: boolean;
            tokenRef?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderGitlabTokenref;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderGitlabTokenref {
            key: string;
            secretName: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpec;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecGeneratorsScmproviderTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetSpecSyncpolicy {
            preserveResourcesOnDeletion?: boolean;
        }

        export interface ApplicationSetSpecTemplate {
            metadata: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateMetadata;
            spec: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpec;
        }

        export interface ApplicationSetSpecTemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecTemplateSpec {
            destination: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecDestination;
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecIgnoredifferences[];
            info?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecInfo[];
            project: string;
            revisionHistoryLimit?: number;
            source: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSource;
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSyncpolicy;
        }

        export interface ApplicationSetSpecTemplateSpecDestination {
            name?: string;
            namespace?: string;
            server?: string;
        }

        export interface ApplicationSetSpecTemplateSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSetSpecTemplateSpecInfo {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecTemplateSpecSource {
            chart?: string;
            directory?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceDirectory;
            helm?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceHelm;
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceKsonnet;
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceKustomize;
            path?: string;
            plugin?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourcePlugin;
            repoURL: string;
            targetRevision?: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceDirectory {
            exclude?: string;
            include?: string;
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceDirectoryJsonnet;
            recurse?: boolean;
        }

        export interface ApplicationSetSpecTemplateSpecSourceDirectoryJsonnet {
            extVars?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceDirectoryJsonnetExtvars[];
            libs?: string[];
            tlas?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceDirectoryJsonnetTlas[];
        }

        export interface ApplicationSetSpecTemplateSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceHelm {
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceHelmFileparameters[];
            ignoreMissingValueFiles?: boolean;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceHelmParameters[];
            passCredentials?: boolean;
            releaseName?: string;
            skipCrds?: boolean;
            valueFiles?: string[];
            values?: string;
            version?: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceHelmFileparameters {
            name?: string;
            path?: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceHelmParameters {
            forceString?: boolean;
            name?: string;
            value?: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceKsonnet {
            environment?: string;
            parameters?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourceKsonnetParameters[];
        }

        export interface ApplicationSetSpecTemplateSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourceKustomize {
            commonAnnotations?: {[key: string]: string};
            commonLabels?: {[key: string]: string};
            forceCommonAnnotations?: boolean;
            forceCommonLabels?: boolean;
            images?: string[];
            namePrefix?: string;
            nameSuffix?: string;
            version?: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourcePlugin {
            env?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSourcePluginEnv[];
            name?: string;
        }

        export interface ApplicationSetSpecTemplateSpecSourcePluginEnv {
            name: string;
            value: string;
        }

        export interface ApplicationSetSpecTemplateSpecSyncpolicy {
            automated?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSyncpolicyAutomated;
            retry?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSyncpolicyRetry;
            syncOptions?: string[];
        }

        export interface ApplicationSetSpecTemplateSpecSyncpolicyAutomated {
            allowEmpty?: boolean;
            prune?: boolean;
            selfHeal?: boolean;
        }

        export interface ApplicationSetSpecTemplateSpecSyncpolicyRetry {
            backoff?: outputs.argoproj.v1alpha1.ApplicationSetSpecTemplateSpecSyncpolicyRetryBackoff;
            limit?: number;
        }

        export interface ApplicationSetSpecTemplateSpecSyncpolicyRetryBackoff {
            duration?: string;
            factor?: number;
            maxDuration?: string;
        }

        export interface ApplicationSetStatus {
            conditions?: outputs.argoproj.v1alpha1.ApplicationSetStatusConditions[];
        }

        export interface ApplicationSetStatusConditions {
            lastTransitionTime?: string;
            message: string;
            reason: string;
            status: string;
            type: string;
        }

        /**
         * ApplicationSpec represents desired application state. Contains link to repository with application definition and additional parameters link definition revision.
         */
        export interface ApplicationSpec {
            /**
             * Destination is a reference to the target Kubernetes server and namespace
             */
            destination: outputs.argoproj.v1alpha1.ApplicationSpecDestination;
            /**
             * IgnoreDifferences is a list of resources and their fields which should be ignored during comparison
             */
            ignoreDifferences?: outputs.argoproj.v1alpha1.ApplicationSpecIgnoredifferences[];
            /**
             * Info contains a list of information (URLs, email addresses, and plain text) that relates to the application
             */
            info?: outputs.argoproj.v1alpha1.ApplicationSpecInfo[];
            /**
             * Project is a reference to the project this application belongs to. The empty string means that application belongs to the 'default' project.
             */
            project: string;
            /**
             * RevisionHistoryLimit limits the number of items kept in the application's revision history, which is used for informational purposes as well as for rollbacks to previous versions. This should only be changed in exceptional circumstances. Setting to zero will store no history. This will reduce storage used. Increasing will increase the space used to store the history, so we do not recommend increasing it. Default is 10.
             */
            revisionHistoryLimit?: number;
            /**
             * Source is a reference to the location of the application's manifests or chart
             */
            source: outputs.argoproj.v1alpha1.ApplicationSpecSource;
            /**
             * SyncPolicy controls when and how a sync will be performed
             */
            syncPolicy?: outputs.argoproj.v1alpha1.ApplicationSpecSyncpolicy;
        }

        /**
         * Destination is a reference to the target Kubernetes server and namespace
         */
        export interface ApplicationSpecDestination {
            /**
             * Name is an alternate way of specifying the target cluster by its symbolic name
             */
            name?: string;
            /**
             * Namespace specifies the target namespace for the application's resources. The namespace will only be set for namespace-scoped resources that have not set a value for .metadata.namespace
             */
            namespace?: string;
            /**
             * Server specifies the URL of the target cluster and must be set to the Kubernetes control plane API
             */
            server?: string;
        }

        /**
         * ResourceIgnoreDifferences contains resource filter and list of json paths which should be ignored during comparison with live state.
         */
        export interface ApplicationSpecIgnoredifferences {
            group?: string;
            jqPathExpressions?: string[];
            jsonPointers?: string[];
            kind: string;
            /**
             * ManagedFieldsManagers is a list of trusted managers. Fields mutated by those managers will take precedence over the desired state defined in the SCM and won't be displayed in diffs
             */
            managedFieldsManagers?: string[];
            name?: string;
            namespace?: string;
        }

        export interface ApplicationSpecInfo {
            name: string;
            value: string;
        }

        /**
         * Source is a reference to the location of the application's manifests or chart
         */
        export interface ApplicationSpecSource {
            /**
             * Chart is a Helm chart name, and must be specified for applications sourced from a Helm repo.
             */
            chart?: string;
            /**
             * Directory holds path/directory specific options
             */
            directory?: outputs.argoproj.v1alpha1.ApplicationSpecSourceDirectory;
            /**
             * Helm holds helm specific options
             */
            helm?: outputs.argoproj.v1alpha1.ApplicationSpecSourceHelm;
            /**
             * Ksonnet holds ksonnet specific options
             */
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationSpecSourceKsonnet;
            /**
             * Kustomize holds kustomize specific options
             */
            kustomize?: outputs.argoproj.v1alpha1.ApplicationSpecSourceKustomize;
            /**
             * Path is a directory path within the Git repository, and is only valid for applications sourced from Git.
             */
            path?: string;
            /**
             * ConfigManagementPlugin holds config management plugin specific options
             */
            plugin?: outputs.argoproj.v1alpha1.ApplicationSpecSourcePlugin;
            /**
             * RepoURL is the URL to the repository (Git or Helm) that contains the application manifests
             */
            repoURL: string;
            /**
             * TargetRevision defines the revision of the source to sync the application to. In case of Git, this can be commit, tag, or branch. If omitted, will equal to HEAD. In case of Helm, this is a semver tag for the Chart's version.
             */
            targetRevision?: string;
        }

        /**
         * Directory holds path/directory specific options
         */
        export interface ApplicationSpecSourceDirectory {
            /**
             * Exclude contains a glob pattern to match paths against that should be explicitly excluded from being used during manifest generation
             */
            exclude?: string;
            /**
             * Include contains a glob pattern to match paths against that should be explicitly included during manifest generation
             */
            include?: string;
            /**
             * Jsonnet holds options specific to Jsonnet
             */
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationSpecSourceDirectoryJsonnet;
            /**
             * Recurse specifies whether to scan a directory recursively for manifests
             */
            recurse?: boolean;
        }

        /**
         * Jsonnet holds options specific to Jsonnet
         */
        export interface ApplicationSpecSourceDirectoryJsonnet {
            /**
             * ExtVars is a list of Jsonnet External Variables
             */
            extVars?: outputs.argoproj.v1alpha1.ApplicationSpecSourceDirectoryJsonnetExtvars[];
            /**
             * Additional library search dirs
             */
            libs?: string[];
            /**
             * TLAS is a list of Jsonnet Top-level Arguments
             */
            tlas?: outputs.argoproj.v1alpha1.ApplicationSpecSourceDirectoryJsonnetTlas[];
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationSpecSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationSpecSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * Helm holds helm specific options
         */
        export interface ApplicationSpecSourceHelm {
            /**
             * FileParameters are file parameters to the helm template
             */
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationSpecSourceHelmFileparameters[];
            /**
             * IgnoreMissingValueFiles prevents helm template from failing when valueFiles do not exist locally by not appending them to helm template --values
             */
            ignoreMissingValueFiles?: boolean;
            /**
             * Parameters is a list of Helm parameters which are passed to the helm template command upon manifest generation
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationSpecSourceHelmParameters[];
            /**
             * PassCredentials pass credentials to all domains (Helm's --pass-credentials)
             */
            passCredentials?: boolean;
            /**
             * ReleaseName is the Helm release name to use. If omitted it will use the application name
             */
            releaseName?: string;
            /**
             * SkipCrds skips custom resource definition installation step (Helm's --skip-crds)
             */
            skipCrds?: boolean;
            /**
             * ValuesFiles is a list of Helm value files to use when generating a template
             */
            valueFiles?: string[];
            /**
             * Values specifies Helm values to be passed to helm template, typically defined as a block
             */
            values?: string;
            /**
             * Version is the Helm version to use for templating (either "2" or "3")
             */
            version?: string;
        }

        /**
         * HelmFileParameter is a file parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationSpecSourceHelmFileparameters {
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Path is the path to the file containing the values for the Helm parameter
             */
            path?: string;
        }

        /**
         * HelmParameter is a parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationSpecSourceHelmParameters {
            /**
             * ForceString determines whether to tell Helm to interpret booleans and numbers as strings
             */
            forceString?: boolean;
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Value is the value for the Helm parameter
             */
            value?: string;
        }

        /**
         * Ksonnet holds ksonnet specific options
         */
        export interface ApplicationSpecSourceKsonnet {
            /**
             * Environment is a ksonnet application environment name
             */
            environment?: string;
            /**
             * Parameters are a list of ksonnet component parameter override values
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationSpecSourceKsonnetParameters[];
        }

        /**
         * KsonnetParameter is a ksonnet component parameter
         */
        export interface ApplicationSpecSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        /**
         * Kustomize holds kustomize specific options
         */
        export interface ApplicationSpecSourceKustomize {
            /**
             * CommonAnnotations is a list of additional annotations to add to rendered manifests
             */
            commonAnnotations?: {[key: string]: string};
            /**
             * CommonLabels is a list of additional labels to add to rendered manifests
             */
            commonLabels?: {[key: string]: string};
            /**
             * ForceCommonAnnotations specifies whether to force applying common annotations to resources for Kustomize apps
             */
            forceCommonAnnotations?: boolean;
            /**
             * ForceCommonLabels specifies whether to force applying common labels to resources for Kustomize apps
             */
            forceCommonLabels?: boolean;
            /**
             * Images is a list of Kustomize image override specifications
             */
            images?: string[];
            /**
             * NamePrefix is a prefix appended to resources for Kustomize apps
             */
            namePrefix?: string;
            /**
             * NameSuffix is a suffix appended to resources for Kustomize apps
             */
            nameSuffix?: string;
            /**
             * Version controls which version of Kustomize to use for rendering manifests
             */
            version?: string;
        }

        /**
         * ConfigManagementPlugin holds config management plugin specific options
         */
        export interface ApplicationSpecSourcePlugin {
            /**
             * Env is a list of environment variable entries
             */
            env?: outputs.argoproj.v1alpha1.ApplicationSpecSourcePluginEnv[];
            name?: string;
        }

        /**
         * EnvEntry represents an entry in the application's environment
         */
        export interface ApplicationSpecSourcePluginEnv {
            /**
             * Name is the name of the variable, usually expressed in uppercase
             */
            name: string;
            /**
             * Value is the value of the variable
             */
            value: string;
        }

        /**
         * SyncPolicy controls when and how a sync will be performed
         */
        export interface ApplicationSpecSyncpolicy {
            /**
             * Automated will keep an application synced to the target revision
             */
            automated?: outputs.argoproj.v1alpha1.ApplicationSpecSyncpolicyAutomated;
            /**
             * Retry controls failed sync retry behavior
             */
            retry?: outputs.argoproj.v1alpha1.ApplicationSpecSyncpolicyRetry;
            /**
             * Options allow you to specify whole app sync-options
             */
            syncOptions?: string[];
        }

        /**
         * Automated will keep an application synced to the target revision
         */
        export interface ApplicationSpecSyncpolicyAutomated {
            /**
             * AllowEmpty allows apps have zero live resources (default: false)
             */
            allowEmpty?: boolean;
            /**
             * Prune specifies whether to delete resources from the cluster that are not found in the sources anymore as part of automated sync (default: false)
             */
            prune?: boolean;
            /**
             * SelfHeal specifes whether to revert resources back to their desired state upon modification in the cluster (default: false)
             */
            selfHeal?: boolean;
        }

        /**
         * Retry controls failed sync retry behavior
         */
        export interface ApplicationSpecSyncpolicyRetry {
            /**
             * Backoff controls how to backoff on subsequent retries of failed syncs
             */
            backoff?: outputs.argoproj.v1alpha1.ApplicationSpecSyncpolicyRetryBackoff;
            /**
             * Limit is the maximum number of attempts for retrying a failed sync. If set to 0, no retries will be performed.
             */
            limit?: number;
        }

        /**
         * Backoff controls how to backoff on subsequent retries of failed syncs
         */
        export interface ApplicationSpecSyncpolicyRetryBackoff {
            /**
             * Duration is the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
             */
            duration?: string;
            /**
             * Factor is a factor to multiply the base duration after each failed retry
             */
            factor?: number;
            /**
             * MaxDuration is the maximum amount of time allowed for the backoff strategy
             */
            maxDuration?: string;
        }

        /**
         * ApplicationStatus contains status information for the application
         */
        export interface ApplicationStatus {
            /**
             * Conditions is a list of currently observed application conditions
             */
            conditions?: outputs.argoproj.v1alpha1.ApplicationStatusConditions[];
            /**
             * Health contains information about the application's current health status
             */
            health?: outputs.argoproj.v1alpha1.ApplicationStatusHealth;
            /**
             * History contains information about the application's sync history
             */
            history?: outputs.argoproj.v1alpha1.ApplicationStatusHistory[];
            /**
             * ObservedAt indicates when the application state was updated without querying latest git state Deprecated: controller no longer updates ObservedAt field
             */
            observedAt?: string;
            /**
             * OperationState contains information about any ongoing operations, such as a sync
             */
            operationState?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstate;
            /**
             * ReconciledAt indicates when the application state was reconciled using the latest git version
             */
            reconciledAt?: string;
            /**
             * Resources is a list of Kubernetes resources managed by this application
             */
            resources?: outputs.argoproj.v1alpha1.ApplicationStatusResources[];
            /**
             * SourceType specifies the type of this application
             */
            sourceType?: string;
            /**
             * Summary contains a list of URLs and container images used by this application
             */
            summary?: outputs.argoproj.v1alpha1.ApplicationStatusSummary;
            /**
             * Sync contains information about the application's current sync status
             */
            sync?: outputs.argoproj.v1alpha1.ApplicationStatusSync;
        }

        /**
         * ApplicationCondition contains details about an application condition, which is usually an error or warning
         */
        export interface ApplicationStatusConditions {
            /**
             * LastTransitionTime is the time the condition was last observed
             */
            lastTransitionTime?: string;
            /**
             * Message contains human-readable message indicating details about condition
             */
            message: string;
            /**
             * Type is an application condition type
             */
            type: string;
        }

        /**
         * Health contains information about the application's current health status
         */
        export interface ApplicationStatusHealth {
            /**
             * Message is a human-readable informational message describing the health status
             */
            message?: string;
            /**
             * Status holds the status code of the application or resource
             */
            status?: string;
        }

        /**
         * RevisionHistory contains history information about a previous sync
         */
        export interface ApplicationStatusHistory {
            /**
             * DeployStartedAt holds the time the sync operation started
             */
            deployStartedAt?: string;
            /**
             * DeployedAt holds the time the sync operation completed
             */
            deployedAt: string;
            /**
             * ID is an auto incrementing identifier of the RevisionHistory
             */
            id: number;
            /**
             * Revision holds the revision the sync was performed against
             */
            revision: string;
            /**
             * Source is a reference to the application source used for the sync operation
             */
            source?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySource;
        }

        /**
         * Source is a reference to the application source used for the sync operation
         */
        export interface ApplicationStatusHistorySource {
            /**
             * Chart is a Helm chart name, and must be specified for applications sourced from a Helm repo.
             */
            chart?: string;
            /**
             * Directory holds path/directory specific options
             */
            directory?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceDirectory;
            /**
             * Helm holds helm specific options
             */
            helm?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceHelm;
            /**
             * Ksonnet holds ksonnet specific options
             */
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceKsonnet;
            /**
             * Kustomize holds kustomize specific options
             */
            kustomize?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceKustomize;
            /**
             * Path is a directory path within the Git repository, and is only valid for applications sourced from Git.
             */
            path?: string;
            /**
             * ConfigManagementPlugin holds config management plugin specific options
             */
            plugin?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourcePlugin;
            /**
             * RepoURL is the URL to the repository (Git or Helm) that contains the application manifests
             */
            repoURL: string;
            /**
             * TargetRevision defines the revision of the source to sync the application to. In case of Git, this can be commit, tag, or branch. If omitted, will equal to HEAD. In case of Helm, this is a semver tag for the Chart's version.
             */
            targetRevision?: string;
        }

        /**
         * Directory holds path/directory specific options
         */
        export interface ApplicationStatusHistorySourceDirectory {
            /**
             * Exclude contains a glob pattern to match paths against that should be explicitly excluded from being used during manifest generation
             */
            exclude?: string;
            /**
             * Include contains a glob pattern to match paths against that should be explicitly included during manifest generation
             */
            include?: string;
            /**
             * Jsonnet holds options specific to Jsonnet
             */
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceDirectoryJsonnet;
            /**
             * Recurse specifies whether to scan a directory recursively for manifests
             */
            recurse?: boolean;
        }

        /**
         * Jsonnet holds options specific to Jsonnet
         */
        export interface ApplicationStatusHistorySourceDirectoryJsonnet {
            /**
             * ExtVars is a list of Jsonnet External Variables
             */
            extVars?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceDirectoryJsonnetExtvars[];
            /**
             * Additional library search dirs
             */
            libs?: string[];
            /**
             * TLAS is a list of Jsonnet Top-level Arguments
             */
            tlas?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceDirectoryJsonnetTlas[];
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusHistorySourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusHistorySourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * Helm holds helm specific options
         */
        export interface ApplicationStatusHistorySourceHelm {
            /**
             * FileParameters are file parameters to the helm template
             */
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceHelmFileparameters[];
            /**
             * IgnoreMissingValueFiles prevents helm template from failing when valueFiles do not exist locally by not appending them to helm template --values
             */
            ignoreMissingValueFiles?: boolean;
            /**
             * Parameters is a list of Helm parameters which are passed to the helm template command upon manifest generation
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceHelmParameters[];
            /**
             * PassCredentials pass credentials to all domains (Helm's --pass-credentials)
             */
            passCredentials?: boolean;
            /**
             * ReleaseName is the Helm release name to use. If omitted it will use the application name
             */
            releaseName?: string;
            /**
             * SkipCrds skips custom resource definition installation step (Helm's --skip-crds)
             */
            skipCrds?: boolean;
            /**
             * ValuesFiles is a list of Helm value files to use when generating a template
             */
            valueFiles?: string[];
            /**
             * Values specifies Helm values to be passed to helm template, typically defined as a block
             */
            values?: string;
            /**
             * Version is the Helm version to use for templating (either "2" or "3")
             */
            version?: string;
        }

        /**
         * HelmFileParameter is a file parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusHistorySourceHelmFileparameters {
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Path is the path to the file containing the values for the Helm parameter
             */
            path?: string;
        }

        /**
         * HelmParameter is a parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusHistorySourceHelmParameters {
            /**
             * ForceString determines whether to tell Helm to interpret booleans and numbers as strings
             */
            forceString?: boolean;
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Value is the value for the Helm parameter
             */
            value?: string;
        }

        /**
         * Ksonnet holds ksonnet specific options
         */
        export interface ApplicationStatusHistorySourceKsonnet {
            /**
             * Environment is a ksonnet application environment name
             */
            environment?: string;
            /**
             * Parameters are a list of ksonnet component parameter override values
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourceKsonnetParameters[];
        }

        /**
         * KsonnetParameter is a ksonnet component parameter
         */
        export interface ApplicationStatusHistorySourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        /**
         * Kustomize holds kustomize specific options
         */
        export interface ApplicationStatusHistorySourceKustomize {
            /**
             * CommonAnnotations is a list of additional annotations to add to rendered manifests
             */
            commonAnnotations?: {[key: string]: string};
            /**
             * CommonLabels is a list of additional labels to add to rendered manifests
             */
            commonLabels?: {[key: string]: string};
            /**
             * ForceCommonAnnotations specifies whether to force applying common annotations to resources for Kustomize apps
             */
            forceCommonAnnotations?: boolean;
            /**
             * ForceCommonLabels specifies whether to force applying common labels to resources for Kustomize apps
             */
            forceCommonLabels?: boolean;
            /**
             * Images is a list of Kustomize image override specifications
             */
            images?: string[];
            /**
             * NamePrefix is a prefix appended to resources for Kustomize apps
             */
            namePrefix?: string;
            /**
             * NameSuffix is a suffix appended to resources for Kustomize apps
             */
            nameSuffix?: string;
            /**
             * Version controls which version of Kustomize to use for rendering manifests
             */
            version?: string;
        }

        /**
         * ConfigManagementPlugin holds config management plugin specific options
         */
        export interface ApplicationStatusHistorySourcePlugin {
            /**
             * Env is a list of environment variable entries
             */
            env?: outputs.argoproj.v1alpha1.ApplicationStatusHistorySourcePluginEnv[];
            name?: string;
        }

        /**
         * EnvEntry represents an entry in the application's environment
         */
        export interface ApplicationStatusHistorySourcePluginEnv {
            /**
             * Name is the name of the variable, usually expressed in uppercase
             */
            name: string;
            /**
             * Value is the value of the variable
             */
            value: string;
        }

        /**
         * OperationState contains information about any ongoing operations, such as a sync
         */
        export interface ApplicationStatusOperationstate {
            /**
             * FinishedAt contains time of operation completion
             */
            finishedAt?: string;
            /**
             * Message holds any pertinent messages when attempting to perform operation (typically errors).
             */
            message?: string;
            /**
             * Operation is the original requested operation
             */
            operation: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperation;
            /**
             * Phase is the current phase of the operation
             */
            phase: string;
            /**
             * RetryCount contains time of operation retries
             */
            retryCount?: number;
            /**
             * StartedAt contains time of operation start
             */
            startedAt: string;
            /**
             * SyncResult is the result of a Sync operation
             */
            syncResult?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresult;
        }

        /**
         * Operation is the original requested operation
         */
        export interface ApplicationStatusOperationstateOperation {
            /**
             * Info is a list of informational items for this operation
             */
            info?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationInfo[];
            /**
             * InitiatedBy contains information about who initiated the operations
             */
            initiatedBy?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationInitiatedby;
            /**
             * Retry controls the strategy to apply if a sync fails
             */
            retry?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationRetry;
            /**
             * Sync contains parameters for the operation
             */
            sync?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSync;
        }

        export interface ApplicationStatusOperationstateOperationInfo {
            name: string;
            value: string;
        }

        /**
         * InitiatedBy contains information about who initiated the operations
         */
        export interface ApplicationStatusOperationstateOperationInitiatedby {
            /**
             * Automated is set to true if operation was initiated automatically by the application controller.
             */
            automated?: boolean;
            /**
             * Username contains the name of a user who started operation
             */
            username?: string;
        }

        /**
         * Retry controls the strategy to apply if a sync fails
         */
        export interface ApplicationStatusOperationstateOperationRetry {
            /**
             * Backoff controls how to backoff on subsequent retries of failed syncs
             */
            backoff?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationRetryBackoff;
            /**
             * Limit is the maximum number of attempts for retrying a failed sync. If set to 0, no retries will be performed.
             */
            limit?: number;
        }

        /**
         * Backoff controls how to backoff on subsequent retries of failed syncs
         */
        export interface ApplicationStatusOperationstateOperationRetryBackoff {
            /**
             * Duration is the amount to back off. Default unit is seconds, but could also be a duration (e.g. "2m", "1h")
             */
            duration?: string;
            /**
             * Factor is a factor to multiply the base duration after each failed retry
             */
            factor?: number;
            /**
             * MaxDuration is the maximum amount of time allowed for the backoff strategy
             */
            maxDuration?: string;
        }

        /**
         * Sync contains parameters for the operation
         */
        export interface ApplicationStatusOperationstateOperationSync {
            /**
             * DryRun specifies to perform a `kubectl apply --dry-run` without actually performing the sync
             */
            dryRun?: boolean;
            /**
             * Manifests is an optional field that overrides sync source with a local directory for development
             */
            manifests?: string[];
            /**
             * Prune specifies to delete resources from the cluster that are no longer tracked in git
             */
            prune?: boolean;
            /**
             * Resources describes which resources shall be part of the sync
             */
            resources?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncResources[];
            /**
             * Revision is the revision (Git) or chart version (Helm) which to sync the application to If omitted, will use the revision specified in app spec.
             */
            revision?: string;
            /**
             * Source overrides the source definition set in the application. This is typically set in a Rollback operation and is nil during a Sync operation
             */
            source?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSource;
            /**
             * SyncOptions provide per-sync sync-options, e.g. Validate=false
             */
            syncOptions?: string[];
            /**
             * SyncStrategy describes how to perform the sync
             */
            syncStrategy?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSyncstrategy;
        }

        /**
         * SyncOperationResource contains resources to sync.
         */
        export interface ApplicationStatusOperationstateOperationSyncResources {
            group?: string;
            kind: string;
            name: string;
            namespace?: string;
        }

        /**
         * Source overrides the source definition set in the application. This is typically set in a Rollback operation and is nil during a Sync operation
         */
        export interface ApplicationStatusOperationstateOperationSyncSource {
            /**
             * Chart is a Helm chart name, and must be specified for applications sourced from a Helm repo.
             */
            chart?: string;
            /**
             * Directory holds path/directory specific options
             */
            directory?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceDirectory;
            /**
             * Helm holds helm specific options
             */
            helm?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceHelm;
            /**
             * Ksonnet holds ksonnet specific options
             */
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceKsonnet;
            /**
             * Kustomize holds kustomize specific options
             */
            kustomize?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceKustomize;
            /**
             * Path is a directory path within the Git repository, and is only valid for applications sourced from Git.
             */
            path?: string;
            /**
             * ConfigManagementPlugin holds config management plugin specific options
             */
            plugin?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourcePlugin;
            /**
             * RepoURL is the URL to the repository (Git or Helm) that contains the application manifests
             */
            repoURL: string;
            /**
             * TargetRevision defines the revision of the source to sync the application to. In case of Git, this can be commit, tag, or branch. If omitted, will equal to HEAD. In case of Helm, this is a semver tag for the Chart's version.
             */
            targetRevision?: string;
        }

        /**
         * Directory holds path/directory specific options
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceDirectory {
            /**
             * Exclude contains a glob pattern to match paths against that should be explicitly excluded from being used during manifest generation
             */
            exclude?: string;
            /**
             * Include contains a glob pattern to match paths against that should be explicitly included during manifest generation
             */
            include?: string;
            /**
             * Jsonnet holds options specific to Jsonnet
             */
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceDirectoryJsonnet;
            /**
             * Recurse specifies whether to scan a directory recursively for manifests
             */
            recurse?: boolean;
        }

        /**
         * Jsonnet holds options specific to Jsonnet
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceDirectoryJsonnet {
            /**
             * ExtVars is a list of Jsonnet External Variables
             */
            extVars?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceDirectoryJsonnetExtvars[];
            /**
             * Additional library search dirs
             */
            libs?: string[];
            /**
             * TLAS is a list of Jsonnet Top-level Arguments
             */
            tlas?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceDirectoryJsonnetTlas[];
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * Helm holds helm specific options
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceHelm {
            /**
             * FileParameters are file parameters to the helm template
             */
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceHelmFileparameters[];
            /**
             * IgnoreMissingValueFiles prevents helm template from failing when valueFiles do not exist locally by not appending them to helm template --values
             */
            ignoreMissingValueFiles?: boolean;
            /**
             * Parameters is a list of Helm parameters which are passed to the helm template command upon manifest generation
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceHelmParameters[];
            /**
             * PassCredentials pass credentials to all domains (Helm's --pass-credentials)
             */
            passCredentials?: boolean;
            /**
             * ReleaseName is the Helm release name to use. If omitted it will use the application name
             */
            releaseName?: string;
            /**
             * SkipCrds skips custom resource definition installation step (Helm's --skip-crds)
             */
            skipCrds?: boolean;
            /**
             * ValuesFiles is a list of Helm value files to use when generating a template
             */
            valueFiles?: string[];
            /**
             * Values specifies Helm values to be passed to helm template, typically defined as a block
             */
            values?: string;
            /**
             * Version is the Helm version to use for templating (either "2" or "3")
             */
            version?: string;
        }

        /**
         * HelmFileParameter is a file parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceHelmFileparameters {
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Path is the path to the file containing the values for the Helm parameter
             */
            path?: string;
        }

        /**
         * HelmParameter is a parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceHelmParameters {
            /**
             * ForceString determines whether to tell Helm to interpret booleans and numbers as strings
             */
            forceString?: boolean;
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Value is the value for the Helm parameter
             */
            value?: string;
        }

        /**
         * Ksonnet holds ksonnet specific options
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceKsonnet {
            /**
             * Environment is a ksonnet application environment name
             */
            environment?: string;
            /**
             * Parameters are a list of ksonnet component parameter override values
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourceKsonnetParameters[];
        }

        /**
         * KsonnetParameter is a ksonnet component parameter
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        /**
         * Kustomize holds kustomize specific options
         */
        export interface ApplicationStatusOperationstateOperationSyncSourceKustomize {
            /**
             * CommonAnnotations is a list of additional annotations to add to rendered manifests
             */
            commonAnnotations?: {[key: string]: string};
            /**
             * CommonLabels is a list of additional labels to add to rendered manifests
             */
            commonLabels?: {[key: string]: string};
            /**
             * ForceCommonAnnotations specifies whether to force applying common annotations to resources for Kustomize apps
             */
            forceCommonAnnotations?: boolean;
            /**
             * ForceCommonLabels specifies whether to force applying common labels to resources for Kustomize apps
             */
            forceCommonLabels?: boolean;
            /**
             * Images is a list of Kustomize image override specifications
             */
            images?: string[];
            /**
             * NamePrefix is a prefix appended to resources for Kustomize apps
             */
            namePrefix?: string;
            /**
             * NameSuffix is a suffix appended to resources for Kustomize apps
             */
            nameSuffix?: string;
            /**
             * Version controls which version of Kustomize to use for rendering manifests
             */
            version?: string;
        }

        /**
         * ConfigManagementPlugin holds config management plugin specific options
         */
        export interface ApplicationStatusOperationstateOperationSyncSourcePlugin {
            /**
             * Env is a list of environment variable entries
             */
            env?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSourcePluginEnv[];
            name?: string;
        }

        /**
         * EnvEntry represents an entry in the application's environment
         */
        export interface ApplicationStatusOperationstateOperationSyncSourcePluginEnv {
            /**
             * Name is the name of the variable, usually expressed in uppercase
             */
            name: string;
            /**
             * Value is the value of the variable
             */
            value: string;
        }

        /**
         * SyncStrategy describes how to perform the sync
         */
        export interface ApplicationStatusOperationstateOperationSyncSyncstrategy {
            /**
             * Apply will perform a `kubectl apply` to perform the sync.
             */
            apply?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSyncstrategyApply;
            /**
             * Hook will submit any referenced resources to perform the sync. This is the default strategy
             */
            hook?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateOperationSyncSyncstrategyHook;
        }

        /**
         * Apply will perform a `kubectl apply` to perform the sync.
         */
        export interface ApplicationStatusOperationstateOperationSyncSyncstrategyApply {
            /**
             * Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
             */
            force?: boolean;
        }

        /**
         * Hook will submit any referenced resources to perform the sync. This is the default strategy
         */
        export interface ApplicationStatusOperationstateOperationSyncSyncstrategyHook {
            /**
             * Force indicates whether or not to supply the --force flag to `kubectl apply`. The --force flag deletes and re-create the resource, when PATCH encounters conflict and has retried for 5 times.
             */
            force?: boolean;
        }

        /**
         * SyncResult is the result of a Sync operation
         */
        export interface ApplicationStatusOperationstateSyncresult {
            /**
             * Resources contains a list of sync result items for each individual resource in a sync operation
             */
            resources?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultResources[];
            /**
             * Revision holds the revision this sync operation was performed to
             */
            revision: string;
            /**
             * Source records the application source information of the sync, used for comparing auto-sync
             */
            source?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSource;
        }

        /**
         * ResourceResult holds the operation result details of a specific resource
         */
        export interface ApplicationStatusOperationstateSyncresultResources {
            /**
             * Group specifies the API group of the resource
             */
            group: string;
            /**
             * HookPhase contains the state of any operation associated with this resource OR hook This can also contain values for non-hook resources.
             */
            hookPhase?: string;
            /**
             * HookType specifies the type of the hook. Empty for non-hook resources
             */
            hookType?: string;
            /**
             * Kind specifies the API kind of the resource
             */
            kind: string;
            /**
             * Message contains an informational or error message for the last sync OR operation
             */
            message?: string;
            /**
             * Name specifies the name of the resource
             */
            name: string;
            /**
             * Namespace specifies the target namespace of the resource
             */
            namespace: string;
            /**
             * Status holds the final result of the sync. Will be empty if the resources is yet to be applied/pruned and is always zero-value for hooks
             */
            status?: string;
            /**
             * SyncPhase indicates the particular phase of the sync that this result was acquired in
             */
            syncPhase?: string;
            /**
             * Version specifies the API version of the resource
             */
            version: string;
        }

        /**
         * Source records the application source information of the sync, used for comparing auto-sync
         */
        export interface ApplicationStatusOperationstateSyncresultSource {
            /**
             * Chart is a Helm chart name, and must be specified for applications sourced from a Helm repo.
             */
            chart?: string;
            /**
             * Directory holds path/directory specific options
             */
            directory?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceDirectory;
            /**
             * Helm holds helm specific options
             */
            helm?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceHelm;
            /**
             * Ksonnet holds ksonnet specific options
             */
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceKsonnet;
            /**
             * Kustomize holds kustomize specific options
             */
            kustomize?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceKustomize;
            /**
             * Path is a directory path within the Git repository, and is only valid for applications sourced from Git.
             */
            path?: string;
            /**
             * ConfigManagementPlugin holds config management plugin specific options
             */
            plugin?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourcePlugin;
            /**
             * RepoURL is the URL to the repository (Git or Helm) that contains the application manifests
             */
            repoURL: string;
            /**
             * TargetRevision defines the revision of the source to sync the application to. In case of Git, this can be commit, tag, or branch. If omitted, will equal to HEAD. In case of Helm, this is a semver tag for the Chart's version.
             */
            targetRevision?: string;
        }

        /**
         * Directory holds path/directory specific options
         */
        export interface ApplicationStatusOperationstateSyncresultSourceDirectory {
            /**
             * Exclude contains a glob pattern to match paths against that should be explicitly excluded from being used during manifest generation
             */
            exclude?: string;
            /**
             * Include contains a glob pattern to match paths against that should be explicitly included during manifest generation
             */
            include?: string;
            /**
             * Jsonnet holds options specific to Jsonnet
             */
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceDirectoryJsonnet;
            /**
             * Recurse specifies whether to scan a directory recursively for manifests
             */
            recurse?: boolean;
        }

        /**
         * Jsonnet holds options specific to Jsonnet
         */
        export interface ApplicationStatusOperationstateSyncresultSourceDirectoryJsonnet {
            /**
             * ExtVars is a list of Jsonnet External Variables
             */
            extVars?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceDirectoryJsonnetExtvars[];
            /**
             * Additional library search dirs
             */
            libs?: string[];
            /**
             * TLAS is a list of Jsonnet Top-level Arguments
             */
            tlas?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceDirectoryJsonnetTlas[];
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusOperationstateSyncresultSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusOperationstateSyncresultSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * Helm holds helm specific options
         */
        export interface ApplicationStatusOperationstateSyncresultSourceHelm {
            /**
             * FileParameters are file parameters to the helm template
             */
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceHelmFileparameters[];
            /**
             * IgnoreMissingValueFiles prevents helm template from failing when valueFiles do not exist locally by not appending them to helm template --values
             */
            ignoreMissingValueFiles?: boolean;
            /**
             * Parameters is a list of Helm parameters which are passed to the helm template command upon manifest generation
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceHelmParameters[];
            /**
             * PassCredentials pass credentials to all domains (Helm's --pass-credentials)
             */
            passCredentials?: boolean;
            /**
             * ReleaseName is the Helm release name to use. If omitted it will use the application name
             */
            releaseName?: string;
            /**
             * SkipCrds skips custom resource definition installation step (Helm's --skip-crds)
             */
            skipCrds?: boolean;
            /**
             * ValuesFiles is a list of Helm value files to use when generating a template
             */
            valueFiles?: string[];
            /**
             * Values specifies Helm values to be passed to helm template, typically defined as a block
             */
            values?: string;
            /**
             * Version is the Helm version to use for templating (either "2" or "3")
             */
            version?: string;
        }

        /**
         * HelmFileParameter is a file parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusOperationstateSyncresultSourceHelmFileparameters {
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Path is the path to the file containing the values for the Helm parameter
             */
            path?: string;
        }

        /**
         * HelmParameter is a parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusOperationstateSyncresultSourceHelmParameters {
            /**
             * ForceString determines whether to tell Helm to interpret booleans and numbers as strings
             */
            forceString?: boolean;
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Value is the value for the Helm parameter
             */
            value?: string;
        }

        /**
         * Ksonnet holds ksonnet specific options
         */
        export interface ApplicationStatusOperationstateSyncresultSourceKsonnet {
            /**
             * Environment is a ksonnet application environment name
             */
            environment?: string;
            /**
             * Parameters are a list of ksonnet component parameter override values
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourceKsonnetParameters[];
        }

        /**
         * KsonnetParameter is a ksonnet component parameter
         */
        export interface ApplicationStatusOperationstateSyncresultSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        /**
         * Kustomize holds kustomize specific options
         */
        export interface ApplicationStatusOperationstateSyncresultSourceKustomize {
            /**
             * CommonAnnotations is a list of additional annotations to add to rendered manifests
             */
            commonAnnotations?: {[key: string]: string};
            /**
             * CommonLabels is a list of additional labels to add to rendered manifests
             */
            commonLabels?: {[key: string]: string};
            /**
             * ForceCommonAnnotations specifies whether to force applying common annotations to resources for Kustomize apps
             */
            forceCommonAnnotations?: boolean;
            /**
             * ForceCommonLabels specifies whether to force applying common labels to resources for Kustomize apps
             */
            forceCommonLabels?: boolean;
            /**
             * Images is a list of Kustomize image override specifications
             */
            images?: string[];
            /**
             * NamePrefix is a prefix appended to resources for Kustomize apps
             */
            namePrefix?: string;
            /**
             * NameSuffix is a suffix appended to resources for Kustomize apps
             */
            nameSuffix?: string;
            /**
             * Version controls which version of Kustomize to use for rendering manifests
             */
            version?: string;
        }

        /**
         * ConfigManagementPlugin holds config management plugin specific options
         */
        export interface ApplicationStatusOperationstateSyncresultSourcePlugin {
            /**
             * Env is a list of environment variable entries
             */
            env?: outputs.argoproj.v1alpha1.ApplicationStatusOperationstateSyncresultSourcePluginEnv[];
            name?: string;
        }

        /**
         * EnvEntry represents an entry in the application's environment
         */
        export interface ApplicationStatusOperationstateSyncresultSourcePluginEnv {
            /**
             * Name is the name of the variable, usually expressed in uppercase
             */
            name: string;
            /**
             * Value is the value of the variable
             */
            value: string;
        }

        /**
         * ResourceStatus holds the current sync and health status of a resource TODO: describe members of this type
         */
        export interface ApplicationStatusResources {
            group?: string;
            /**
             * HealthStatus contains information about the currently observed health state of an application or resource
             */
            health?: outputs.argoproj.v1alpha1.ApplicationStatusResourcesHealth;
            hook?: boolean;
            kind?: string;
            name?: string;
            namespace?: string;
            requiresPruning?: boolean;
            /**
             * SyncStatusCode is a type which represents possible comparison results
             */
            status?: string;
            version?: string;
        }

        /**
         * HealthStatus contains information about the currently observed health state of an application or resource
         */
        export interface ApplicationStatusResourcesHealth {
            /**
             * Message is a human-readable informational message describing the health status
             */
            message?: string;
            /**
             * Status holds the status code of the application or resource
             */
            status?: string;
        }

        /**
         * Summary contains a list of URLs and container images used by this application
         */
        export interface ApplicationStatusSummary {
            /**
             * ExternalURLs holds all external URLs of application child resources.
             */
            externalURLs?: string[];
            /**
             * Images holds all images of application child resources.
             */
            images?: string[];
        }

        /**
         * Sync contains information about the application's current sync status
         */
        export interface ApplicationStatusSync {
            /**
             * ComparedTo contains information about what has been compared
             */
            comparedTo?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedto;
            /**
             * Revision contains information about the revision the comparison has been performed to
             */
            revision?: string;
            /**
             * Status is the sync state of the comparison
             */
            status: string;
        }

        /**
         * ComparedTo contains information about what has been compared
         */
        export interface ApplicationStatusSyncComparedto {
            /**
             * Destination is a reference to the application's destination used for comparison
             */
            destination: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoDestination;
            /**
             * Source is a reference to the application's source used for comparison
             */
            source: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSource;
        }

        /**
         * Destination is a reference to the application's destination used for comparison
         */
        export interface ApplicationStatusSyncComparedtoDestination {
            /**
             * Name is an alternate way of specifying the target cluster by its symbolic name
             */
            name?: string;
            /**
             * Namespace specifies the target namespace for the application's resources. The namespace will only be set for namespace-scoped resources that have not set a value for .metadata.namespace
             */
            namespace?: string;
            /**
             * Server specifies the URL of the target cluster and must be set to the Kubernetes control plane API
             */
            server?: string;
        }

        /**
         * Source is a reference to the application's source used for comparison
         */
        export interface ApplicationStatusSyncComparedtoSource {
            /**
             * Chart is a Helm chart name, and must be specified for applications sourced from a Helm repo.
             */
            chart?: string;
            /**
             * Directory holds path/directory specific options
             */
            directory?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceDirectory;
            /**
             * Helm holds helm specific options
             */
            helm?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceHelm;
            /**
             * Ksonnet holds ksonnet specific options
             */
            ksonnet?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceKsonnet;
            /**
             * Kustomize holds kustomize specific options
             */
            kustomize?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceKustomize;
            /**
             * Path is a directory path within the Git repository, and is only valid for applications sourced from Git.
             */
            path?: string;
            /**
             * ConfigManagementPlugin holds config management plugin specific options
             */
            plugin?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourcePlugin;
            /**
             * RepoURL is the URL to the repository (Git or Helm) that contains the application manifests
             */
            repoURL: string;
            /**
             * TargetRevision defines the revision of the source to sync the application to. In case of Git, this can be commit, tag, or branch. If omitted, will equal to HEAD. In case of Helm, this is a semver tag for the Chart's version.
             */
            targetRevision?: string;
        }

        /**
         * Directory holds path/directory specific options
         */
        export interface ApplicationStatusSyncComparedtoSourceDirectory {
            /**
             * Exclude contains a glob pattern to match paths against that should be explicitly excluded from being used during manifest generation
             */
            exclude?: string;
            /**
             * Include contains a glob pattern to match paths against that should be explicitly included during manifest generation
             */
            include?: string;
            /**
             * Jsonnet holds options specific to Jsonnet
             */
            jsonnet?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceDirectoryJsonnet;
            /**
             * Recurse specifies whether to scan a directory recursively for manifests
             */
            recurse?: boolean;
        }

        /**
         * Jsonnet holds options specific to Jsonnet
         */
        export interface ApplicationStatusSyncComparedtoSourceDirectoryJsonnet {
            /**
             * ExtVars is a list of Jsonnet External Variables
             */
            extVars?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceDirectoryJsonnetExtvars[];
            /**
             * Additional library search dirs
             */
            libs?: string[];
            /**
             * TLAS is a list of Jsonnet Top-level Arguments
             */
            tlas?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceDirectoryJsonnetTlas[];
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusSyncComparedtoSourceDirectoryJsonnetExtvars {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * JsonnetVar represents a variable to be passed to jsonnet during manifest generation
         */
        export interface ApplicationStatusSyncComparedtoSourceDirectoryJsonnetTlas {
            code?: boolean;
            name: string;
            value: string;
        }

        /**
         * Helm holds helm specific options
         */
        export interface ApplicationStatusSyncComparedtoSourceHelm {
            /**
             * FileParameters are file parameters to the helm template
             */
            fileParameters?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceHelmFileparameters[];
            /**
             * IgnoreMissingValueFiles prevents helm template from failing when valueFiles do not exist locally by not appending them to helm template --values
             */
            ignoreMissingValueFiles?: boolean;
            /**
             * Parameters is a list of Helm parameters which are passed to the helm template command upon manifest generation
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceHelmParameters[];
            /**
             * PassCredentials pass credentials to all domains (Helm's --pass-credentials)
             */
            passCredentials?: boolean;
            /**
             * ReleaseName is the Helm release name to use. If omitted it will use the application name
             */
            releaseName?: string;
            /**
             * SkipCrds skips custom resource definition installation step (Helm's --skip-crds)
             */
            skipCrds?: boolean;
            /**
             * ValuesFiles is a list of Helm value files to use when generating a template
             */
            valueFiles?: string[];
            /**
             * Values specifies Helm values to be passed to helm template, typically defined as a block
             */
            values?: string;
            /**
             * Version is the Helm version to use for templating (either "2" or "3")
             */
            version?: string;
        }

        /**
         * HelmFileParameter is a file parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusSyncComparedtoSourceHelmFileparameters {
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Path is the path to the file containing the values for the Helm parameter
             */
            path?: string;
        }

        /**
         * HelmParameter is a parameter that's passed to helm template during manifest generation
         */
        export interface ApplicationStatusSyncComparedtoSourceHelmParameters {
            /**
             * ForceString determines whether to tell Helm to interpret booleans and numbers as strings
             */
            forceString?: boolean;
            /**
             * Name is the name of the Helm parameter
             */
            name?: string;
            /**
             * Value is the value for the Helm parameter
             */
            value?: string;
        }

        /**
         * Ksonnet holds ksonnet specific options
         */
        export interface ApplicationStatusSyncComparedtoSourceKsonnet {
            /**
             * Environment is a ksonnet application environment name
             */
            environment?: string;
            /**
             * Parameters are a list of ksonnet component parameter override values
             */
            parameters?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourceKsonnetParameters[];
        }

        /**
         * KsonnetParameter is a ksonnet component parameter
         */
        export interface ApplicationStatusSyncComparedtoSourceKsonnetParameters {
            component?: string;
            name: string;
            value: string;
        }

        /**
         * Kustomize holds kustomize specific options
         */
        export interface ApplicationStatusSyncComparedtoSourceKustomize {
            /**
             * CommonAnnotations is a list of additional annotations to add to rendered manifests
             */
            commonAnnotations?: {[key: string]: string};
            /**
             * CommonLabels is a list of additional labels to add to rendered manifests
             */
            commonLabels?: {[key: string]: string};
            /**
             * ForceCommonAnnotations specifies whether to force applying common annotations to resources for Kustomize apps
             */
            forceCommonAnnotations?: boolean;
            /**
             * ForceCommonLabels specifies whether to force applying common labels to resources for Kustomize apps
             */
            forceCommonLabels?: boolean;
            /**
             * Images is a list of Kustomize image override specifications
             */
            images?: string[];
            /**
             * NamePrefix is a prefix appended to resources for Kustomize apps
             */
            namePrefix?: string;
            /**
             * NameSuffix is a suffix appended to resources for Kustomize apps
             */
            nameSuffix?: string;
            /**
             * Version controls which version of Kustomize to use for rendering manifests
             */
            version?: string;
        }

        /**
         * ConfigManagementPlugin holds config management plugin specific options
         */
        export interface ApplicationStatusSyncComparedtoSourcePlugin {
            /**
             * Env is a list of environment variable entries
             */
            env?: outputs.argoproj.v1alpha1.ApplicationStatusSyncComparedtoSourcePluginEnv[];
            name?: string;
        }

        /**
         * EnvEntry represents an entry in the application's environment
         */
        export interface ApplicationStatusSyncComparedtoSourcePluginEnv {
            /**
             * Name is the name of the variable, usually expressed in uppercase
             */
            name: string;
            /**
             * Value is the value of the variable
             */
            value: string;
        }

        /**
         * ArgoCDExtensionSpec defines the desired state of ArgoCDExtension
         */
        export interface ArgoCDExtensionSpec {
            /**
             * Sources specifies where the extension should come from
             */
            sources: outputs.argoproj.v1alpha1.ArgoCDExtensionSpecSources[];
        }

        /**
         * ExtensionSource specifies where the extension should be sourced from
         */
        export interface ArgoCDExtensionSpecSources {
            /**
             * Git is specified if the extension should be sourced from a git repository
             */
            git?: outputs.argoproj.v1alpha1.ArgoCDExtensionSpecSourcesGit;
            /**
             * Web is specified if the extension should be sourced from a web file
             */
            web?: outputs.argoproj.v1alpha1.ArgoCDExtensionSpecSourcesWeb;
        }

        /**
         * Git is specified if the extension should be sourced from a git repository
         */
        export interface ArgoCDExtensionSpecSourcesGit {
            /**
             * Revision specifies the revision of the Repository to fetch
             */
            revision?: string;
            /**
             * URL specifies the Git repository URL to fetch
             */
            url?: string;
        }

        /**
         * Web is specified if the extension should be sourced from a web file
         */
        export interface ArgoCDExtensionSpecSourcesWeb {
            /**
             * URK specifies the remote file URL
             */
            url?: string;
        }

        /**
         * ArgoCDExtensionStatus defines the observed state of ArgoCDExtension
         */
        export interface ArgoCDExtensionStatus {
            conditions?: outputs.argoproj.v1alpha1.ArgoCDExtensionStatusConditions[];
        }

        export interface ArgoCDExtensionStatusConditions {
            /**
             * Message contains human-readable message indicating details about condition
             */
            message: string;
            /**
             * Boolean status describing if the condition is currently true
             */
            status: string;
            /**
             * Type is an ArgoCDExtension condition type
             */
            type: string;
        }

    }
}

export namespace bitnami {
    export namespace v1alpha1 {
        /**
         * SealedSecretSpec is the specification of a SealedSecret
         */
        export interface SealedSecretSpec {
            /**
             * Data is deprecated and will be removed eventually. Use per-value EncryptedData instead.
             */
            data?: string;
            encryptedData: {[key: string]: any};
            /**
             * Template defines the structure of the Secret that will be created from this sealed secret.
             */
            template?: outputs.bitnami.v1alpha1.SealedSecretSpecTemplate;
        }

        /**
         * Template defines the structure of the Secret that will be created from this sealed secret.
         */
        export interface SealedSecretSpecTemplate {
            /**
             * Keys that should be templated using decrypted data
             */
            data?: {[key: string]: string};
            /**
             * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata
             */
            metadata?: {[key: string]: any};
            /**
             * Used to facilitate programmatic handling of secret data.
             */
            type?: string;
        }

        /**
         * SealedSecretStatus is the most recently observed status of the SealedSecret.
         */
        export interface SealedSecretStatus {
            /**
             * Represents the latest available observations of a sealed secret's current state.
             */
            conditions?: outputs.bitnami.v1alpha1.SealedSecretStatusConditions[];
            /**
             * ObservedGeneration reflects the generation most recently observed by the sealed-secrets controller.
             */
            observedGeneration?: number;
        }

        /**
         * SealedSecretCondition describes the state of a sealed secret at a certain point.
         */
        export interface SealedSecretStatusConditions {
            /**
             * Last time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * The last time this condition was updated.
             */
            lastUpdateTime?: string;
            /**
             * A human readable message indicating details about the transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition for a sealed secret. Valid values for "Synced": "True", "False", or "Unknown".
             */
            status: string;
            /**
             * Type of condition for a sealed secret. Valid value: "Synced"
             */
            type: string;
        }

    }
}

export namespace ceph {
    export namespace v1 {
        /**
         * Spec represents the specification of a Ceph BlockPool Rados Namespace
         */
        export interface CephBlockPoolRadosNamespaceSpec {
            /**
             * BlockPoolName is the name of Ceph BlockPool. Typically it's the name of the CephBlockPool CR.
             */
            blockPoolName: string;
        }

        /**
         * NamedBlockPoolSpec allows a block pool to be created with a non-default name. This is more specific than the NamedPoolSpec so we get schema validation on the allowed pool names that can be specified.
         */
        export interface CephBlockPoolSpec {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephBlockPoolSpecErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephBlockPoolSpecMirroring;
            /**
             * The desired name of the pool if different from the CephBlockPool CR name.
             */
            name?: string;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephBlockPoolSpecQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephBlockPoolSpecReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephBlockPoolSpecErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephBlockPoolSpecMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephBlockPoolSpecMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephBlockPoolSpecMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephBlockPoolSpecMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephBlockPoolSpecMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephBlockPoolSpecQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephBlockPoolSpecReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephBlockPoolSpecReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephBlockPoolSpecReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * BucketNotificationSpec represent the spec of a Bucket Notification
         */
        export interface CephBucketNotificationSpec {
            /**
             * List of events that should trigger the notification
             */
            events?: string[];
            /**
             * Spec of notification filter
             */
            filter?: outputs.ceph.v1.CephBucketNotificationSpecFilter;
            /**
             * The name of the topic associated with this notification
             */
            topic: string;
        }

        /**
         * Spec of notification filter
         */
        export interface CephBucketNotificationSpecFilter {
            /**
             * Filters based on the object's key
             */
            keyFilters?: outputs.ceph.v1.CephBucketNotificationSpecFilterKeyfilters[];
            /**
             * Filters based on the object's metadata
             */
            metadataFilters?: outputs.ceph.v1.CephBucketNotificationSpecFilterMetadatafilters[];
            /**
             * Filters based on the object's tags
             */
            tagFilters?: outputs.ceph.v1.CephBucketNotificationSpecFilterTagfilters[];
        }

        /**
         * NotificationKeyFilterRule represent a single key rule in the Notification Filter spec
         */
        export interface CephBucketNotificationSpecFilterKeyfilters {
            /**
             * Name of the filter - prefix/suffix/regex
             */
            name: string;
            /**
             * Value to filter on
             */
            value: string;
        }

        /**
         * NotificationFilterRule represent a single rule in the Notification Filter spec
         */
        export interface CephBucketNotificationSpecFilterMetadatafilters {
            /**
             * Name of the metadata or tag
             */
            name: string;
            /**
             * Value to filter on
             */
            value: string;
        }

        /**
         * NotificationFilterRule represent a single rule in the Notification Filter spec
         */
        export interface CephBucketNotificationSpecFilterTagfilters {
            /**
             * Name of the metadata or tag
             */
            name: string;
            /**
             * Value to filter on
             */
            value: string;
        }

        /**
         * BucketTopicSpec represent the spec of a Bucket Topic
         */
        export interface CephBucketTopicSpec {
            /**
             * Contains the endpoint spec of the topic
             */
            endpoint: outputs.ceph.v1.CephBucketTopicSpecEndpoint;
            /**
             * The name of the object store on which to define the topic
             */
            objectStoreName: string;
            /**
             * The namespace of the object store on which to define the topic
             */
            objectStoreNamespace: string;
            /**
             * Data which is sent in each event
             */
            opaqueData?: string;
            /**
             * Indication whether notifications to this endpoint are persistent or not
             */
            persistent?: boolean;
        }
        /**
         * cephBucketTopicSpecProvideDefaults sets the appropriate defaults for CephBucketTopicSpec
         */
        export function cephBucketTopicSpecProvideDefaults(val: CephBucketTopicSpec): CephBucketTopicSpec {
            return {
                ...val,
                endpoint: outputs.ceph.v1.cephBucketTopicSpecEndpointProvideDefaults(val.endpoint),
            };
        }

        /**
         * Contains the endpoint spec of the topic
         */
        export interface CephBucketTopicSpecEndpoint {
            /**
             * Spec of AMQP endpoint
             */
            amqp?: outputs.ceph.v1.CephBucketTopicSpecEndpointAmqp;
            /**
             * Spec of HTTP endpoint
             */
            http?: outputs.ceph.v1.CephBucketTopicSpecEndpointHttp;
            /**
             * Spec of Kafka endpoint
             */
            kafka?: outputs.ceph.v1.CephBucketTopicSpecEndpointKafka;
        }
        /**
         * cephBucketTopicSpecEndpointProvideDefaults sets the appropriate defaults for CephBucketTopicSpecEndpoint
         */
        export function cephBucketTopicSpecEndpointProvideDefaults(val: CephBucketTopicSpecEndpoint): CephBucketTopicSpecEndpoint {
            return {
                ...val,
                amqp: (val.amqp ? outputs.ceph.v1.cephBucketTopicSpecEndpointAmqpProvideDefaults(val.amqp) : undefined),
                kafka: (val.kafka ? outputs.ceph.v1.cephBucketTopicSpecEndpointKafkaProvideDefaults(val.kafka) : undefined),
            };
        }

        /**
         * Spec of AMQP endpoint
         */
        export interface CephBucketTopicSpecEndpointAmqp {
            /**
             * The ack level required for this topic (none/broker/routeable)
             */
            ackLevel?: string;
            /**
             * Indicate whether the server certificate is validated by the client or not
             */
            disableVerifySSL?: boolean;
            /**
             * Name of the exchange that is used to route messages based on topics
             */
            exchange: string;
            /**
             * The URI of the AMQP endpoint to push notification to
             */
            uri: string;
        }
        /**
         * cephBucketTopicSpecEndpointAmqpProvideDefaults sets the appropriate defaults for CephBucketTopicSpecEndpointAmqp
         */
        export function cephBucketTopicSpecEndpointAmqpProvideDefaults(val: CephBucketTopicSpecEndpointAmqp): CephBucketTopicSpecEndpointAmqp {
            return {
                ...val,
                ackLevel: (val.ackLevel) ?? "broker",
            };
        }

        /**
         * Spec of HTTP endpoint
         */
        export interface CephBucketTopicSpecEndpointHttp {
            /**
             * Indicate whether the server certificate is validated by the client or not
             */
            disableVerifySSL?: boolean;
            /**
             * Send the notifications with the CloudEvents header: https://github.com/cloudevents/spec/blob/main/cloudevents/adapters/aws-s3.md Supported for Ceph Quincy (v17) or newer.
             */
            sendCloudEvents?: boolean;
            /**
             * The URI of the HTTP endpoint to push notification to
             */
            uri: string;
        }

        /**
         * Spec of Kafka endpoint
         */
        export interface CephBucketTopicSpecEndpointKafka {
            /**
             * The ack level required for this topic (none/broker)
             */
            ackLevel?: string;
            /**
             * Indicate whether the server certificate is validated by the client or not
             */
            disableVerifySSL?: boolean;
            /**
             * The URI of the Kafka endpoint to push notification to
             */
            uri: string;
            /**
             * Indicate whether to use SSL when communicating with the broker
             */
            useSSL?: boolean;
        }
        /**
         * cephBucketTopicSpecEndpointKafkaProvideDefaults sets the appropriate defaults for CephBucketTopicSpecEndpointKafka
         */
        export function cephBucketTopicSpecEndpointKafkaProvideDefaults(val: CephBucketTopicSpecEndpointKafka): CephBucketTopicSpecEndpointKafka {
            return {
                ...val,
                ackLevel: (val.ackLevel) ?? "broker",
            };
        }

        /**
         * Spec represents the specification of a Ceph Client
         */
        export interface CephClientSpec {
            caps: {[key: string]: any};
            name?: string;
        }

        /**
         * ClusterSpec represents the specification of Ceph Cluster
         */
        export interface CephClusterSpec {
            /**
             * The annotations-related configuration to add/set on each Pod related object.
             */
            annotations?: {[key: string]: any};
            /**
             * The version information that instructs Rook to orchestrate a particular version of Ceph.
             */
            cephVersion?: outputs.ceph.v1.CephClusterSpecCephversion;
            /**
             * Indicates user intent when deleting a cluster; blocks orchestration and should not be set if cluster deletion is not imminent.
             */
            cleanupPolicy?: outputs.ceph.v1.CephClusterSpecCleanuppolicy;
            /**
             * ContinueUpgradeAfterChecksEvenIfNotHealthy defines if an upgrade should continue even if PGs are not clean
             */
            continueUpgradeAfterChecksEvenIfNotHealthy?: boolean;
            /**
             * A spec for the crash controller
             */
            crashCollector?: outputs.ceph.v1.CephClusterSpecCrashcollector;
            /**
             * Dashboard settings
             */
            dashboard?: outputs.ceph.v1.CephClusterSpecDashboard;
            /**
             * The path on the host where config and data can be persisted
             */
            dataDirHostPath?: string;
            /**
             * A spec for configuring disruption management.
             */
            disruptionManagement?: outputs.ceph.v1.CephClusterSpecDisruptionmanagement;
            /**
             * Whether the Ceph Cluster is running external to this Kubernetes cluster mon, mgr, osd, mds, and discover daemons will not be created for external clusters.
             */
            external?: {[key: string]: any};
            /**
             * Internal daemon healthchecks and liveness probe
             */
            healthCheck?: outputs.ceph.v1.CephClusterSpecHealthcheck;
            /**
             * The labels-related configuration to add/set on each Pod related object.
             */
            labels?: {[key: string]: any};
            /**
             * Logging represents loggings settings
             */
            logCollector?: outputs.ceph.v1.CephClusterSpecLogcollector;
            /**
             * A spec for mgr related options
             */
            mgr?: outputs.ceph.v1.CephClusterSpecMgr;
            /**
             * A spec for mon related options
             */
            mon?: outputs.ceph.v1.CephClusterSpecMon;
            /**
             * Prometheus based Monitoring settings
             */
            monitoring?: outputs.ceph.v1.CephClusterSpecMonitoring;
            /**
             * Network related configuration
             */
            network?: {[key: string]: any};
            /**
             * The placement-related configuration to pass to kubernetes (affinity, node selector, tolerations).
             */
            placement?: {[key: string]: any};
            /**
             * PriorityClassNames sets priority classes on components
             */
            priorityClassNames?: {[key: string]: any};
            /**
             * Remove the OSD that is out and safe to remove only if this option is true
             */
            removeOSDsIfOutAndSafeToRemove?: boolean;
            /**
             * Resources set resource requests and limits
             */
            resources?: {[key: string]: any};
            /**
             * Security represents security settings
             */
            security?: outputs.ceph.v1.CephClusterSpecSecurity;
            /**
             * SkipUpgradeChecks defines if an upgrade should be forced even if one of the check fails
             */
            skipUpgradeChecks?: boolean;
            /**
             * A spec for available storage in the cluster and how it should be used
             */
            storage?: outputs.ceph.v1.CephClusterSpecStorage;
            /**
             * WaitTimeoutForHealthyOSDInMinutes defines the time the operator would wait before an OSD can be stopped for upgrade or restart. If the timeout exceeds and OSD is not ok to stop, then the operator would skip upgrade for the current OSD and proceed with the next one if `continueUpgradeAfterChecksEvenIfNotHealthy` is `false`. If `continueUpgradeAfterChecksEvenIfNotHealthy` is `true`, then operator would continue with the upgrade of an OSD even if its not ok to stop after the timeout. This timeout won't be applied if `skipUpgradeChecks` is `true`. The default wait timeout is 10 minutes.
             */
            waitTimeoutForHealthyOSDInMinutes?: number;
        }

        /**
         * The version information that instructs Rook to orchestrate a particular version of Ceph.
         */
        export interface CephClusterSpecCephversion {
            /**
             * Whether to allow unsupported versions (do not set to true in production)
             */
            allowUnsupported?: boolean;
            /**
             * Image is the container image used to launch the ceph daemons, such as quay.io/ceph/ceph:<tag> The full list of images can be found at https://quay.io/repository/ceph/ceph?tab=tags
             */
            image?: string;
            /**
             * ImagePullPolicy describes a policy for if/when to pull a container image One of Always, Never, IfNotPresent.
             */
            imagePullPolicy?: string;
        }

        /**
         * Indicates user intent when deleting a cluster; blocks orchestration and should not be set if cluster deletion is not imminent.
         */
        export interface CephClusterSpecCleanuppolicy {
            /**
             * AllowUninstallWithVolumes defines whether we can proceed with the uninstall if they are RBD images still present
             */
            allowUninstallWithVolumes?: boolean;
            /**
             * Confirmation represents the cleanup confirmation
             */
            confirmation?: string;
            /**
             * SanitizeDisks represents way we sanitize disks
             */
            sanitizeDisks?: outputs.ceph.v1.CephClusterSpecCleanuppolicySanitizedisks;
        }

        /**
         * SanitizeDisks represents way we sanitize disks
         */
        export interface CephClusterSpecCleanuppolicySanitizedisks {
            /**
             * DataSource is the data source to use to sanitize the disk with
             */
            dataSource?: string;
            /**
             * Iteration is the number of pass to apply the sanitizing
             */
            iteration?: number;
            /**
             * Method is the method we use to sanitize disks
             */
            method?: string;
        }

        /**
         * A spec for the crash controller
         */
        export interface CephClusterSpecCrashcollector {
            /**
             * DaysToRetain represents the number of days to retain crash until they get pruned
             */
            daysToRetain?: number;
            /**
             * Disable determines whether we should enable the crash collector
             */
            disable?: boolean;
        }

        /**
         * Dashboard settings
         */
        export interface CephClusterSpecDashboard {
            /**
             * Enabled determines whether to enable the dashboard
             */
            enabled?: boolean;
            /**
             * Port is the dashboard webserver port
             */
            port?: number;
            /**
             * SSL determines whether SSL should be used
             */
            ssl?: boolean;
            /**
             * URLPrefix is a prefix for all URLs to use the dashboard with a reverse proxy
             */
            urlPrefix?: string;
        }

        /**
         * A spec for configuring disruption management.
         */
        export interface CephClusterSpecDisruptionmanagement {
            /**
             * Namespace to look for MDBs by the machineDisruptionBudgetController
             */
            machineDisruptionBudgetNamespace?: string;
            /**
             * This enables management of machinedisruptionbudgets
             */
            manageMachineDisruptionBudgets?: boolean;
            /**
             * This enables management of poddisruptionbudgets
             */
            managePodBudgets?: boolean;
            /**
             * OSDMaintenanceTimeout sets how many additional minutes the DOWN/OUT interval is for drained failure domains it only works if managePodBudgets is true. the default is 30 minutes
             */
            osdMaintenanceTimeout?: number;
            /**
             * PGHealthCheckTimeout is the time (in minutes) that the operator will wait for the placement groups to become healthy (active+clean) after a drain was completed and OSDs came back up. Rook will continue with the next drain if the timeout exceeds. It only works if managePodBudgets is true. No values or 0 means that the operator will wait until the placement groups are healthy before unblocking the next drain.
             */
            pgHealthCheckTimeout?: number;
        }

        /**
         * Internal daemon healthchecks and liveness probe
         */
        export interface CephClusterSpecHealthcheck {
            /**
             * DaemonHealth is the health check for a given daemon
             */
            daemonHealth?: outputs.ceph.v1.CephClusterSpecHealthcheckDaemonhealth;
            /**
             * LivenessProbe allows changing the livenessProbe configuration for a given daemon
             */
            livenessProbe?: {[key: string]: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobe};
            /**
             * StartupProbe allows changing the startupProbe configuration for a given daemon
             */
            startupProbe?: {[key: string]: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobe};
        }

        /**
         * DaemonHealth is the health check for a given daemon
         */
        export interface CephClusterSpecHealthcheckDaemonhealth {
            /**
             * Monitor represents the health check settings for the Ceph monitor
             */
            mon?: outputs.ceph.v1.CephClusterSpecHealthcheckDaemonhealthMon;
            /**
             * ObjectStorageDaemon represents the health check settings for the Ceph OSDs
             */
            osd?: outputs.ceph.v1.CephClusterSpecHealthcheckDaemonhealthOsd;
            /**
             * Status represents the health check settings for the Ceph health
             */
            status?: outputs.ceph.v1.CephClusterSpecHealthcheckDaemonhealthStatus;
        }

        /**
         * Monitor represents the health check settings for the Ceph monitor
         */
        export interface CephClusterSpecHealthcheckDaemonhealthMon {
            disabled?: boolean;
            /**
             * Interval is the internal in second or minute for the health check to run like 60s for 60 seconds
             */
            interval?: string;
            timeout?: string;
        }

        /**
         * ObjectStorageDaemon represents the health check settings for the Ceph OSDs
         */
        export interface CephClusterSpecHealthcheckDaemonhealthOsd {
            disabled?: boolean;
            /**
             * Interval is the internal in second or minute for the health check to run like 60s for 60 seconds
             */
            interval?: string;
            timeout?: string;
        }

        /**
         * Status represents the health check settings for the Ceph health
         */
        export interface CephClusterSpecHealthcheckDaemonhealthStatus {
            disabled?: boolean;
            /**
             * Interval is the internal in second or minute for the health check to run like 60s for 60 seconds
             */
            interval?: string;
            timeout?: string;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephClusterSpecHealthcheckLivenessprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephClusterSpecHealthcheckLivenessprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephClusterSpecHealthcheckLivenessprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephClusterSpecHealthcheckLivenessprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephClusterSpecHealthcheckLivenessprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephClusterSpecHealthcheckLivenessprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephClusterSpecHealthcheckLivenessprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephClusterSpecHealthcheckLivenessprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephClusterSpecHealthcheckStartupprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephClusterSpecHealthcheckStartupprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephClusterSpecHealthcheckStartupprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephClusterSpecHealthcheckStartupprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephClusterSpecHealthcheckStartupprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephClusterSpecHealthcheckStartupprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephClusterSpecHealthcheckStartupprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephClusterSpecHealthcheckStartupprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * Logging represents loggings settings
         */
        export interface CephClusterSpecLogcollector {
            /**
             * Enabled represents whether the log collector is enabled
             */
            enabled?: boolean;
            /**
             * MaxLogSize is the maximum size of the log per ceph daemons. Must be at least 1M.
             */
            maxLogSize?: number | string;
            /**
             * Periodicity is the periodicity of the log rotation.
             */
            periodicity?: string;
        }

        /**
         * A spec for mgr related options
         */
        export interface CephClusterSpecMgr {
            /**
             * AllowMultiplePerNode allows to run multiple managers on the same node (not recommended)
             */
            allowMultiplePerNode?: boolean;
            /**
             * Count is the number of manager to run
             */
            count?: number;
            /**
             * Modules is the list of ceph manager modules to enable/disable
             */
            modules?: outputs.ceph.v1.CephClusterSpecMgrModules[];
        }

        /**
         * Module represents mgr modules that the user wants to enable or disable
         */
        export interface CephClusterSpecMgrModules {
            /**
             * Enabled determines whether a module should be enabled or not
             */
            enabled?: boolean;
            /**
             * Name is the name of the ceph manager module
             */
            name?: string;
        }

        /**
         * A spec for mon related options
         */
        export interface CephClusterSpecMon {
            /**
             * AllowMultiplePerNode determines if we can run multiple monitors on the same node (not recommended)
             */
            allowMultiplePerNode?: boolean;
            /**
             * Count is the number of Ceph monitors
             */
            count?: number;
            /**
             * StretchCluster is the stretch cluster specification
             */
            stretchCluster?: outputs.ceph.v1.CephClusterSpecMonStretchcluster;
            /**
             * VolumeClaimTemplate is the PVC definition
             */
            volumeClaimTemplate?: {[key: string]: any};
        }

        /**
         * StretchCluster is the stretch cluster specification
         */
        export interface CephClusterSpecMonStretchcluster {
            /**
             * FailureDomainLabel the failure domain name (e,g: zone)
             */
            failureDomainLabel?: string;
            /**
             * SubFailureDomain is the failure domain within a zone
             */
            subFailureDomain?: string;
            /**
             * Zones is the list of zones
             */
            zones?: outputs.ceph.v1.CephClusterSpecMonStretchclusterZones[];
        }

        /**
         * StretchClusterZoneSpec represents the specification of a stretched zone in a Ceph Cluster
         */
        export interface CephClusterSpecMonStretchclusterZones {
            /**
             * Arbiter determines if the zone contains the arbiter
             */
            arbiter?: boolean;
            /**
             * Name is the name of the zone
             */
            name?: string;
            /**
             * VolumeClaimTemplate is the PVC template
             */
            volumeClaimTemplate?: {[key: string]: any};
        }

        /**
         * Prometheus based Monitoring settings
         */
        export interface CephClusterSpecMonitoring {
            /**
             * Enabled determines whether to create the prometheus rules for the ceph cluster. If true, the prometheus types must exist or the creation will fail.
             */
            enabled?: boolean;
            /**
             * ExternalMgrEndpoints points to an existing Ceph prometheus exporter endpoint
             */
            externalMgrEndpoints?: outputs.ceph.v1.CephClusterSpecMonitoringExternalmgrendpoints[];
            /**
             * ExternalMgrPrometheusPort Prometheus exporter port
             */
            externalMgrPrometheusPort?: number;
        }

        /**
         * EndpointAddress is a tuple that describes single IP address.
         */
        export interface CephClusterSpecMonitoringExternalmgrendpoints {
            /**
             * The Hostname of this endpoint
             */
            hostname?: string;
            /**
             * The IP of this endpoint. May not be loopback (127.0.0.0/8), link-local (169.254.0.0/16), or link-local multicast ((224.0.0.0/24). IPv6 is also accepted but not fully supported on all platforms. Also, certain kubernetes components, like kube-proxy, are not IPv6 ready. TODO: This should allow hostname or IP, See #4447.
             */
            ip: string;
            /**
             * Optional: Node hosting this endpoint. This can be used to determine endpoints local to a node.
             */
            nodeName?: string;
            /**
             * Reference to object providing the endpoint.
             */
            targetRef?: outputs.ceph.v1.CephClusterSpecMonitoringExternalmgrendpointsTargetref;
        }

        /**
         * Reference to object providing the endpoint.
         */
        export interface CephClusterSpecMonitoringExternalmgrendpointsTargetref {
            /**
             * API version of the referent.
             */
            apiVersion?: string;
            /**
             * If referring to a piece of an object instead of an entire object, this string should contain a valid JSON/Go field access statement, such as desiredState.manifest.containers[2]. For example, if the object reference is to a container within a pod, this would take on a value like: "spec.containers{name}" (where "name" refers to the name of the container that triggered the event) or if no container name is specified "spec.containers[2]" (container with index 2 in this pod). This syntax is chosen only to have some well-defined way of referencing a part of an object. TODO: this design is not final and this field is subject to change in the future.
             */
            fieldPath?: string;
            /**
             * Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name?: string;
            /**
             * Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
             */
            namespace?: string;
            /**
             * Specific resourceVersion to which this reference is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
             */
            resourceVersion?: string;
            /**
             * UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids
             */
            uid?: string;
        }

        /**
         * Security represents security settings
         */
        export interface CephClusterSpecSecurity {
            /**
             * KeyManagementService is the main Key Management option
             */
            kms?: outputs.ceph.v1.CephClusterSpecSecurityKms;
        }

        /**
         * KeyManagementService is the main Key Management option
         */
        export interface CephClusterSpecSecurityKms {
            /**
             * ConnectionDetails contains the KMS connection details (address, port etc)
             */
            connectionDetails?: {[key: string]: any};
            /**
             * TokenSecretName is the kubernetes secret containing the KMS token
             */
            tokenSecretName?: string;
        }

        /**
         * A spec for available storage in the cluster and how it should be used
         */
        export interface CephClusterSpecStorage {
            config?: {[key: string]: any};
            /**
             * A regular expression to allow more fine-grained selection of devices on nodes across the cluster
             */
            deviceFilter?: string;
            /**
             * A regular expression to allow more fine-grained selection of devices with path names
             */
            devicePathFilter?: string;
            /**
             * List of devices to use as storage devices
             */
            devices?: {[key: string]: any};
            nodes?: outputs.ceph.v1.CephClusterSpecStorageNodes[];
            onlyApplyOSDPlacement?: boolean;
            storageClassDeviceSets?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesets[];
            /**
             * Whether to consume all the storage devices found on a machine
             */
            useAllDevices?: boolean;
            useAllNodes?: boolean;
            /**
             * PersistentVolumeClaims to use as storage
             */
            volumeClaimTemplates?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplates[];
        }

        /**
         * Node is a storage nodes
         */
        export interface CephClusterSpecStorageNodes {
            config?: {[key: string]: any};
            /**
             * A regular expression to allow more fine-grained selection of devices on nodes across the cluster
             */
            deviceFilter?: string;
            /**
             * A regular expression to allow more fine-grained selection of devices with path names
             */
            devicePathFilter?: string;
            /**
             * List of devices to use as storage devices
             */
            devices?: {[key: string]: any};
            name?: string;
            /**
             * ResourceRequirements describes the compute resource requirements.
             */
            resources?: {[key: string]: any};
            /**
             * Whether to consume all the storage devices found on a machine
             */
            useAllDevices?: boolean;
            /**
             * PersistentVolumeClaims to use as storage
             */
            volumeClaimTemplates?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplates[];
        }

        /**
         * PersistentVolumeClaim is a user's request for and claim to a persistent volume
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplates {
            /**
             * APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
             */
            apiVersion?: string;
            /**
             * Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
             */
            metadata?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesMetadata;
            /**
             * spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            spec?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesSpec;
            /**
             * status represents the current information/status of a persistent volume claim. R"ead-only. More info: https"://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            status?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesStatus;
        }

        /**
         * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * status represents the current information/status of a persistent volume claim. R"ead-only. More info: https"://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesStatus {
            /**
             * accessModes contains the actual access modes the volume backing the PVC has. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * allocatedResources is the storage resource within AllocatedResources tracks the capacity allocated to a PVC. It may be larger than the actual capacity when a volume expansion operation is requested. For storage quota, the larger value from allocatedResources and PVC.spec.resources is used. If allocatedResources is not set, PVC.spec.resources alone is used for quota calculation. If a volume expansion capacity request is lowered, allocatedResources is only lowered if there are no expansion operations in progress and if the actual volume capacity is equal or lower than the requested capacity. This is an alpha field and requires enabling RecoverVolumeExpansionFailure feature.
             */
            allocatedResources?: {[key: string]: number | string};
            /**
             * capacity represents the actual resources of the underlying volume.
             */
            capacity?: {[key: string]: number | string};
            /**
             * conditions is the current Condition of persistent volume claim. If underlying persistent volume is being resized then the Condition will be set to 'ResizeStarted'.
             */
            conditions?: outputs.ceph.v1.CephClusterSpecStorageNodesVolumeclaimtemplatesStatusConditions[];
            /**
             * phase represents the current phase of PersistentVolumeClaim.
             */
            phase?: string;
            /**
             * resizeStatus stores status of resize operation. ResizeStatus is not set by default but when expansion is complete resizeStatus is set to empty string by resize controller or kubelet. This is an alpha field and requires enabling RecoverVolumeExpansionFailure feature.
             */
            resizeStatus?: string;
        }

        /**
         * PersistentVolumeClaimCondition contails details about state of pvc
         */
        export interface CephClusterSpecStorageNodesVolumeclaimtemplatesStatusConditions {
            /**
             * lastProbeTime is the time we probed the condition.
             */
            lastProbeTime?: string;
            /**
             * lastTransitionTime is the time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * message is the human-readable message indicating details about last transition.
             */
            message?: string;
            /**
             * reason is a unique, this should be a short, machine understandable string that gives the reason for condition's last transition. If it reports "ResizeStarted" that means the underlying persistent volume is being resized.
             */
            reason?: string;
            status: string;
            /**
             * PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
             */
            type: string;
        }

        /**
         * StorageClassDeviceSet is a storage class device set
         */
        export interface CephClusterSpecStorageStorageclassdevicesets {
            /**
             * Provider-specific device configuration
             */
            config?: {[key: string]: any};
            /**
             * Count is the number of devices in this set
             */
            count: number;
            /**
             * Whether to encrypt the deviceSet
             */
            encrypted?: boolean;
            /**
             * Name is a unique identifier for the set
             */
            name: string;
            /**
             * Placement is the placement for an object
             */
            placement?: {[key: string]: any};
            /**
             * Portable represents OSD portability across the hosts
             */
            portable?: boolean;
            /**
             * Placement is the placement for an object
             */
            preparePlacement?: {[key: string]: any};
            /**
             * ResourceRequirements describes the compute resource requirements.
             */
            resources?: {[key: string]: any};
            /**
             * Scheduler name for OSD pod placement
             */
            schedulerName?: string;
            /**
             * TuneSlowDeviceClass Tune the OSD when running on a slow Device Class
             */
            tuneDeviceClass?: boolean;
            /**
             * TuneFastDeviceClass Tune the OSD when running on a fast Device Class
             */
            tuneFastDeviceClass?: boolean;
            /**
             * VolumeClaimTemplates is a list of PVC templates for the underlying storage devices
             */
            volumeClaimTemplates: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplates[];
        }

        /**
         * PersistentVolumeClaim is a user's request for and claim to a persistent volume
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplates {
            /**
             * APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
             */
            apiVersion?: string;
            /**
             * Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
             */
            metadata?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesMetadata;
            /**
             * spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            spec?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpec;
            /**
             * status represents the current information/status of a persistent volume claim. R"ead-only. More info: https"://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            status?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesStatus;
        }

        /**
         * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesMetadata {
            annotations?: {[key: string]: any};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * status represents the current information/status of a persistent volume claim. R"ead-only. More info: https"://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesStatus {
            /**
             * accessModes contains the actual access modes the volume backing the PVC has. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * allocatedResources is the storage resource within AllocatedResources tracks the capacity allocated to a PVC. It may be larger than the actual capacity when a volume expansion operation is requested. For storage quota, the larger value from allocatedResources and PVC.spec.resources is used. If allocatedResources is not set, PVC.spec.resources alone is used for quota calculation. If a volume expansion capacity request is lowered, allocatedResources is only lowered if there are no expansion operations in progress and if the actual volume capacity is equal or lower than the requested capacity. This is an alpha field and requires enabling RecoverVolumeExpansionFailure feature.
             */
            allocatedResources?: {[key: string]: number | string};
            /**
             * capacity represents the actual resources of the underlying volume.
             */
            capacity?: {[key: string]: number | string};
            /**
             * conditions is the current Condition of persistent volume claim. If underlying persistent volume is being resized then the Condition will be set to 'ResizeStarted'.
             */
            conditions?: outputs.ceph.v1.CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesStatusConditions[];
            /**
             * phase represents the current phase of PersistentVolumeClaim.
             */
            phase?: string;
            /**
             * resizeStatus stores status of resize operation. ResizeStatus is not set by default but when expansion is complete resizeStatus is set to empty string by resize controller or kubelet. This is an alpha field and requires enabling RecoverVolumeExpansionFailure feature.
             */
            resizeStatus?: string;
        }

        /**
         * PersistentVolumeClaimCondition contails details about state of pvc
         */
        export interface CephClusterSpecStorageStorageclassdevicesetsVolumeclaimtemplatesStatusConditions {
            /**
             * lastProbeTime is the time we probed the condition.
             */
            lastProbeTime?: string;
            /**
             * lastTransitionTime is the time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * message is the human-readable message indicating details about last transition.
             */
            message?: string;
            /**
             * reason is a unique, this should be a short, machine understandable string that gives the reason for condition's last transition. If it reports "ResizeStarted" that means the underlying persistent volume is being resized.
             */
            reason?: string;
            status: string;
            /**
             * PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
             */
            type: string;
        }

        /**
         * PersistentVolumeClaim is a user's request for and claim to a persistent volume
         */
        export interface CephClusterSpecStorageVolumeclaimtemplates {
            /**
             * APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
             */
            apiVersion?: string;
            /**
             * Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
             */
            metadata?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesMetadata;
            /**
             * spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            spec?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesSpec;
            /**
             * status represents the current information/status of a persistent volume claim. R"ead-only. More info: https"://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            status?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesStatus;
        }

        /**
         * Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * status represents the current information/status of a persistent volume claim. R"ead-only. More info: https"://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesStatus {
            /**
             * accessModes contains the actual access modes the volume backing the PVC has. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * allocatedResources is the storage resource within AllocatedResources tracks the capacity allocated to a PVC. It may be larger than the actual capacity when a volume expansion operation is requested. For storage quota, the larger value from allocatedResources and PVC.spec.resources is used. If allocatedResources is not set, PVC.spec.resources alone is used for quota calculation. If a volume expansion capacity request is lowered, allocatedResources is only lowered if there are no expansion operations in progress and if the actual volume capacity is equal or lower than the requested capacity. This is an alpha field and requires enabling RecoverVolumeExpansionFailure feature.
             */
            allocatedResources?: {[key: string]: number | string};
            /**
             * capacity represents the actual resources of the underlying volume.
             */
            capacity?: {[key: string]: number | string};
            /**
             * conditions is the current Condition of persistent volume claim. If underlying persistent volume is being resized then the Condition will be set to 'ResizeStarted'.
             */
            conditions?: outputs.ceph.v1.CephClusterSpecStorageVolumeclaimtemplatesStatusConditions[];
            /**
             * phase represents the current phase of PersistentVolumeClaim.
             */
            phase?: string;
            /**
             * resizeStatus stores status of resize operation. ResizeStatus is not set by default but when expansion is complete resizeStatus is set to empty string by resize controller or kubelet. This is an alpha field and requires enabling RecoverVolumeExpansionFailure feature.
             */
            resizeStatus?: string;
        }

        /**
         * PersistentVolumeClaimCondition contails details about state of pvc
         */
        export interface CephClusterSpecStorageVolumeclaimtemplatesStatusConditions {
            /**
             * lastProbeTime is the time we probed the condition.
             */
            lastProbeTime?: string;
            /**
             * lastTransitionTime is the time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * message is the human-readable message indicating details about last transition.
             */
            message?: string;
            /**
             * reason is a unique, this should be a short, machine understandable string that gives the reason for condition's last transition. If it reports "ResizeStarted" that means the underlying persistent volume is being resized.
             */
            reason?: string;
            status: string;
            /**
             * PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
             */
            type: string;
        }

        /**
         * FilesystemMirroringSpec is the filesystem mirroring specification
         */
        export interface CephFilesystemMirrorSpec {
            /**
             * The annotations-related configuration to add/set on each Pod related object.
             */
            annotations?: {[key: string]: string};
            /**
             * The labels-related configuration to add/set on each Pod related object.
             */
            labels?: {[key: string]: string};
            /**
             * The affinity to place the rgw pods (default is to place on any available node)
             */
            placement?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacement;
            /**
             * PriorityClassName sets priority class on the cephfs-mirror pods
             */
            priorityClassName?: string;
            /**
             * The resource requirements for the cephfs-mirror pods
             */
            resources?: outputs.ceph.v1.CephFilesystemMirrorSpecResources;
        }

        /**
         * The affinity to place the rgw pods (default is to place on any available node)
         */
        export interface CephFilesystemMirrorSpecPlacement {
            /**
             * NodeAffinity is a group of node affinity scheduling rules
             */
            nodeAffinity?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinity;
            /**
             * PodAffinity is a group of inter pod affinity scheduling rules
             */
            podAffinity?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinity;
            /**
             * PodAntiAffinity is a group of inter pod anti affinity scheduling rules
             */
            podAntiAffinity?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinity;
            /**
             * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>
             */
            tolerations?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementTolerations[];
            /**
             * TopologySpreadConstraint specifies how to spread matching pods among the given topology
             */
            topologySpreadConstraints?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementTopologyspreadconstraints[];
        }

        /**
         * NodeAffinity is a group of node affinity scheduling rules
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * PodAffinity is a group of inter pod affinity scheduling rules
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * PodAntiAffinity is a group of inter pod anti affinity scheduling rules
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface CephFilesystemMirrorSpecPlacementTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * TopologySpreadConstraint specifies how to spread matching pods among the given topology.
         */
        export interface CephFilesystemMirrorSpecPlacementTopologyspreadconstraints {
            /**
             * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
             */
            labelSelector?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementTopologyspreadconstraintsLabelselector;
            /**
             * MaxSkew describes the degree to which pods may be unevenly distributed. When `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference between the number of matching pods in the target topology and the global minimum. The global minimum is the minimum number of matching pods in an eligible domain or zero if the number of eligible domains is less than MinDomains. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 2/2/1: In this case, the global minimum is 1. | zone1 | zone2 | zone3 | |  P P  |  P P  |   P   |  if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2; scheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. When `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence to topologies that satisfy it. It's a required field. Default value is 1 and 0 is not allowed.
             */
            maxSkew: number;
            /**
             * MinDomains indicates a minimum number of eligible domains. When the number of eligible domains with matching topology keys is less than minDomains, Pod Topology Spread treats "global minimum" as 0, and then the calculation of Skew is performed. And when the number of eligible domains with matching topology keys equals or greater than minDomains, this value has no effect on scheduling. As a result, when the number of eligible domains is less than minDomains, scheduler won't schedule more than maxSkew Pods to those domains. If value is nil, the constraint behaves as if MinDomains is equal to 1. Valid values are integers greater than 0. When value is not nil, WhenUnsatisfiable must be DoNotSchedule. 
             *  For example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same labelSelector spread as 2/2/2: | zone1 | zone2 | zone3 | |  P P  |  P P  |  P P  | The number of domains is less than 5(MinDomains), so "global minimum" is treated as 0. In this situation, new pod with the same labelSelector cannot be scheduled, because computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones, it will violate MaxSkew. 
             *  This is an alpha field and requires enabling MinDomainsInPodTopologySpread feature gate.
             */
            minDomains?: number;
            /**
             * TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. We define a domain as a particular instance of a topology. Also, we define an eligible domain as a domain whose nodes match the node selector. e.g. If TopologyKey is "kubernetes.io/hostname", each Node is a domain of that topology. And, if TopologyKey is "topology.kubernetes.io/zone", each zone is a domain of that topology. It's a required field.
             */
            topologyKey: string;
            /**
             * WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it. - ScheduleAnyway tells the scheduler to schedule the pod in any location,   but giving higher precedence to topologies that would help reduce the   skew. A constraint is considered "Unsatisfiable" for an incoming pod if and only if every possible node assignment for that pod would violate "MaxSkew" on some topology. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: | zone1 | zone2 | zone3 | | P P P |   P   |   P   | If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.
             */
            whenUnsatisfiable: string;
        }

        /**
         * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
         */
        export interface CephFilesystemMirrorSpecPlacementTopologyspreadconstraintsLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephFilesystemMirrorSpecPlacementTopologyspreadconstraintsLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephFilesystemMirrorSpecPlacementTopologyspreadconstraintsLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The resource requirements for the cephfs-mirror pods
         */
        export interface CephFilesystemMirrorSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * Status represents the status of an object
         */
        export interface CephFilesystemMirrorStatus {
            conditions?: outputs.ceph.v1.CephFilesystemMirrorStatusConditions[];
            /**
             * ObservedGeneration is the latest generation observed by the controller.
             */
            observedGeneration?: number;
            phase?: string;
        }

        /**
         * Condition represents a status condition on any Rook-Ceph Custom Resource.
         */
        export interface CephFilesystemMirrorStatusConditions {
            lastHeartbeatTime?: string;
            lastTransitionTime?: string;
            message?: string;
            /**
             * ConditionReason is a reason for a condition
             */
            reason?: string;
            status?: string;
            /**
             * ConditionType represent a resource's status
             */
            type?: string;
        }

        /**
         * FilesystemSpec represents the spec of a file system
         */
        export interface CephFilesystemSpec {
            /**
             * The data pool settings, with optional predefined pool name.
             */
            dataPools: outputs.ceph.v1.CephFilesystemSpecDatapools[];
            /**
             * The metadata pool settings
             */
            metadataPool: outputs.ceph.v1.CephFilesystemSpecMetadatapool;
            /**
             * The mds pod info
             */
            metadataServer: outputs.ceph.v1.CephFilesystemSpecMetadataserver;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephFilesystemSpecMirroring;
            /**
             * Preserve the fs in the cluster on CephFilesystem CR deletion. Setting this to true automatically implies PreservePoolsOnDelete is true.
             */
            preserveFilesystemOnDelete?: boolean;
            /**
             * Preserve pools on filesystem deletion
             */
            preservePoolsOnDelete?: boolean;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * NamedPoolSpec represents the named ceph pool spec
         */
        export interface CephFilesystemSpecDatapools {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephFilesystemSpecDatapoolsErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephFilesystemSpecDatapoolsMirroring;
            /**
             * Name of the pool
             */
            name?: string;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephFilesystemSpecDatapoolsQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephFilesystemSpecDatapoolsReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephFilesystemSpecDatapoolsErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephFilesystemSpecDatapoolsMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephFilesystemSpecDatapoolsMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephFilesystemSpecDatapoolsMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephFilesystemSpecDatapoolsMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephFilesystemSpecDatapoolsMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephFilesystemSpecDatapoolsQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephFilesystemSpecDatapoolsReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephFilesystemSpecDatapoolsReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephFilesystemSpecDatapoolsReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * The metadata pool settings
         */
        export interface CephFilesystemSpecMetadatapool {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolMirroring;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephFilesystemSpecMetadatapoolErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephFilesystemSpecMetadatapoolMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephFilesystemSpecMetadatapoolMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephFilesystemSpecMetadatapoolMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephFilesystemSpecMetadatapoolQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephFilesystemSpecMetadatapoolReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephFilesystemSpecMetadatapoolReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephFilesystemSpecMetadatapoolReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * The mds pod info
         */
        export interface CephFilesystemSpecMetadataserver {
            /**
             * The number of metadata servers that are active. The remaining servers in the cluster will be in standby mode.
             */
            activeCount: number;
            /**
             * Whether each active MDS instance will have an active standby with a warm metadata cache for faster failover. If false, standbys will still be available, but will not have a warm metadata cache.
             */
            activeStandby?: boolean;
            /**
             * The annotations-related configuration to add/set on each Pod related object.
             */
            annotations?: {[key: string]: any};
            /**
             * The labels-related configuration to add/set on each Pod related object.
             */
            labels?: {[key: string]: any};
            /**
             * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
             */
            livenessProbe?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobe;
            /**
             * The affinity to place the mds pods (default is to place on all available node) with a daemonset
             */
            placement?: {[key: string]: any};
            /**
             * PriorityClassName sets priority classes on components
             */
            priorityClassName?: string;
            /**
             * The resource requirements for the rgw pods
             */
            resources?: {[key: string]: any};
            /**
             * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
             */
            startupProbe?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobe;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephFilesystemSpecMetadataserverLivenessprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephFilesystemSpecMetadataserverLivenessprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephFilesystemSpecMetadataserverStartupprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephFilesystemSpecMetadataserverStartupprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephFilesystemSpecMetadataserverStartupprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephFilesystemSpecMetadataserverStartupprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephFilesystemSpecMetadataserverStartupprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephFilesystemSpecMetadataserverStartupprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephFilesystemSpecMetadataserverStartupprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephFilesystemSpecMetadataserverStartupprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * The mirroring settings
         */
        export interface CephFilesystemSpecMirroring {
            /**
             * Enabled whether this filesystem is mirrored or not
             */
            enabled?: boolean;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephFilesystemSpecMirroringPeers;
            /**
             * Retention is the retention policy for a snapshot schedule One path has exactly one retention policy. A policy can however contain multiple count-time period pairs in order to specify complex retention policies
             */
            snapshotRetention?: outputs.ceph.v1.CephFilesystemSpecMirroringSnapshotretention[];
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored filesystems
             */
            snapshotSchedules?: outputs.ceph.v1.CephFilesystemSpecMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephFilesystemSpecMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleRetentionSpec is a retention policy
         */
        export interface CephFilesystemSpecMirroringSnapshotretention {
            /**
             * Duration represents the retention duration for a snapshot
             */
            duration?: string;
            /**
             * Path is the path to snapshot
             */
            path?: string;
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephFilesystemSpecMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * Spec represents the specification of a Ceph Filesystem SubVolumeGroup
         */
        export interface CephFilesystemSubVolumeGroupSpec {
            /**
             * FilesystemName is the name of Ceph Filesystem SubVolumeGroup volume name. Typically it's the name of the CephFilesystem CR. If not coming from the CephFilesystem CR, it can be retrieved from the list of Ceph Filesystem volumes with `ceph fs volume ls`. To learn more about Ceph Filesystem abstractions see https://docs.ceph.com/en/latest/cephfs/fs-volumes/#fs-volumes-and-subvolumes
             */
            filesystemName: string;
        }

        /**
         * NFSGaneshaSpec represents the spec of an nfs ganesha server
         */
        export interface CephNFSSpec {
            /**
             * RADOS is the Ganesha RADOS specification
             */
            rados?: outputs.ceph.v1.CephNFSSpecRados;
            /**
             * Security allows specifying security configurations for the NFS cluster
             */
            security?: outputs.ceph.v1.CephNFSSpecSecurity;
            /**
             * Server is the Ganesha Server specification
             */
            server: outputs.ceph.v1.CephNFSSpecServer;
        }
        /**
         * cephNFSSpecProvideDefaults sets the appropriate defaults for CephNFSSpec
         */
        export function cephNFSSpecProvideDefaults(val: CephNFSSpec): CephNFSSpec {
            return {
                ...val,
                security: (val.security ? outputs.ceph.v1.cephNFSSpecSecurityProvideDefaults(val.security) : undefined),
            };
        }

        /**
         * RADOS is the Ganesha RADOS specification
         */
        export interface CephNFSSpecRados {
            /**
             * The namespace inside the Ceph pool (set by 'pool') where shared NFS-Ganesha config is stored. This setting is required for Ceph v15 and ignored for Ceph v16. As of Ceph Pacific v16+, this is internally set to the name of the CephNFS.
             */
            namespace?: string;
            /**
             * The Ceph pool used store the shared configuration for NFS-Ganesha daemons. This setting is required for Ceph v15 and ignored for Ceph v16. As of Ceph Pacific 16.2.7+, this is internally hardcoded to ".nfs".
             */
            pool?: string;
        }

        /**
         * Security allows specifying security configurations for the NFS cluster
         */
        export interface CephNFSSpecSecurity {
            /**
             * Kerberos configures NFS-Ganesha to secure NFS client connections with Kerberos.
             */
            kerberos?: outputs.ceph.v1.CephNFSSpecSecurityKerberos;
            /**
             * SSSD enables integration with System Security Services Daemon (SSSD). SSSD can be used to provide user ID mapping from a number of sources. See https://sssd.io for more information about the SSSD project.
             */
            sssd?: outputs.ceph.v1.CephNFSSpecSecuritySssd;
        }
        /**
         * cephNFSSpecSecurityProvideDefaults sets the appropriate defaults for CephNFSSpecSecurity
         */
        export function cephNFSSpecSecurityProvideDefaults(val: CephNFSSpecSecurity): CephNFSSpecSecurity {
            return {
                ...val,
                kerberos: (val.kerberos ? outputs.ceph.v1.cephNFSSpecSecurityKerberosProvideDefaults(val.kerberos) : undefined),
            };
        }

        /**
         * Kerberos configures NFS-Ganesha to secure NFS client connections with Kerberos.
         */
        export interface CephNFSSpecSecurityKerberos {
            /**
             * ConfigFiles defines where the Kerberos configuration should be sourced from. Config files will be placed into the `/etc/krb5.conf.rook/` directory. 
             *  If this is left empty, Rook will not add any files. This allows you to manage the files yourself however you wish. For example, you may build them into your custom Ceph container image or use the Vault agent injector to securely add the files via annotations on the CephNFS spec (passed to the NFS server pods). 
             *  Rook configures Kerberos to log to stderr. We suggest removing logging sections from config files to avoid consuming unnecessary disk space from logging to files.
             */
            configFiles?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfiles;
            /**
             * KeytabFile defines where the Kerberos keytab should be sourced from. The keytab file will be placed into `/etc/krb5.keytab`. If this is left empty, Rook will not add the file. This allows you to manage the `krb5.keytab` file yourself however you wish. For example, you may build it into your custom Ceph container image or use the Vault agent injector to securely add the file via annotations on the CephNFS spec (passed to the NFS server pods).
             */
            keytabFile?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfile;
            /**
             * PrincipalName corresponds directly to NFS-Ganesha's NFS_KRB5:PrincipalName config. In practice, this is the service prefix of the principal name. The default is "nfs". This value is combined with (a) the namespace and name of the CephNFS (with a hyphen between) and (b) the Realm configured in the "user-provided krb5.conf to determine the full principal name: <principalName>/<namespace>-<name>@<realm>. e.g., nfs/rook-ceph-my-nfs@example.net. See https"://github.com/nfs-ganesha/nfs-ganesha/wiki/RPCSEC_GSS for more detail.
             */
            principalName?: string;
        }
        /**
         * cephNFSSpecSecurityKerberosProvideDefaults sets the appropriate defaults for CephNFSSpecSecurityKerberos
         */
        export function cephNFSSpecSecurityKerberosProvideDefaults(val: CephNFSSpecSecurityKerberos): CephNFSSpecSecurityKerberos {
            return {
                ...val,
                principalName: (val.principalName) ?? "nfs",
            };
        }

        /**
         * ConfigFiles defines where the Kerberos configuration should be sourced from. Config files will be placed into the `/etc/krb5.conf.rook/` directory. 
         *  If this is left empty, Rook will not add any files. This allows you to manage the files yourself however you wish. For example, you may build them into your custom Ceph container image or use the Vault agent injector to securely add the files via annotations on the CephNFS spec (passed to the NFS server pods). 
         *  Rook configures Kerberos to log to stderr. We suggest removing logging sections from config files to avoid consuming unnecessary disk space from logging to files.
         */
        export interface CephNFSSpecSecurityKerberosConfigfiles {
            /**
             * VolumeSource accepts a standard Kubernetes VolumeSource for Kerberos configuration files like what is normally used to configure Volumes for a Pod. For example, a ConfigMap, Secret, or HostPath. The volume may contain multiple files, all of which will be loaded.
             */
            volumeSource?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesource;
        }

        /**
         * VolumeSource accepts a standard Kubernetes VolumeSource for Kerberos configuration files like what is normally used to configure Volumes for a Pod. For example, a ConfigMap, Secret, or HostPath. The volume may contain multiple files, all of which will be loaded.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesource {
            /**
             * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceAwselasticblockstore;
            /**
             * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceAzuredisk;
            /**
             * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceAzurefile;
            /**
             * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceCephfs;
            /**
             * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceCinder;
            /**
             * configMap represents a configMap that should populate this volume
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceConfigmap;
            /**
             * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
             */
            csi?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceCsi;
            /**
             * downwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapi;
            /**
             * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEmptydir;
            /**
             * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
             *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
             *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
             *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
             *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
             */
            ephemeral?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeral;
            /**
             * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceFc;
            /**
             * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceFlexvolume;
            /**
             * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceFlocker;
            /**
             * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceGcepersistentdisk;
            /**
             * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceGitrepo;
            /**
             * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceGlusterfs;
            /**
             * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceHostpath;
            /**
             * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceIscsi;
            /**
             * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceNfs;
            /**
             * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourcePersistentvolumeclaim;
            /**
             * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourcePhotonpersistentdisk;
            /**
             * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourcePortworxvolume;
            /**
             * projected items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjected;
            /**
             * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceQuobyte;
            /**
             * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceRbd;
            /**
             * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceScaleio;
            /**
             * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceSecret;
            /**
             * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceStorageos;
            /**
             * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceVspherevolume;
        }

        /**
         * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceAwselasticblockstore {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * readOnly value true will force the readOnly setting in VolumeMounts. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceAzuredisk {
            /**
             * cachingMode is the Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * diskName is the Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * diskURI is the URI of data disk in the blob storage
             */
            diskURI: string;
            /**
             * fsType is Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceAzurefile {
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretName is the  name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * shareName is the azure share Name
             */
            shareName: string;
        }

        /**
         * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceCephfs {
            /**
             * monitors is Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceCephfsSecretref;
            /**
             * user is optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceCephfsSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceCinder {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceCinderSecretref;
            /**
             * volumeID used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceCinderSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * configMap represents a configMap that should populate this volume
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceConfigmap {
            /**
             * defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceCsi {
            /**
             * driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * fsType to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceCsiNodepublishsecretref;
            /**
             * readOnly specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * volumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceCsiNodepublishsecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * downwardAPI represents downward API about the pod that should populate this volume
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapi {
            /**
             * Optional: mode bits to use on created files by default. Must be a Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEmptydir {
            /**
             * medium represents what type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * sizeLimit is the total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: number | string;
        }

        /**
         * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
         *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
         *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
         *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
         *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeral {
            /**
             * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
             *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
             *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
             *  Required, must not be nil.
             */
            volumeClaimTemplate?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplate;
        }

        /**
         * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
         *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
         *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
         *  Required, must not be nil.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplate {
            /**
             * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
             */
            metadata?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateMetadata;
            /**
             * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
             */
            spec: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpec;
        }

        /**
         * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceFc {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * lun is Optional: FC target lun number
             */
            lun?: number;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * targetWWNs is Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * wwids Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceFlexvolume {
            /**
             * driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * options is Optional: this field holds extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * readOnly is Optional: defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceFlexvolumeSecretref;
        }

        /**
         * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceFlexvolumeSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceFlocker {
            /**
             * datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceGcepersistentdisk {
            /**
             * fsType is filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceGitrepo {
            /**
             * directory is the target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * repository is the URL
             */
            repository: string;
            /**
             * revision is the commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceGlusterfs {
            /**
             * endpoints is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * readOnly here will force the Glusterfs volume to be mounted with "read-only permissions. Defaults to false. More info: https"://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceHostpath {
            /**
             * path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceIscsi {
            /**
             * chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * chapAuthSession defines whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * initiatorName is the custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * iqn is the target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iscsiInterface is the interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * lun represents iSCSI Target Lun number.
             */
            lun: number;
            /**
             * portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * secretRef is the CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceIscsiSecretref;
            /**
             * targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * secretRef is the CHAP Secret for iSCSI target and initiator authentication
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceIscsiSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceNfs {
            /**
             * path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * readOnly here will force the NFS export to be mounted with "read-only permissions. Defaults to false. More info: https"://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourcePersistentvolumeclaim {
            /**
             * claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * readOnly Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourcePhotonpersistentdisk {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * pdID is the ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourcePortworxvolume {
            /**
             * fSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * volumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * projected items for all in one resources secrets, configmaps, and downward API
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjected {
            /**
             * defaultMode are the mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * sources is the list of volume projections
             */
            sources?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSources {
            /**
             * configMap information about the configMap data to project
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesConfigmap;
            /**
             * downwardAPI information about the downwardAPI data to project
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapi;
            /**
             * secret information about the secret data to project
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesSecret;
            /**
             * serviceAccountToken is information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesServiceaccounttoken;
        }

        /**
         * configMap information about the configMap data to project
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesConfigmap {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * downwardAPI information about the downwardAPI data to project
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapi {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * secret information about the secret data to project
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesSecret {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional field specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * serviceAccountToken is information about the serviceAccountToken data to project
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceProjectedSourcesServiceaccounttoken {
            /**
             * audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * expirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceQuobyte {
            /**
             * group to map volume access to Default is no group
             */
            group?: string;
            /**
             * readOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * user to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceRbd {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * image is the rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * monitors is a collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * pool is the rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceRbdSecretref;
            /**
             * user is the rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceRbdSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceScaleio {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * gateway is the host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * protectionDomain is the name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceScaleioSecretref;
            /**
             * sslEnabled Flag enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * storagePool is the ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * system is the name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * volumeName is the name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceScaleioSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceSecret {
            /**
             * defaultMode is Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceSecretItems[];
            /**
             * optional field specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * secretName is the name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceStorageos {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosConfigfilesVolumesourceStorageosSecretref;
            /**
             * volumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * volumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceStorageosSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecurityKerberosConfigfilesVolumesourceVspherevolume {
            /**
             * fsType is filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * storagePolicyName is the storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * volumePath is the path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * KeytabFile defines where the Kerberos keytab should be sourced from. The keytab file will be placed into `/etc/krb5.keytab`. If this is left empty, Rook will not add the file. This allows you to manage the `krb5.keytab` file yourself however you wish. For example, you may build it into your custom Ceph container image or use the Vault agent injector to securely add the file via annotations on the CephNFS spec (passed to the NFS server pods).
         */
        export interface CephNFSSpecSecurityKerberosKeytabfile {
            /**
             * VolumeSource accepts a standard Kubernetes VolumeSource for the Kerberos keytab file like what is normally used to configure Volumes for a Pod. For example, a Secret or HostPath. There are two requirements for the source's content:   1. The config file must be mountable via `subPath: krb5.keytab`. For example, in a      Secret, the data item must be named `krb5.keytab`, or `items` must be defined to      select the key and give it path `krb5.keytab`. A HostPath directory must have the      `krb5.keytab` file.   2. The volume or config file must have mode 0600.
             */
            volumeSource?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesource;
        }

        /**
         * VolumeSource accepts a standard Kubernetes VolumeSource for the Kerberos keytab file like what is normally used to configure Volumes for a Pod. For example, a Secret or HostPath. There are two requirements for the source's content:   1. The config file must be mountable via `subPath: krb5.keytab`. For example, in a      Secret, the data item must be named `krb5.keytab`, or `items` must be defined to      select the key and give it path `krb5.keytab`. A HostPath directory must have the      `krb5.keytab` file.   2. The volume or config file must have mode 0600.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesource {
            /**
             * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceAwselasticblockstore;
            /**
             * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceAzuredisk;
            /**
             * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceAzurefile;
            /**
             * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceCephfs;
            /**
             * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceCinder;
            /**
             * configMap represents a configMap that should populate this volume
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceConfigmap;
            /**
             * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
             */
            csi?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceCsi;
            /**
             * downwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapi;
            /**
             * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEmptydir;
            /**
             * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
             *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
             *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
             *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
             *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
             */
            ephemeral?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeral;
            /**
             * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceFc;
            /**
             * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceFlexvolume;
            /**
             * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceFlocker;
            /**
             * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceGcepersistentdisk;
            /**
             * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceGitrepo;
            /**
             * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceGlusterfs;
            /**
             * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceHostpath;
            /**
             * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceIscsi;
            /**
             * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceNfs;
            /**
             * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourcePersistentvolumeclaim;
            /**
             * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourcePhotonpersistentdisk;
            /**
             * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourcePortworxvolume;
            /**
             * projected items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjected;
            /**
             * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceQuobyte;
            /**
             * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceRbd;
            /**
             * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceScaleio;
            /**
             * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceSecret;
            /**
             * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceStorageos;
            /**
             * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceVspherevolume;
        }

        /**
         * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceAwselasticblockstore {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * readOnly value true will force the readOnly setting in VolumeMounts. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceAzuredisk {
            /**
             * cachingMode is the Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * diskName is the Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * diskURI is the URI of data disk in the blob storage
             */
            diskURI: string;
            /**
             * fsType is Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceAzurefile {
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretName is the  name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * shareName is the azure share Name
             */
            shareName: string;
        }

        /**
         * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceCephfs {
            /**
             * monitors is Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceCephfsSecretref;
            /**
             * user is optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceCephfsSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceCinder {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceCinderSecretref;
            /**
             * volumeID used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceCinderSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * configMap represents a configMap that should populate this volume
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceConfigmap {
            /**
             * defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceCsi {
            /**
             * driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * fsType to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceCsiNodepublishsecretref;
            /**
             * readOnly specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * volumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceCsiNodepublishsecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * downwardAPI represents downward API about the pod that should populate this volume
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapi {
            /**
             * Optional: mode bits to use on created files by default. Must be a Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEmptydir {
            /**
             * medium represents what type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * sizeLimit is the total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: number | string;
        }

        /**
         * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
         *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
         *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
         *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
         *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeral {
            /**
             * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
             *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
             *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
             *  Required, must not be nil.
             */
            volumeClaimTemplate?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplate;
        }

        /**
         * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
         *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
         *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
         *  Required, must not be nil.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplate {
            /**
             * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
             */
            metadata?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateMetadata;
            /**
             * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
             */
            spec: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpec;
        }

        /**
         * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceFc {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * lun is Optional: FC target lun number
             */
            lun?: number;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * targetWWNs is Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * wwids Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceFlexvolume {
            /**
             * driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * options is Optional: this field holds extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * readOnly is Optional: defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceFlexvolumeSecretref;
        }

        /**
         * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceFlexvolumeSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceFlocker {
            /**
             * datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceGcepersistentdisk {
            /**
             * fsType is filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceGitrepo {
            /**
             * directory is the target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * repository is the URL
             */
            repository: string;
            /**
             * revision is the commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceGlusterfs {
            /**
             * endpoints is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * readOnly here will force the Glusterfs volume to be mounted with "read-only permissions. Defaults to false. More info: https"://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceHostpath {
            /**
             * path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceIscsi {
            /**
             * chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * chapAuthSession defines whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * initiatorName is the custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * iqn is the target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iscsiInterface is the interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * lun represents iSCSI Target Lun number.
             */
            lun: number;
            /**
             * portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * secretRef is the CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceIscsiSecretref;
            /**
             * targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * secretRef is the CHAP Secret for iSCSI target and initiator authentication
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceIscsiSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceNfs {
            /**
             * path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * readOnly here will force the NFS export to be mounted with "read-only permissions. Defaults to false. More info: https"://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourcePersistentvolumeclaim {
            /**
             * claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * readOnly Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourcePhotonpersistentdisk {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * pdID is the ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourcePortworxvolume {
            /**
             * fSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * volumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * projected items for all in one resources secrets, configmaps, and downward API
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjected {
            /**
             * defaultMode are the mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * sources is the list of volume projections
             */
            sources?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSources {
            /**
             * configMap information about the configMap data to project
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesConfigmap;
            /**
             * downwardAPI information about the downwardAPI data to project
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapi;
            /**
             * secret information about the secret data to project
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesSecret;
            /**
             * serviceAccountToken is information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesServiceaccounttoken;
        }

        /**
         * configMap information about the configMap data to project
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesConfigmap {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * downwardAPI information about the downwardAPI data to project
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapi {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * secret information about the secret data to project
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesSecret {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional field specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * serviceAccountToken is information about the serviceAccountToken data to project
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceProjectedSourcesServiceaccounttoken {
            /**
             * audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * expirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceQuobyte {
            /**
             * group to map volume access to Default is no group
             */
            group?: string;
            /**
             * readOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * user to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceRbd {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * image is the rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * monitors is a collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * pool is the rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceRbdSecretref;
            /**
             * user is the rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceRbdSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceScaleio {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * gateway is the host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * protectionDomain is the name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceScaleioSecretref;
            /**
             * sslEnabled Flag enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * storagePool is the ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * system is the name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * volumeName is the name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceScaleioSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceSecret {
            /**
             * defaultMode is Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceSecretItems[];
            /**
             * optional field specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * secretName is the name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceStorageos {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecurityKerberosKeytabfileVolumesourceStorageosSecretref;
            /**
             * volumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * volumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceStorageosSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecurityKerberosKeytabfileVolumesourceVspherevolume {
            /**
             * fsType is filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * storagePolicyName is the storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * volumePath is the path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * SSSD enables integration with System Security Services Daemon (SSSD). SSSD can be used to provide user ID mapping from a number of sources. See https://sssd.io for more information about the SSSD project.
         */
        export interface CephNFSSpecSecuritySssd {
            /**
             * Sidecar tells Rook to run SSSD in a sidecar alongside the NFS-Ganesha server in each NFS pod.
             */
            sidecar?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecar;
        }

        /**
         * Sidecar tells Rook to run SSSD in a sidecar alongside the NFS-Ganesha server in each NFS pod.
         */
        export interface CephNFSSpecSecuritySssdSidecar {
            /**
             * AdditionalFiles defines any number of additional files that should be mounted into the SSSD sidecar. These files may be referenced by the sssd.conf config file.
             */
            additionalFiles?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfiles[];
            /**
             * DebugLevel sets the debug level for SSSD. If unset or set to 0, Rook does nothing. Otherwise, this may be a value between 1 and 10. See SSSD docs for more info: https://sssd.io/troubleshooting/basics.html#sssd-debug-logs
             */
            debugLevel?: number;
            /**
             * Image defines the container image that should be used for the SSSD sidecar.
             */
            image: string;
            /**
             * Resources allow specifying resource requests/limits on the SSSD sidecar container.
             */
            resources?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarResources;
            /**
             * SSSDConfigFile defines where the SSSD configuration should be sourced from. The config file will be placed into `/etc/sssd/sssd.conf`. If this is left empty, Rook will not add the file. This allows you to manage the `sssd.conf` file yourself however you wish. For example, you may build it into your custom Ceph container image or use the Vault agent injector to securely add the file via annotations on the CephNFS spec (passed to the NFS server pods).
             */
            sssdConfigFile?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfile;
        }

        /**
         * SSSDSidecarAdditionalFile represents the source from where additional files for the the SSSD configuration should come from and are made available.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfiles {
            /**
             * SubPath defines the sub-path in `/etc/sssd/rook-additional/` where the additional file(s) will be placed. Each subPath definition must be unique and must not contain ':'.
             */
            subPath: string;
            /**
             * VolumeSource accepts standard Kubernetes VolumeSource for the additional file(s) like what is normally used to configure Volumes for a Pod. Fore example, a ConfigMap, Secret, or HostPath. Each VolumeSource adds one or more additional files to the SSSD sidecar container in the `/etc/sssd/rook-additional/<subPath>` directory. Be aware that some files may need to have a specific file mode like 0600 due to requirements by SSSD for some files. For example, CA or TLS certificates.
             */
            volumeSource: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesource;
        }

        /**
         * VolumeSource accepts standard Kubernetes VolumeSource for the additional file(s) like what is normally used to configure Volumes for a Pod. Fore example, a ConfigMap, Secret, or HostPath. Each VolumeSource adds one or more additional files to the SSSD sidecar container in the `/etc/sssd/rook-additional/<subPath>` directory. Be aware that some files may need to have a specific file mode like 0600 due to requirements by SSSD for some files. For example, CA or TLS certificates.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesource {
            /**
             * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceAwselasticblockstore;
            /**
             * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceAzuredisk;
            /**
             * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceAzurefile;
            /**
             * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCephfs;
            /**
             * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCinder;
            /**
             * configMap represents a configMap that should populate this volume
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceConfigmap;
            /**
             * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
             */
            csi?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCsi;
            /**
             * downwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapi;
            /**
             * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEmptydir;
            /**
             * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
             *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
             *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
             *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
             *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
             */
            ephemeral?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeral;
            /**
             * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFc;
            /**
             * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFlexvolume;
            /**
             * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFlocker;
            /**
             * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceGcepersistentdisk;
            /**
             * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceGitrepo;
            /**
             * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceGlusterfs;
            /**
             * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceHostpath;
            /**
             * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceIscsi;
            /**
             * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceNfs;
            /**
             * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourcePersistentvolumeclaim;
            /**
             * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourcePhotonpersistentdisk;
            /**
             * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourcePortworxvolume;
            /**
             * projected items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjected;
            /**
             * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceQuobyte;
            /**
             * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceRbd;
            /**
             * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceScaleio;
            /**
             * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceSecret;
            /**
             * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceStorageos;
            /**
             * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceVspherevolume;
        }

        /**
         * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceAwselasticblockstore {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * readOnly value true will force the readOnly setting in VolumeMounts. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceAzuredisk {
            /**
             * cachingMode is the Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * diskName is the Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * diskURI is the URI of data disk in the blob storage
             */
            diskURI: string;
            /**
             * fsType is Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceAzurefile {
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretName is the  name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * shareName is the azure share Name
             */
            shareName: string;
        }

        /**
         * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCephfs {
            /**
             * monitors is Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCephfsSecretref;
            /**
             * user is optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCephfsSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCinder {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCinderSecretref;
            /**
             * volumeID used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCinderSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * configMap represents a configMap that should populate this volume
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceConfigmap {
            /**
             * defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCsi {
            /**
             * driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * fsType to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCsiNodepublishsecretref;
            /**
             * readOnly specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * volumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceCsiNodepublishsecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * downwardAPI represents downward API about the pod that should populate this volume
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapi {
            /**
             * Optional: mode bits to use on created files by default. Must be a Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEmptydir {
            /**
             * medium represents what type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * sizeLimit is the total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: number | string;
        }

        /**
         * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
         *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
         *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
         *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
         *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeral {
            /**
             * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
             *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
             *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
             *  Required, must not be nil.
             */
            volumeClaimTemplate?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplate;
        }

        /**
         * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
         *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
         *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
         *  Required, must not be nil.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplate {
            /**
             * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
             */
            metadata?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateMetadata;
            /**
             * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
             */
            spec: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpec;
        }

        /**
         * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFc {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * lun is Optional: FC target lun number
             */
            lun?: number;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * targetWWNs is Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * wwids Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFlexvolume {
            /**
             * driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * options is Optional: this field holds extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * readOnly is Optional: defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFlexvolumeSecretref;
        }

        /**
         * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFlexvolumeSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceFlocker {
            /**
             * datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceGcepersistentdisk {
            /**
             * fsType is filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceGitrepo {
            /**
             * directory is the target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * repository is the URL
             */
            repository: string;
            /**
             * revision is the commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceGlusterfs {
            /**
             * endpoints is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * readOnly here will force the Glusterfs volume to be mounted with "read-only permissions. Defaults to false. More info: https"://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceHostpath {
            /**
             * path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceIscsi {
            /**
             * chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * chapAuthSession defines whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * initiatorName is the custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * iqn is the target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iscsiInterface is the interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * lun represents iSCSI Target Lun number.
             */
            lun: number;
            /**
             * portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * secretRef is the CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceIscsiSecretref;
            /**
             * targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * secretRef is the CHAP Secret for iSCSI target and initiator authentication
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceIscsiSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceNfs {
            /**
             * path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * readOnly here will force the NFS export to be mounted with "read-only permissions. Defaults to false. More info: https"://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourcePersistentvolumeclaim {
            /**
             * claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * readOnly Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourcePhotonpersistentdisk {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * pdID is the ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourcePortworxvolume {
            /**
             * fSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * volumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * projected items for all in one resources secrets, configmaps, and downward API
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjected {
            /**
             * defaultMode are the mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * sources is the list of volume projections
             */
            sources?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSources {
            /**
             * configMap information about the configMap data to project
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesConfigmap;
            /**
             * downwardAPI information about the downwardAPI data to project
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapi;
            /**
             * secret information about the secret data to project
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesSecret;
            /**
             * serviceAccountToken is information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesServiceaccounttoken;
        }

        /**
         * configMap information about the configMap data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesConfigmap {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * downwardAPI information about the downwardAPI data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapi {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * secret information about the secret data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesSecret {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional field specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * serviceAccountToken is information about the serviceAccountToken data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceProjectedSourcesServiceaccounttoken {
            /**
             * audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * expirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceQuobyte {
            /**
             * group to map volume access to Default is no group
             */
            group?: string;
            /**
             * readOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * user to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceRbd {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * image is the rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * monitors is a collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * pool is the rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceRbdSecretref;
            /**
             * user is the rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceRbdSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceScaleio {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * gateway is the host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * protectionDomain is the name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceScaleioSecretref;
            /**
             * sslEnabled Flag enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * storagePool is the ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * system is the name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * volumeName is the name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceScaleioSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceSecret {
            /**
             * defaultMode is Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceSecretItems[];
            /**
             * optional field specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * secretName is the name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceStorageos {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceStorageosSecretref;
            /**
             * volumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * volumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceStorageosSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecuritySssdSidecarAdditionalfilesVolumesourceVspherevolume {
            /**
             * fsType is filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * storagePolicyName is the storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * volumePath is the path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * Resources allow specifying resource requests/limits on the SSSD sidecar container.
         */
        export interface CephNFSSpecSecuritySssdSidecarResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * SSSDConfigFile defines where the SSSD configuration should be sourced from. The config file will be placed into `/etc/sssd/sssd.conf`. If this is left empty, Rook will not add the file. This allows you to manage the `sssd.conf` file yourself however you wish. For example, you may build it into your custom Ceph container image or use the Vault agent injector to securely add the file via annotations on the CephNFS spec (passed to the NFS server pods).
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfile {
            /**
             * VolumeSource accepts a standard Kubernetes VolumeSource for the SSSD configuration file like what is normally used to configure Volumes for a Pod. For example, a ConfigMap, Secret, or HostPath. There are two requirements for the source's content:   1. The config file must be mountable via `subPath: sssd.conf`. For example, in a ConfigMap,      the data item must be named `sssd.conf`, or `items` must be defined to select the key      and give it path `sssd.conf`. A HostPath directory must have the `sssd.conf` file.   2. The volume or config file must have mode 0600.
             */
            volumeSource?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesource;
        }

        /**
         * VolumeSource accepts a standard Kubernetes VolumeSource for the SSSD configuration file like what is normally used to configure Volumes for a Pod. For example, a ConfigMap, Secret, or HostPath. There are two requirements for the source's content:   1. The config file must be mountable via `subPath: sssd.conf`. For example, in a ConfigMap,      the data item must be named `sssd.conf`, or `items` must be defined to select the key      and give it path `sssd.conf`. A HostPath directory must have the `sssd.conf` file.   2. The volume or config file must have mode 0600.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesource {
            /**
             * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceAwselasticblockstore;
            /**
             * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceAzuredisk;
            /**
             * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceAzurefile;
            /**
             * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCephfs;
            /**
             * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCinder;
            /**
             * configMap represents a configMap that should populate this volume
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceConfigmap;
            /**
             * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
             */
            csi?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCsi;
            /**
             * downwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapi;
            /**
             * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEmptydir;
            /**
             * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
             *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
             *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
             *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
             *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
             */
            ephemeral?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeral;
            /**
             * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFc;
            /**
             * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFlexvolume;
            /**
             * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFlocker;
            /**
             * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceGcepersistentdisk;
            /**
             * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceGitrepo;
            /**
             * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceGlusterfs;
            /**
             * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceHostpath;
            /**
             * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceIscsi;
            /**
             * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceNfs;
            /**
             * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourcePersistentvolumeclaim;
            /**
             * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourcePhotonpersistentdisk;
            /**
             * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourcePortworxvolume;
            /**
             * projected items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjected;
            /**
             * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceQuobyte;
            /**
             * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceRbd;
            /**
             * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceScaleio;
            /**
             * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceSecret;
            /**
             * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceStorageos;
            /**
             * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceVspherevolume;
        }

        /**
         * awsElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceAwselasticblockstore {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * readOnly value true will force the readOnly setting in VolumeMounts. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * volumeID is unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * azureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceAzuredisk {
            /**
             * cachingMode is the Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * diskName is the Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * diskURI is the URI of data disk in the blob storage
             */
            diskURI: string;
            /**
             * fsType is Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * kind expected values are Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * azureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceAzurefile {
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretName is the  name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * shareName is the azure share Name
             */
            shareName: string;
        }

        /**
         * cephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCephfs {
            /**
             * monitors is Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * path is Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretFile is Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCephfsSecretref;
            /**
             * user is optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCephfsSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCinder {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCinderSecretref;
            /**
             * volumeID used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * secretRef is optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCinderSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * configMap represents a configMap that should populate this volume
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceConfigmap {
            /**
             * defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * csi (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers (Beta feature).
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCsi {
            /**
             * driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * fsType to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCsiNodepublishsecretref;
            /**
             * readOnly specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * volumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * nodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceCsiNodepublishsecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * downwardAPI represents downward API about the pod that should populate this volume
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapi {
            /**
             * Optional: mode bits to use on created files by default. Must be a Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * emptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEmptydir {
            /**
             * medium represents what type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * sizeLimit is the total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: number | string;
        }

        /**
         * ephemeral represents a volume that is handled by a cluster storage driver. The volume's lifecycle is tied to the pod that defines it - it will be created before the pod starts, and deleted when the pod is removed. 
         *  Use this if: a) the volume is only needed while the pod runs, b) features of normal volumes like restoring from snapshot or capacity    tracking are needed, c) the storage driver is specified through a storage class, and d) the storage driver supports dynamic volume provisioning through    a PersistentVolumeClaim (see EphemeralVolumeSource for more    information on the connection between this volume type    and PersistentVolumeClaim). 
         *  Use PersistentVolumeClaim or one of the vendor-specific APIs for volumes that persist for longer than the lifecycle of an individual pod. 
         *  Use CSI for light-weight local ephemeral volumes if the CSI driver is meant to be used that way - see the documentation of the driver for more information. 
         *  A pod can use both types of ephemeral volumes and persistent volumes at the same time.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeral {
            /**
             * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
             *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
             *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
             *  Required, must not be nil.
             */
            volumeClaimTemplate?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplate;
        }

        /**
         * Will be used to create a stand-alone PVC to provision the volume. The pod in which this EphemeralVolumeSource is embedded will be the owner of the PVC, i.e. the PVC will be deleted together with the pod.  The name of the PVC will be `<pod name>-<volume name>` where `<volume name>` is the name from the `PodSpec.Volumes` array entry. Pod validation will reject the pod if the concatenated name is not valid for a PVC (for example, too long). 
         *  An existing PVC with that name that is not owned by the pod will *not* be used for the pod to avoid using an unrelated volume by mistake. Starting the pod is then blocked until the unrelated PVC is removed. If such a pre-created PVC is meant to be used by the pod, the PVC has to updated with an owner reference to the pod once the pod exists. Normally this should not be necessary, but it may be useful when manually reconstructing a broken cluster. 
         *  This field is read-only and no changes will be made by Kubernetes to the PVC after it has been created. 
         *  Required, must not be nil.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplate {
            /**
             * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
             */
            metadata?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateMetadata;
            /**
             * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
             */
            spec: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpec;
        }

        /**
         * May contain labels and annotations that will be copied into the PVC when creating it. No other fields are allowed and will be rejected during validation.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateMetadata {
            annotations?: {[key: string]: string};
            finalizers?: string[];
            labels?: {[key: string]: string};
            name?: string;
            namespace?: string;
        }

        /**
         * The specification for the PersistentVolumeClaim. The entire content is copied unchanged into the PVC that gets created from this template. The same fields as in a PersistentVolumeClaim are also valid here.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpec {
            /**
             * accessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
             */
            dataSource?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasource;
            /**
             * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
             */
            dataSourceRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref;
            /**
             * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecResources;
            /**
             * selector is a label query over volumes to consider for binding.
             */
            selector?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecSelector;
            /**
             * storageClassName is the name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * volumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * dataSource field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot) * An existing PVC (PersistentVolumeClaim) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the AnyVolumeDataSource feature gate is enabled, this field will always have the same contents as the DataSourceRef field.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * dataSourceRef specifies the object from which to populate the volume with data, if a "non-empty volume is desired. This may be any local object from a non-empty API group (non core object) or a PersistentVolumeClaim object. When this field is specified, volume binding will only succeed if the type of the specified object matches some installed volume populator or dynamic provisioner. This field will replace the functionality of the DataSource field and as such if both fields are non-empty, they must have the same value. For backwards compatibility, both fields (DataSource and DataSourceRef) will be set to the same value automatically if one of them is empty and the other is non-empty. There are two important differences between DataSource and DataSourceRef": * While DataSource only allows two specific types of objects, DataSourceRef   allows any non-core object, as well as PersistentVolumeClaim objects. * While DataSource ignores disallowed values (dropping them), DataSourceRef   preserves all values, and generates an error if a disallowed value is   specified. (Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecDatasourceref {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * resources represents the minimum resources the volume should have. If RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements that are lower than previous value but must still be higher than capacity recorded in the status field of the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            limits?: {[key: string]: number | string};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an "implementation-defined value. More info: https"://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
             */
            requests?: {[key: string]: number | string};
        }

        /**
         * selector is a label query over volumes to consider for binding.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * fc represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFc {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * lun is Optional: FC target lun number
             */
            lun?: number;
            /**
             * readOnly is Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * targetWWNs is Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * wwids Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * flexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFlexvolume {
            /**
             * driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * options is Optional: this field holds extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * readOnly is Optional: defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFlexvolumeSecretref;
        }

        /**
         * secretRef is Optional: secretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFlexvolumeSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceFlocker {
            /**
             * datasetName is Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * datasetUUID is the UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * gcePersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceGcepersistentdisk {
            /**
             * fsType is filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * partition is the partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * pdName is unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * gitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceGitrepo {
            /**
             * directory is the target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * repository is the URL
             */
            repository: string;
            /**
             * revision is the commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceGlusterfs {
            /**
             * endpoints is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * readOnly here will force the Glusterfs volume to be mounted with "read-only permissions. Defaults to false. More info: https"://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * hostPath represents a "pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https"://kubernetes.io/docs/concepts/storage/volumes#hostpath TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceHostpath {
            /**
             * path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * iscsi represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceIscsi {
            /**
             * chapAuthDiscovery defines whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * chapAuthSession defines whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * initiatorName is the custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * iqn is the target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iscsiInterface is the interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * lun represents iSCSI Target Lun number.
             */
            lun: number;
            /**
             * portals is the iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * secretRef is the CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceIscsiSecretref;
            /**
             * targetPortal is iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * secretRef is the CHAP Secret for iSCSI target and initiator authentication
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceIscsiSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * nfs represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceNfs {
            /**
             * path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * readOnly here will force the NFS export to be mounted with "read-only permissions. Defaults to false. More info: https"://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * persistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourcePersistentvolumeclaim {
            /**
             * claimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * readOnly Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * photonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourcePhotonpersistentdisk {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * pdID is the ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * portworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourcePortworxvolume {
            /**
             * fSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * volumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * projected items for all in one resources secrets, configmaps, and downward API
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjected {
            /**
             * defaultMode are the mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * sources is the list of volume projections
             */
            sources?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSources {
            /**
             * configMap information about the configMap data to project
             */
            configMap?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesConfigmap;
            /**
             * downwardAPI information about the downwardAPI data to project
             */
            downwardAPI?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapi;
            /**
             * secret information about the secret data to project
             */
            secret?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesSecret;
            /**
             * serviceAccountToken is information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesServiceaccounttoken;
        }

        /**
         * configMap information about the configMap data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesConfigmap {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesConfigmapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesConfigmapItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * downwardAPI information about the downwardAPI data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapi {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapiItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapiItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapiItemsFieldref;
            /**
             * Optional: mode bits used to set permissions on this file, must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapiItemsFieldref {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesDownwardapiItemsResourcefieldref {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: number | string;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        /**
         * secret information about the secret data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesSecret {
            /**
             * items if unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * optional field specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * serviceAccountToken is information about the serviceAccountToken data to project
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceProjectedSourcesServiceaccounttoken {
            /**
             * audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * expirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceQuobyte {
            /**
             * group to map volume access to Default is no group
             */
            group?: string;
            /**
             * readOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * user to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * rbd represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceRbd {
            /**
             * fsType is the filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * image is the rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * monitors is a collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * pool is the rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * readOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceRbdSecretref;
            /**
             * user is the rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * secretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceRbdSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * scaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceScaleio {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * gateway is the host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * protectionDomain is the name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * readOnly Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceScaleioSecretref;
            /**
             * sslEnabled Flag enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * storageMode indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * storagePool is the ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * system is the name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * volumeName is the name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * secretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceScaleioSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceSecret {
            /**
             * defaultMode is Optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * items If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceSecretItems[];
            /**
             * optional field specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * secretName is the name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceSecretItems {
            /**
             * key is the key to project.
             */
            key: string;
            /**
             * mode is Optional: mode bits used to set permissions on this file. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * path is the relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * storageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceStorageos {
            /**
             * fsType is the filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * readOnly defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.ceph.v1.CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceStorageosSecretref;
            /**
             * volumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * volumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * secretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceStorageosSecretref {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * vsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface CephNFSSpecSecuritySssdSidecarSssdconfigfileVolumesourceVspherevolume {
            /**
             * fsType is filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * storagePolicyID is the storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * storagePolicyName is the storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * volumePath is the path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * Server is the Ganesha Server specification
         */
        export interface CephNFSSpecServer {
            /**
             * The number of active Ganesha servers
             */
            active: number;
            /**
             * The annotations-related configuration to add/set on each Pod related object.
             */
            annotations?: {[key: string]: any};
            /**
             * The labels-related configuration to add/set on each Pod related object.
             */
            labels?: {[key: string]: any};
            /**
             * LogLevel set logging level
             */
            logLevel?: string;
            /**
             * The affinity to place the ganesha pods
             */
            placement?: {[key: string]: any};
            /**
             * PriorityClassName sets the priority class on the pods
             */
            priorityClassName?: string;
            /**
             * Resources set resource requests and limits
             */
            resources?: {[key: string]: any};
        }

        /**
         * ObjectRealmSpec represent the spec of an ObjectRealm
         */
        export interface CephObjectRealmSpec {
            /**
             * PullSpec represents the pulling specification of a Ceph Object Storage Gateway Realm
             */
            pull?: outputs.ceph.v1.CephObjectRealmSpecPull;
        }

        /**
         * PullSpec represents the pulling specification of a Ceph Object Storage Gateway Realm
         */
        export interface CephObjectRealmSpecPull {
            endpoint?: string;
        }

        /**
         * ObjectStoreSpec represent the spec of a pool
         */
        export interface CephObjectStoreSpec {
            /**
             * The data pool settings
             */
            dataPool?: outputs.ceph.v1.CephObjectStoreSpecDatapool;
            /**
             * The rgw pod info
             */
            gateway?: outputs.ceph.v1.CephObjectStoreSpecGateway;
            /**
             * The rgw Bucket healthchecks and liveness probe
             */
            healthCheck?: outputs.ceph.v1.CephObjectStoreSpecHealthcheck;
            /**
             * The metadata pool settings
             */
            metadataPool?: outputs.ceph.v1.CephObjectStoreSpecMetadatapool;
            /**
             * Preserve pools on object store deletion
             */
            preservePoolsOnDelete?: boolean;
            /**
             * Security represents security settings
             */
            security?: outputs.ceph.v1.CephObjectStoreSpecSecurity;
            /**
             * The multisite info
             */
            zone?: outputs.ceph.v1.CephObjectStoreSpecZone;
        }

        /**
         * The data pool settings
         */
        export interface CephObjectStoreSpecDatapool {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephObjectStoreSpecDatapoolErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephObjectStoreSpecDatapoolMirroring;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephObjectStoreSpecDatapoolQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephObjectStoreSpecDatapoolReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephObjectStoreSpecDatapoolErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephObjectStoreSpecDatapoolMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephObjectStoreSpecDatapoolMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephObjectStoreSpecDatapoolMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephObjectStoreSpecDatapoolMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephObjectStoreSpecDatapoolMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephObjectStoreSpecDatapoolQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephObjectStoreSpecDatapoolReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephObjectStoreSpecDatapoolReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephObjectStoreSpecDatapoolReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * The rgw pod info
         */
        export interface CephObjectStoreSpecGateway {
            /**
             * The annotations-related configuration to add/set on each Pod related object.
             */
            annotations?: {[key: string]: any};
            /**
             * The name of the secret that stores custom ca-bundle with root and intermediate certificates.
             */
            caBundleRef?: string;
            /**
             * ExternalRgwEndpoints points to external rgw endpoint(s)
             */
            externalRgwEndpoints?: outputs.ceph.v1.CephObjectStoreSpecGatewayExternalrgwendpoints[];
            /**
             * Whether host networking is enabled for the rgw daemon. If not set, the network settings from the cluster CR will be applied.
             */
            hostNetwork?: {[key: string]: any};
            /**
             * The number of pods in the rgw replicaset.
             */
            instances?: number;
            /**
             * The labels-related configuration to add/set on each Pod related object.
             */
            labels?: {[key: string]: any};
            /**
             * The affinity to place the rgw pods (default is to place on any available node)
             */
            placement?: {[key: string]: any};
            /**
             * The port the rgw service will be listening on (http)
             */
            port?: number;
            /**
             * PriorityClassName sets priority classes on the rgw pods
             */
            priorityClassName?: string;
            /**
             * The resource requirements for the rgw pods
             */
            resources?: {[key: string]: any};
            /**
             * The port the rgw service will be listening on (https)
             */
            securePort?: number;
            /**
             * The configuration related to add/set on each rgw service.
             */
            service?: outputs.ceph.v1.CephObjectStoreSpecGatewayService;
            /**
             * The name of the secret that stores the ssl certificate for secure rgw connections
             */
            sslCertificateRef?: string;
        }

        /**
         * EndpointAddress is a tuple that describes single IP address.
         */
        export interface CephObjectStoreSpecGatewayExternalrgwendpoints {
            /**
             * The Hostname of this endpoint
             */
            hostname?: string;
            /**
             * The IP of this endpoint. May not be loopback (127.0.0.0/8), link-local (169.254.0.0/16), or link-local multicast ((224.0.0.0/24). IPv6 is also accepted but not fully supported on all platforms. Also, certain kubernetes components, like kube-proxy, are not IPv6 ready. TODO: This should allow hostname or IP, See #4447.
             */
            ip: string;
            /**
             * Optional: Node hosting this endpoint. This can be used to determine endpoints local to a node.
             */
            nodeName?: string;
            /**
             * Reference to object providing the endpoint.
             */
            targetRef?: outputs.ceph.v1.CephObjectStoreSpecGatewayExternalrgwendpointsTargetref;
        }

        /**
         * Reference to object providing the endpoint.
         */
        export interface CephObjectStoreSpecGatewayExternalrgwendpointsTargetref {
            /**
             * API version of the referent.
             */
            apiVersion?: string;
            /**
             * If referring to a piece of an object instead of an entire object, this string should contain a valid JSON/Go field access statement, such as desiredState.manifest.containers[2]. For example, if the object reference is to a container within a pod, this would take on a value like: "spec.containers{name}" (where "name" refers to the name of the container that triggered the event) or if no container name is specified "spec.containers[2]" (container with index 2 in this pod). This syntax is chosen only to have some well-defined way of referencing a part of an object. TODO: this design is not final and this field is subject to change in the future.
             */
            fieldPath?: string;
            /**
             * Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name?: string;
            /**
             * Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
             */
            namespace?: string;
            /**
             * Specific resourceVersion to which this reference is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency
             */
            resourceVersion?: string;
            /**
             * UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids
             */
            uid?: string;
        }

        /**
         * The configuration related to add/set on each rgw service.
         */
        export interface CephObjectStoreSpecGatewayService {
            /**
             * The annotations-related configuration to add/set on each rgw service. nullable optional
             */
            annotations?: {[key: string]: string};
        }

        /**
         * The rgw Bucket healthchecks and liveness probe
         */
        export interface CephObjectStoreSpecHealthcheck {
            /**
             * HealthCheckSpec represents the health check of an object store bucket
             */
            bucket?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckBucket;
            /**
             * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
             */
            livenessProbe?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobe;
            /**
             * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
             */
            readinessProbe?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobe;
            /**
             * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
             */
            startupProbe?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobe;
        }

        /**
         * HealthCheckSpec represents the health check of an object store bucket
         */
        export interface CephObjectStoreSpecHealthcheckBucket {
            disabled?: boolean;
            /**
             * Interval is the internal in second or minute for the health check to run like 60s for 60 seconds
             */
            interval?: string;
            timeout?: string;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckLivenessprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephObjectStoreSpecHealthcheckLivenessprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckReadinessprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephObjectStoreSpecHealthcheckReadinessprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * ProbeSpec is a wrapper around Probe so it can be enabled or disabled for a Ceph daemon
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobe {
            /**
             * Disabled determines whether probe is disable or not
             */
            disabled?: boolean;
            /**
             * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
             */
            probe?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobeProbe;
        }

        /**
         * Probe describes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobeProbe {
            /**
             * Exec specifies the action to take.
             */
            exec?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobeProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
             */
            grpc?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobeProbeGrpc;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobeProbeHttpget;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port.
             */
            tcpSocket?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobeProbeTcpsocket;
            /**
             * Optional duration in seconds the pod needs to terminate gracefully upon probe failure. The grace period is the duration in seconds after the processes running in the pod are sent a termination signal and the time when the processes are forcibly halted with a kill signal. Set this value longer than the expected cleanup time for your process. If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this value overrides the value provided by the pod spec. Value must be non-negative integer. The value zero indicates stop immediately via the kill signal (no opportunity to shut down). This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate. Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * Exec specifies the action to take.
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobeProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * GRPC specifies an action involving a GRPC port. This is a beta field and requires enabling GRPCContainerProbe feature gate.
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobeProbeGrpc {
            /**
             * Port number of the gRPC service. Number must be in the range 1 to 65535.
             */
            port: number;
            /**
             * Service is the name of the service to place in the gRPC HealthCheckRequest (see https://github.com/grpc/grpc/blob/master/doc/health-checking.md). 
             *  If this is not specified, the default behavior is defined by gRPC.
             */
            service?: string;
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobeProbeHttpget {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.ceph.v1.CephObjectStoreSpecHealthcheckStartupprobeProbeHttpgetHttpheaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobeProbeHttpgetHttpheaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        /**
         * TCPSocket specifies an action involving a TCP port.
         */
        export interface CephObjectStoreSpecHealthcheckStartupprobeProbeTcpsocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: number | string;
        }

        /**
         * The metadata pool settings
         */
        export interface CephObjectStoreSpecMetadatapool {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolMirroring;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephObjectStoreSpecMetadatapoolErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephObjectStoreSpecMetadatapoolMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephObjectStoreSpecMetadatapoolMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephObjectStoreSpecMetadatapoolMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephObjectStoreSpecMetadatapoolQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephObjectStoreSpecMetadatapoolReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephObjectStoreSpecMetadatapoolReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephObjectStoreSpecMetadatapoolReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * Security represents security settings
         */
        export interface CephObjectStoreSpecSecurity {
            /**
             * KeyManagementService is the main Key Management option
             */
            kms?: outputs.ceph.v1.CephObjectStoreSpecSecurityKms;
            /**
             * The settings for supporting AWS-SSE:S3 with RGW
             */
            s3?: outputs.ceph.v1.CephObjectStoreSpecSecurityS3;
        }

        /**
         * KeyManagementService is the main Key Management option
         */
        export interface CephObjectStoreSpecSecurityKms {
            /**
             * ConnectionDetails contains the KMS connection details (address, port etc)
             */
            connectionDetails?: {[key: string]: any};
            /**
             * TokenSecretName is the kubernetes secret containing the KMS token
             */
            tokenSecretName?: string;
        }

        /**
         * The settings for supporting AWS-SSE:S3 with RGW
         */
        export interface CephObjectStoreSpecSecurityS3 {
            /**
             * ConnectionDetails contains the KMS connection details (address, port etc)
             */
            connectionDetails?: {[key: string]: any};
            /**
             * TokenSecretName is the kubernetes secret containing the KMS token
             */
            tokenSecretName?: string;
        }

        /**
         * The multisite info
         */
        export interface CephObjectStoreSpecZone {
            /**
             * RGW Zone the Object Store is in
             */
            name: string;
        }

        /**
         * ObjectStoreUserSpec represent the spec of an Objectstoreuser
         */
        export interface CephObjectStoreUserSpec {
            /**
             * Additional admin-level capabilities for the Ceph object store user
             */
            capabilities?: outputs.ceph.v1.CephObjectStoreUserSpecCapabilities;
            /**
             * The display name for the ceph users
             */
            displayName?: string;
            /**
             * ObjectUserQuotaSpec can be used to set quotas for the object store user to limit their usage. See the [Ceph docs](https://docs.ceph.com/en/latest/radosgw/admin/?#quota-management) for more
             */
            quotas?: outputs.ceph.v1.CephObjectStoreUserSpecQuotas;
            /**
             * The store the user will be created in
             */
            store?: string;
        }

        /**
         * Additional admin-level capabilities for the Ceph object store user
         */
        export interface CephObjectStoreUserSpecCapabilities {
            /**
             * Admin capabilities to read/write Ceph object store buckets. Documented in https://docs.ceph.com/en/latest/radosgw/admin/?#add-remove-admin-capabilities
             */
            bucket?: string;
            /**
             * Admin capabilities to read/write Ceph object store metadata. Documented in https://docs.ceph.com/en/latest/radosgw/admin/?#add-remove-admin-capabilities
             */
            metadata?: string;
            /**
             * Admin capabilities to read/write Ceph object store usage. Documented in https://docs.ceph.com/en/latest/radosgw/admin/?#add-remove-admin-capabilities
             */
            usage?: string;
            /**
             * Admin capabilities to read/write Ceph object store users. Documented in https://docs.ceph.com/en/latest/radosgw/admin/?#add-remove-admin-capabilities
             */
            user?: string;
            /**
             * Admin capabilities to read/write Ceph object store zones. Documented in https://docs.ceph.com/en/latest/radosgw/admin/?#add-remove-admin-capabilities
             */
            zone?: string;
        }

        /**
         * ObjectUserQuotaSpec can be used to set quotas for the object store user to limit their usage. See the [Ceph docs](https://docs.ceph.com/en/latest/radosgw/admin/?#quota-management) for more
         */
        export interface CephObjectStoreUserSpecQuotas {
            /**
             * Maximum bucket limit for the ceph user
             */
            maxBuckets?: number;
            /**
             * Maximum number of objects across all the user's buckets
             */
            maxObjects?: number;
            /**
             * Maximum size limit of all objects across all the user's buckets See https://pkg.go.dev/k8s.io/apimachinery/pkg/api/resource#Quantity for more info.
             */
            maxSize?: number | string;
        }

        /**
         * ObjectZoneGroupSpec represent the spec of an ObjectZoneGroup
         */
        export interface CephObjectZoneGroupSpec {
            /**
             * The display name for the ceph users
             */
            realm: string;
        }

        /**
         * ObjectZoneSpec represent the spec of an ObjectZone
         */
        export interface CephObjectZoneSpec {
            /**
             * If this zone cannot be accessed from other peer Ceph clusters via the ClusterIP Service endpoint created by Rook, you must set this to the externally reachable endpoint(s). You may include the port in the definition. For example: "https://"my-object-store.my-domain.net":443". In many cases, you should set this to the endpoint of the ingress resource that makes the CephObjectStore associated with this CephObjectStoreZone reachable to peer clusters. The list can have one or more endpoints pointing to different RGW servers in the zone.
             */
            customEndpoints?: string[];
            /**
             * The data pool settings
             */
            dataPool: outputs.ceph.v1.CephObjectZoneSpecDatapool;
            /**
             * The metadata pool settings
             */
            metadataPool: outputs.ceph.v1.CephObjectZoneSpecMetadatapool;
            /**
             * Preserve pools on object zone deletion
             */
            preservePoolsOnDelete?: boolean;
            /**
             * The display name for the ceph users
             */
            zoneGroup: string;
        }
        /**
         * cephObjectZoneSpecProvideDefaults sets the appropriate defaults for CephObjectZoneSpec
         */
        export function cephObjectZoneSpecProvideDefaults(val: CephObjectZoneSpec): CephObjectZoneSpec {
            return {
                ...val,
                preservePoolsOnDelete: (val.preservePoolsOnDelete) ?? true,
            };
        }

        /**
         * The data pool settings
         */
        export interface CephObjectZoneSpecDatapool {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephObjectZoneSpecDatapoolErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephObjectZoneSpecDatapoolMirroring;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephObjectZoneSpecDatapoolQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephObjectZoneSpecDatapoolReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephObjectZoneSpecDatapoolErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephObjectZoneSpecDatapoolMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephObjectZoneSpecDatapoolMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephObjectZoneSpecDatapoolMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephObjectZoneSpecDatapoolMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephObjectZoneSpecDatapoolMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephObjectZoneSpecDatapoolQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephObjectZoneSpecDatapoolReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephObjectZoneSpecDatapoolReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephObjectZoneSpecDatapoolReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * The metadata pool settings
         */
        export interface CephObjectZoneSpecMetadatapool {
            /**
             * DEPRECATED: use Parameters instead, e.g., Parameters["compression_mode"] = "force" The inline compression mode in Bluestore OSD to set to (options are: none, passive, aggressive, force) Do NOT set a default value for kubebuilder as this will override the Parameters
             */
            compressionMode?: string;
            /**
             * The root of the crush hierarchy utilized by the pool
             */
            crushRoot?: string;
            /**
             * The device class the OSD should set to for use in the pool
             */
            deviceClass?: string;
            /**
             * EnableRBDStats is used to enable gathering of statistics for all RBD images in the pool
             */
            enableRBDStats?: boolean;
            /**
             * The erasure code settings
             */
            erasureCoded?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolErasurecoded;
            /**
             * The failure domain: osd/host/(region or zone if available) - technically also any type in the crush map
             */
            failureDomain?: string;
            /**
             * The mirroring settings
             */
            mirroring?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolMirroring;
            /**
             * Parameters is a list of properties to enable on a given pool
             */
            parameters?: {[key: string]: any};
            /**
             * The quota settings
             */
            quotas?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolQuotas;
            /**
             * The replication settings
             */
            replicated?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolReplicated;
            /**
             * The mirroring statusCheck
             */
            statusCheck?: {[key: string]: any};
        }

        /**
         * The erasure code settings
         */
        export interface CephObjectZoneSpecMetadatapoolErasurecoded {
            /**
             * The algorithm for erasure coding
             */
            algorithm?: string;
            /**
             * Number of coding chunks per object in an erasure coded storage pool (required for erasure-coded pool type). This is the number of OSDs that can be lost simultaneously before data cannot be recovered.
             */
            codingChunks: number;
            /**
             * Number of data chunks per object in an erasure coded storage pool (required for erasure-coded pool type). The number of chunks required to recover an object when any single OSD is lost is the same as dataChunks so be aware that the larger the number of data chunks, the higher the cost of recovery.
             */
            dataChunks: number;
        }

        /**
         * The mirroring settings
         */
        export interface CephObjectZoneSpecMetadatapoolMirroring {
            /**
             * Enabled whether this pool is mirrored or not
             */
            enabled?: boolean;
            /**
             * Mode is the mirroring mode: either pool or image
             */
            mode?: string;
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolMirroringPeers;
            /**
             * SnapshotSchedules is the scheduling of snapshot for mirrored images/pools
             */
            snapshotSchedules?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolMirroringSnapshotschedules[];
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephObjectZoneSpecMetadatapoolMirroringPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }

        /**
         * SnapshotScheduleSpec represents the snapshot scheduling settings of a mirrored pool
         */
        export interface CephObjectZoneSpecMetadatapoolMirroringSnapshotschedules {
            /**
             * Interval represent the periodicity of the snapshot.
             */
            interval?: string;
            /**
             * Path is the path to snapshot, only valid for CephFS
             */
            path?: string;
            /**
             * StartTime indicates when to start the snapshot
             */
            startTime?: string;
        }

        /**
         * The quota settings
         */
        export interface CephObjectZoneSpecMetadatapoolQuotas {
            /**
             * MaxBytes represents the quota in bytes Deprecated in favor of MaxSize
             */
            maxBytes?: number;
            /**
             * MaxObjects represents the quota in objects
             */
            maxObjects?: number;
            /**
             * MaxSize represents the quota in bytes as a string
             */
            maxSize?: string;
        }

        /**
         * The replication settings
         */
        export interface CephObjectZoneSpecMetadatapoolReplicated {
            /**
             * HybridStorage represents hybrid storage tier settings
             */
            hybridStorage?: outputs.ceph.v1.CephObjectZoneSpecMetadatapoolReplicatedHybridstorage;
            /**
             * ReplicasPerFailureDomain the number of replica in the specified failure domain
             */
            replicasPerFailureDomain?: number;
            /**
             * RequireSafeReplicaSize if false allows you to set replica 1
             */
            requireSafeReplicaSize?: boolean;
            /**
             * Size - Number of copies per object in a replicated storage pool, including the object itself (required for replicated pool type)
             */
            size: number;
            /**
             * SubFailureDomain the name of the sub-failure domain
             */
            subFailureDomain?: string;
            /**
             * TargetSizeRatio gives a hint (%) to Ceph in terms of expected consumption of the total cluster capacity
             */
            targetSizeRatio?: number;
        }

        /**
         * HybridStorage represents hybrid storage tier settings
         */
        export interface CephObjectZoneSpecMetadatapoolReplicatedHybridstorage {
            /**
             * PrimaryDeviceClass represents high performance tier (for example SSD or NVME) for Primary OSD
             */
            primaryDeviceClass: string;
            /**
             * SecondaryDeviceClass represents low performance tier (for example HDDs) for remaining OSDs
             */
            secondaryDeviceClass: string;
        }

        /**
         * RBDMirroringSpec represents the specification of an RBD mirror daemon
         */
        export interface CephRBDMirrorSpec {
            /**
             * The annotations-related configuration to add/set on each Pod related object.
             */
            annotations?: {[key: string]: any};
            /**
             * Count represents the number of rbd mirror instance to run
             */
            count: number;
            /**
             * The labels-related configuration to add/set on each Pod related object.
             */
            labels?: {[key: string]: any};
            /**
             * Peers represents the peers spec
             */
            peers?: outputs.ceph.v1.CephRBDMirrorSpecPeers;
            /**
             * The affinity to place the rgw pods (default is to place on any available node)
             */
            placement?: {[key: string]: any};
            /**
             * PriorityClassName sets priority class on the rbd mirror pods
             */
            priorityClassName?: string;
            /**
             * The resource requirements for the rbd mirror pods
             */
            resources?: {[key: string]: any};
        }

        /**
         * Peers represents the peers spec
         */
        export interface CephRBDMirrorSpecPeers {
            /**
             * SecretNames represents the Kubernetes Secret names to add rbd-mirror or cephfs-mirror peers
             */
            secretNames?: string[];
        }
    }
}

export namespace certmanager {
    export namespace v1 {
        /**
         * Desired state of the CertificateRequest resource.
         */
        export interface CertificateRequestSpec {
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types.
             */
            duration?: string;
            /**
             * Extra contains extra attributes of the user that created the CertificateRequest. Populated by the cert-manager webhook on creation and immutable.
             */
            extra?: {[key: string]: string[]};
            /**
             * Groups contains group membership of the user that created the CertificateRequest. Populated by the cert-manager webhook on creation and immutable.
             */
            groups?: string[];
            /**
             * IsCA will request to mark the certificate as valid for certificate signing when submitting to the issuer. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this CertificateRequest.  If the `kind` field is not set, or set to `Issuer`, an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the `kind` field is set to `ClusterIssuer`, a ClusterIssuer with the provided name will be used. The `name` field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to `cert-manager.io` if empty.
             */
            issuerRef: outputs.certmanager.v1.CertificateRequestSpecIssuerref;
            /**
             * The PEM-encoded x509 certificate signing request to be submitted to the CA for signing.
             */
            request: string;
            /**
             * UID contains the uid of the user that created the CertificateRequest. Populated by the cert-manager webhook on creation and immutable.
             */
            uid?: string;
            /**
             * Usages is the set of x509 usages that are requested for the certificate. If usages are set they SHOULD be encoded inside the CSR spec Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
            /**
             * Username contains the name of the user that created the CertificateRequest. Populated by the cert-manager webhook on creation and immutable.
             */
            username?: string;
        }

        /**
         * IssuerRef is a reference to the issuer for this CertificateRequest.  If the `kind` field is not set, or set to `Issuer`, an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the `kind` field is set to `ClusterIssuer`, a ClusterIssuer with the provided name will be used. The `name` field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to `cert-manager.io` if empty.
         */
        export interface CertificateRequestSpecIssuerref {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Status of the CertificateRequest. This is set and managed automatically.
         */
        export interface CertificateRequestStatus {
            /**
             * The PEM encoded x509 certificate of the signer, also known as the CA (Certificate Authority). This is set on a best-effort basis by different issuers. If not set, the CA is assumed to be unknown/not available.
             */
            ca?: string;
            /**
             * The PEM encoded x509 certificate resulting from the certificate signing request. If not set, the CertificateRequest has either not been completed or has failed. More information on failure can be found by checking the `conditions` field.
             */
            certificate?: string;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready` and `InvalidRequest`.
             */
            conditions?: outputs.certmanager.v1.CertificateRequestStatusConditions[];
            /**
             * FailureTime stores the time that this CertificateRequest failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
        }

        /**
         * CertificateRequestCondition contains condition information for a CertificateRequest.
         */
        export interface CertificateRequestStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of (`True`, `False`, `Unknown`).
             */
            status: string;
            /**
             * Type of the condition, known values are (`Ready`, `InvalidRequest`, `Approved`, `Denied`).
             */
            type: string;
        }

        /**
         * Desired state of the Certificate resource.
         */
        export interface CertificateSpec {
            /**
             * AdditionalOutputFormats defines extra output formats of the private key and signed certificate chain to be written to this Certificate's target Secret. This is an Alpha Feature and is only enabled with the `--feature-gates=AdditionalCertificateOutputFormats=true` option on both the controller and webhook components.
             */
            additionalOutputFormats?: outputs.certmanager.v1.CertificateSpecAdditionaloutputformats[];
            /**
             * CommonName is a common name to be used on the Certificate. The CommonName should have a length of 64 characters or fewer to avoid generating invalid CSRs. This value is ignored by TLS clients when any subject alt name is set. This is x509 behaviour: https://tools.ietf.org/html/rfc6125#section-6.4.4
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS subjectAltNames to be set on the Certificate.
             */
            dnsNames?: string[];
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types. If unset this defaults to 90 days. Certificate will be renewed either 2/3 through its duration or `renewBefore` period before its expiry, whichever is later. Minimum accepted duration is 1 hour. Value must be in units accepted by Go time.ParseDuration https://golang.org/pkg/time/#ParseDuration
             */
            duration?: string;
            /**
             * EmailAddresses is a list of email subjectAltNames to be set on the Certificate.
             */
            emailAddresses?: string[];
            /**
             * EncodeUsagesInRequest controls whether key usages should be present in the CertificateRequest
             */
            encodeUsagesInRequest?: boolean;
            /**
             * IPAddresses is a list of IP address subjectAltNames to be set on the Certificate.
             */
            ipAddresses?: string[];
            /**
             * IsCA will mark this Certificate as valid for certificate signing. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this certificate. If the `kind` field is not set, or set to `Issuer`, an Issuer resource with the given name in the same namespace as the Certificate will be used. If the `kind` field is set to `ClusterIssuer`, a ClusterIssuer with the provided name will be used. The `name` field in this stanza is required at all times.
             */
            issuerRef: outputs.certmanager.v1.CertificateSpecIssuerref;
            /**
             * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
             */
            keystores?: outputs.certmanager.v1.CertificateSpecKeystores;
            /**
             * LiteralSubject is an LDAP formatted string that represents the [X.509 Subject field](https://datatracker.ietf.org/doc/html/rfc5280#"section-4.1.2.6). Use this *instead* of the Subject field if you need to ensure the correct ordering of the RDN sequence, such as when issuing certs for LDAP authentication. See https://github.com/cert-manager/cert-manager/issues/3203, https"://github.com/cert-manager/cert-manager/issues/4424. This field is alpha level and is only supported by cert-manager installations where LiteralCertificateSubject feature gate is enabled on both cert-manager controller and webhook.
             */
            literalSubject?: string;
            /**
             * Options to control private keys used for the Certificate.
             */
            privateKey?: outputs.certmanager.v1.CertificateSpecPrivatekey;
            /**
             * How long before the currently issued certificate's expiry "cert-manager should renew the certificate. The default is 2/3 of the issued certificate's duration. Minimum accepted value is 5 minutes. Value must be in units accepted by Go time.ParseDuration https"://golang.org/pkg/time/#ParseDuration
             */
            renewBefore?: string;
            /**
             * revisionHistoryLimit is the maximum number of CertificateRequest revisions that are maintained in the Certificate's history. Each revision represents a single `CertificateRequest` created by this Certificate, either when it was created, renewed, or Spec was changed. Revisions will be removed by oldest first if the number of revisions exceeds this number. If set, revisionHistoryLimit must be a value of `1` or greater. If unset (`nil`), revisions will not be garbage collected. Default value is `nil`.
             */
            revisionHistoryLimit?: number;
            /**
             * SecretName is the name of the secret resource that will be automatically created and managed by this Certificate resource. It will be populated with a private key and certificate, signed by the denoted issuer.
             */
            secretName: string;
            /**
             * SecretTemplate defines annotations and labels to be copied to the Certificate's Secret. Labels and annotations on the Secret will be changed as they appear on the SecretTemplate when added or removed. SecretTemplate annotations are added in conjunction with, and cannot overwrite, the base set of annotations cert-manager sets on the Certificate's Secret.
             */
            secretTemplate?: outputs.certmanager.v1.CertificateSpecSecrettemplate;
            /**
             * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
             */
            subject?: outputs.certmanager.v1.CertificateSpecSubject;
            /**
             * URIs is a list of URI subjectAltNames to be set on the Certificate.
             */
            uris?: string[];
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * CertificateAdditionalOutputFormat defines an additional output format of a Certificate resource. These contain supplementary data formats of the signed certificate chain and paired private key.
         */
        export interface CertificateSpecAdditionaloutputformats {
            /**
             * Type is the name of the format type that should be written to the Certificate's target Secret.
             */
            type: string;
        }

        /**
         * IssuerRef is a reference to the issuer for this certificate. If the `kind` field is not set, or set to `Issuer`, an Issuer resource with the given name in the same namespace as the Certificate will be used. If the `kind` field is set to `ClusterIssuer`, a ClusterIssuer with the provided name will be used. The `name` field in this stanza is required at all times.
         */
        export interface CertificateSpecIssuerref {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
         */
        export interface CertificateSpecKeystores {
            /**
             * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
             */
            jks?: outputs.certmanager.v1.CertificateSpecKeystoresJks;
            /**
             * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
             */
            pkcs12?: outputs.certmanager.v1.CertificateSpecKeystoresPkcs12;
        }

        /**
         * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresJks {
            /**
             * Create enables JKS keystore creation for the Certificate. If true, a file named `keystore.jks` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance. A file named `truststore.jks` will also be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef` containing the issuing Certificate Authority
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
             */
            passwordSecretRef: outputs.certmanager.v1.CertificateSpecKeystoresJksPasswordsecretref;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
         */
        export interface CertificateSpecKeystoresJksPasswordsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresPkcs12 {
            /**
             * Create enables PKCS12 keystore creation for the Certificate. If true, a file named `keystore.p12` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance. A file named `truststore.p12` will also be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef` containing the issuing Certificate Authority
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
             */
            passwordSecretRef: outputs.certmanager.v1.CertificateSpecKeystoresPkcs12Passwordsecretref;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
         */
        export interface CertificateSpecKeystoresPkcs12Passwordsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Options to control private keys used for the Certificate.
         */
        export interface CertificateSpecPrivatekey {
            /**
             * Algorithm is the private key algorithm of the corresponding private key for this certificate. If provided, allowed values are either `RSA`,`Ed25519` or `ECDSA` If `algorithm` is specified and `size` is not provided, key size of 256 will be used for `ECDSA` key algorithm and key size of 2048 will be used for `RSA` key algorithm. key size is ignored when using the `Ed25519` key algorithm.
             */
            algorithm?: string;
            /**
             * The private key cryptography standards (PKCS) encoding for this certificate's private key to be encoded in. If provided, allowed values are `PKCS1` and `PKCS8` standing for PKCS#1 and PKCS#8, respectively. Defaults to `PKCS1` if not specified.
             */
            encoding?: string;
            /**
             * RotationPolicy controls how private keys should be regenerated when a re-issuance is being processed. If set to Never, a private key will only be generated if one does not already exist in the target `spec.secretName`. If one does exists but it does not have the correct algorithm or size, a warning will be raised to await user intervention. If set to Always, a private key matching the specified requirements will be generated whenever a re-issuance occurs. Default is 'Never' for backward compatibility.
             */
            rotationPolicy?: string;
            /**
             * Size is the key bit size of the corresponding private key for this certificate. If `algorithm` is set to `RSA`, valid values are `2048`, `4096` or `8192`, and will default to `2048` if not specified. If `algorithm` is set to `ECDSA`, valid values are `256`, `384` or `521`, and will default to `256` if not specified. If `algorithm` is set to `Ed25519`, Size is ignored. No other values are allowed.
             */
            size?: number;
        }

        /**
         * SecretTemplate defines annotations and labels to be copied to the Certificate's Secret. Labels and annotations on the Secret will be changed as they appear on the SecretTemplate when added or removed. SecretTemplate annotations are added in conjunction with, and cannot overwrite, the base set of annotations cert-manager sets on the Certificate's Secret.
         */
        export interface CertificateSpecSecrettemplate {
            /**
             * Annotations is a key value map to be copied to the target Kubernetes Secret.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels is a key value map to be copied to the target Kubernetes Secret.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
         */
        export interface CertificateSpecSubject {
            /**
             * Countries to be used on the Certificate.
             */
            countries?: string[];
            /**
             * Cities to be used on the Certificate.
             */
            localities?: string[];
            /**
             * Organizational Units to be used on the Certificate.
             */
            organizationalUnits?: string[];
            /**
             * Organizations to be used on the Certificate.
             */
            organizations?: string[];
            /**
             * Postal codes to be used on the Certificate.
             */
            postalCodes?: string[];
            /**
             * State/Provinces to be used on the Certificate.
             */
            provinces?: string[];
            /**
             * Serial number to be used on the Certificate.
             */
            serialNumber?: string;
            /**
             * Street addresses to be used on the Certificate.
             */
            streetAddresses?: string[];
        }

        /**
         * Status of the Certificate. This is set and managed automatically.
         */
        export interface CertificateStatus {
            /**
             * List of status conditions to indicate the status of certificates. Known condition types are `Ready` and `Issuing`.
             */
            conditions?: outputs.certmanager.v1.CertificateStatusConditions[];
            /**
             * The number of continuous failed issuance attempts up till now. This field gets removed (if set) on a successful issuance and gets set to 1 if unset and an issuance has failed. If an issuance has failed, the delay till the next issuance will be calculated using formula time.Hour * 2 ^ (failedIssuanceAttempts - 1).
             */
            failedIssuanceAttempts?: number;
            /**
             * LastFailureTime is the time as recorded by the Certificate controller of the most recent failure to complete a CertificateRequest for this Certificate resource. If set, cert-manager will not re-request another Certificate until 1 hour has elapsed from this time.
             */
            lastFailureTime?: string;
            /**
             * The name of the Secret resource containing the private key to be used for the next certificate iteration. The keymanager controller will automatically set this field if the `Issuing` condition is set to `True`. It will automatically unset this field when the Issuing condition is not set or False.
             */
            nextPrivateKeySecretName?: string;
            /**
             * The expiration time of the certificate stored in the secret named by this resource in `spec.secretName`.
             */
            notAfter?: string;
            /**
             * The time after which the certificate stored in the secret named by this resource in spec.secretName is valid.
             */
            notBefore?: string;
            /**
             * RenewalTime is the time at which the certificate will be next renewed. If not set, no upcoming renewal is scheduled.
             */
            renewalTime?: string;
            /**
             * The current 'revision' of the certificate as issued. 
             *  When a CertificateRequest resource is created, it will have the `cert-manager.io/certificate-revision` set to one greater than the current value of this field. 
             *  Upon issuance, this field will be set to the value of the annotation on the CertificateRequest resource used to issue the certificate. 
             *  Persisting the value on the CertificateRequest resource allows the certificates controller to know whether a request is part of an old issuance or if it is part of the ongoing revision's issuance by checking if the revision value in the annotation is greater than this field.
             */
            revision?: number;
        }

        /**
         * CertificateCondition contains condition information for an Certificate.
         */
        export interface CertificateStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * If set, this represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.condition[x].observedGeneration is 9, the condition is out of date with respect to the current state of the Certificate.
             */
            observedGeneration?: number;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of (`True`, `False`, `Unknown`).
             */
            status: string;
            /**
             * Type of the condition, known values are (`Ready`, `Issuing`).
             */
            type: string;
        }

        /**
         * Desired state of the ClusterIssuer resource.
         */
        export interface ClusterIssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1.ClusterIssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1.ClusterIssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1.ClusterIssuerSpecSelfsigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1.ClusterIssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1.ClusterIssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface ClusterIssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1.ClusterIssuerSpecAcmeExternalaccountbinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmePrivatekeysecretref;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface ClusterIssuerSpecAcmeExternalaccountbinding {
            /**
             * Deprecated: keyAlgorithm field exists for historical compatibility reasons and should not be used. The algorithm is now hardcoded to HS256 in golang/x/crypto/acme.
             */
            keyAlgorithm?: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeExternalaccountbindingKeysecretref;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface ClusterIssuerSpecAcmeExternalaccountbindingKeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface ClusterIssuerSpecAcmePrivatekeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * An ACMEChallengeSolver describes how to solve ACME challenges for the issuer it is part of. A selector may be provided to use different solving strategies for different DNS names. Only one of HTTP01 or DNS01 must be provided.
         */
        export interface ClusterIssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AcmednsAccountsecretref;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmednsAccountsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AkamaiAccesstokensecretref;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AkamaiClientsecretsecretref;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AkamaiClienttokensecretref;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiAccesstokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClienttokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AzurednsClientsecretsecretref;
            /**
             * name of the Azure environment (default AzurePublicCloud)
             */
            environment?: string;
            /**
             * name of the DNS zone that should be used
             */
            hostedZoneName?: string;
            /**
             * managed identity configuration, can not be used at the same time as clientID, clientSecretSecretRef or tenantID
             */
            managedIdentity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AzurednsManagedidentity;
            /**
             * resource group the DNS zone is located in
             */
            resourceGroupName: string;
            /**
             * ID of the Azure subscription
             */
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzurednsClientsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * managed identity configuration, can not be used at the same time as clientID, clientSecretSecretRef or tenantID
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzurednsManagedidentity {
            /**
             * client ID of the managed identity, can not be used at the same time as resourceID
             */
            clientID?: string;
            /**
             * resource ID of the managed identity, can not be used at the same time as clientID
             */
            resourceID?: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01ClouddnsServiceaccountsecretref;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01ClouddnsServiceaccountsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01CloudflareApikeysecretref;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01CloudflareApitokensecretref;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApikeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApitokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokensecretref;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1])Â ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Rfc2136Tsigsecretsecretref;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136Tsigsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. Cannot be set when SecretAccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * The SecretAccessKey is used for authentication. If set, pull the AWS access key ID from a key within a Kubernetes Secret. Cannot be set when AccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyIDSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Route53Accesskeyidsecretref;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Route53Secretaccesskeysecretref;
        }

        /**
         * The SecretAccessKey is used for authentication. If set, pull the AWS access key ID from a key within a Kubernetes Secret. Cannot be set when AccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53Accesskeyidsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * The SecretAccessKey is used for authentication. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53Secretaccesskeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01 {
            /**
             * The Gateway API is a "sig-network community API that models service networking in Kubernetes (https"://gateway-api.sigs.k8s.io/). The Gateway solver will create HTTPRoutes with the specified labels in the same namespace as the challenge. This solver is experimental, and fields / behaviour may change in the future.
             */
            gatewayHTTPRoute?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01Gatewayhttproute;
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The Gateway API is a "sig-network community API that models service networking in Kubernetes (https"://gateway-api.sigs.k8s.io/). The Gateway solver will create HTTPRoutes with the specified labels in the same namespace as the challenge. This solver is experimental, and fields / behaviour may change in the future.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01Gatewayhttproute {
            /**
             * Custom labels that will be applied to HTTPRoutes created by cert-manager while solving HTTP-01 challenges.
             */
            labels?: {[key: string]: string};
            /**
             * When solving an HTTP-01 challenge, "cert-manager creates an HTTPRoute. cert-manager needs to know which parentRefs should be used when creating the HTTPRoute. Usually, the parentRef references a Gateway. See: https"://gateway-api.sigs.k8s.io/v1alpha2/api-types/httproute/#attaching-to-gateways
             */
            parentRefs?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs[];
            /**
             * Optional service type for Kubernetes solver service. Supported values are NodePort or ClusterIP. If unset, defaults to NodePort.
             */
            serviceType?: string;
        }

        /**
         * ParentRef identifies an API object (usually a Gateway) that can be considered a parent of this resource (usually a route). The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources, such as HTTPRoute. 
         *  The API object must be valid in the cluster; the Group and Kind must be registered in the cluster for this reference to be valid. 
         *  References to objects with invalid Group and Kind are not valid, and must be rejected by the implementation, with appropriate Conditions set on the containing object.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * clusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefsProvideDefaults sets the appropriate defaults for ClusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs
         */
        export function clusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefsProvideDefaults(val: ClusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs): ClusterIssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs {
            return {
                ...val,
                group: (val.group) ?? "gateway.networking.k8s.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges.
             */
            ingressTemplate?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressIngresstemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges.
             */
            podTemplate?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplate;
            /**
             * Optional service type for Kubernetes solver service. Supported values are NodePort or ClusterIP. If unset, defaults to NodePort.
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngresstemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressIngresstemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngresstemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodtemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ClusterIssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface ClusterIssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * The OCSP server list is an X.509 v3 extension that defines a list of URLs of OCSP responders. The OCSP responders can be queried for the revocation status of an issued certificate. If not set, the certificate will be issued with no OCSP servers set. For example, an OCSP server URL could be "http://ocsp.int-x3.letsencrypt.org".
             */
            ocspServers?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface ClusterIssuerSpecSelfsigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface ClusterIssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1.ClusterIssuerSpecVaultAuth;
            /**
             * PEM-encoded CA bundle (base64-encoded) used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure M"ulti-tenancy. e.g: "ns1" More about namespaces can be found here https"://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthApprole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthTokensecretref;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface ClusterIssuerSpecVaultAuthApprole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthApproleSecretref;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface ClusterIssuerSpecVaultAuthApproleSecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthKubernetesSecretref;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetesSecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface ClusterIssuerSpecVaultAuthTokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface ClusterIssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1.ClusterIssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1.ClusterIssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecVenafiCloudApitokensecretref;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface ClusterIssuerSpecVenafiCloudApitokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1.ClusterIssuerSpecVenafiTppCredentialsref;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface ClusterIssuerSpecVenafiTppCredentialsref {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the ClusterIssuer. This is set and managed automatically.
         */
        export interface ClusterIssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1.ClusterIssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1.ClusterIssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface ClusterIssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface ClusterIssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * If set, this represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.condition[x].observedGeneration is 9, the condition is out of date with respect to the current state of the Issuer.
             */
            observedGeneration?: number;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of (`True`, `False`, `Unknown`).
             */
            status: string;
            /**
             * Type of the condition, known values are (`Ready`).
             */
            type: string;
        }

        /**
         * Desired state of the Issuer resource.
         */
        export interface IssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1.IssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1.IssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1.IssuerSpecSelfsigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1.IssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1.IssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface IssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1.IssuerSpecAcmeExternalaccountbinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1.IssuerSpecAcmePrivatekeysecretref;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1.IssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface IssuerSpecAcmeExternalaccountbinding {
            /**
             * Deprecated: keyAlgorithm field exists for historical compatibility reasons and should not be used. The algorithm is now hardcoded to HS256 in golang/x/crypto/acme.
             */
            keyAlgorithm?: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1.IssuerSpecAcmeExternalaccountbindingKeysecretref;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface IssuerSpecAcmeExternalaccountbindingKeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface IssuerSpecAcmePrivatekeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * An ACMEChallengeSolver describes how to solve ACME challenges for the issuer it is part of. A selector may be provided to use different solving strategies for different DNS names. Only one of HTTP01 or DNS01 must be provided.
         */
        export interface IssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1.IssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface IssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AcmednsAccountsecretref;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AcmednsAccountsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AkamaiAccesstokensecretref;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AkamaiClientsecretsecretref;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AkamaiClienttokensecretref;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiAccesstokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClienttokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AzurednsClientsecretsecretref;
            /**
             * name of the Azure environment (default AzurePublicCloud)
             */
            environment?: string;
            /**
             * name of the DNS zone that should be used
             */
            hostedZoneName?: string;
            /**
             * managed identity configuration, can not be used at the same time as clientID, clientSecretSecretRef or tenantID
             */
            managedIdentity?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AzurednsManagedidentity;
            /**
             * resource group the DNS zone is located in
             */
            resourceGroupName: string;
            /**
             * ID of the Azure subscription
             */
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface IssuerSpecAcmeSolversDns01AzurednsClientsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * managed identity configuration, can not be used at the same time as clientID, clientSecretSecretRef or tenantID
         */
        export interface IssuerSpecAcmeSolversDns01AzurednsManagedidentity {
            /**
             * client ID of the managed identity, can not be used at the same time as resourceID
             */
            clientID?: string;
            /**
             * resource ID of the managed identity, can not be used at the same time as clientID
             */
            resourceID?: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01ClouddnsServiceaccountsecretref;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01ClouddnsServiceaccountsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01CloudflareApikeysecretref;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01CloudflareApitokensecretref;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApikeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApitokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01DigitaloceanTokensecretref;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01DigitaloceanTokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1])Â ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Rfc2136Tsigsecretsecretref;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136Tsigsecretsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. Cannot be set when SecretAccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * The SecretAccessKey is used for authentication. If set, pull the AWS access key ID from a key within a Kubernetes Secret. Cannot be set when AccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyIDSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Route53Accesskeyidsecretref;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Route53Secretaccesskeysecretref;
        }

        /**
         * The SecretAccessKey is used for authentication. If set, pull the AWS access key ID from a key within a Kubernetes Secret. Cannot be set when AccessKeyID is set. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface IssuerSpecAcmeSolversDns01Route53Accesskeyidsecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * The SecretAccessKey is used for authentication. If neither the Access Key nor Key ID are set, we "fall-back to using env vars, shared credentials file or AWS Instance metadata, see: https"://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface IssuerSpecAcmeSolversDns01Route53Secretaccesskeysecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface IssuerSpecAcmeSolversHttp01 {
            /**
             * The Gateway API is a "sig-network community API that models service networking in Kubernetes (https"://gateway-api.sigs.k8s.io/). The Gateway solver will create HTTPRoutes with the specified labels in the same namespace as the challenge. This solver is experimental, and fields / behaviour may change in the future.
             */
            gatewayHTTPRoute?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01Gatewayhttproute;
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The Gateway API is a "sig-network community API that models service networking in Kubernetes (https"://gateway-api.sigs.k8s.io/). The Gateway solver will create HTTPRoutes with the specified labels in the same namespace as the challenge. This solver is experimental, and fields / behaviour may change in the future.
         */
        export interface IssuerSpecAcmeSolversHttp01Gatewayhttproute {
            /**
             * Custom labels that will be applied to HTTPRoutes created by cert-manager while solving HTTP-01 challenges.
             */
            labels?: {[key: string]: string};
            /**
             * When solving an HTTP-01 challenge, "cert-manager creates an HTTPRoute. cert-manager needs to know which parentRefs should be used when creating the HTTPRoute. Usually, the parentRef references a Gateway. See: https"://gateway-api.sigs.k8s.io/v1alpha2/api-types/httproute/#attaching-to-gateways
             */
            parentRefs?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs[];
            /**
             * Optional service type for Kubernetes solver service. Supported values are NodePort or ClusterIP. If unset, defaults to NodePort.
             */
            serviceType?: string;
        }

        /**
         * ParentRef identifies an API object (usually a Gateway) that can be considered a parent of this resource (usually a route). The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources, such as HTTPRoute. 
         *  The API object must be valid in the cluster; the Group and Kind must be registered in the cluster for this reference to be valid. 
         *  References to objects with invalid Group and Kind are not valid, and must be rejected by the implementation, with appropriate Conditions set on the containing object.
         */
        export interface IssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * issuerSpecAcmeSolversHttp01GatewayhttprouteParentrefsProvideDefaults sets the appropriate defaults for IssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs
         */
        export function issuerSpecAcmeSolversHttp01GatewayhttprouteParentrefsProvideDefaults(val: IssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs): IssuerSpecAcmeSolversHttp01GatewayhttprouteParentrefs {
            return {
                ...val,
                group: (val.group) ?? "gateway.networking.k8s.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface IssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges.
             */
            ingressTemplate?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressIngresstemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges.
             */
            podTemplate?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplate;
            /**
             * Optional service type for Kubernetes solver service. Supported values are NodePort or ClusterIP. If unset, defaults to NodePort.
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngresstemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressIngresstemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngresstemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            /**
             * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
             */
            namespaceSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector;
            /**
             * namespaces specifies a static list of namespace names that the term applies to. The term is applied to the union of the namespaces listed in this field and the ones selected by namespaceSelector. null or empty namespaces list and null namespaceSelector means "this pod's namespace".
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label query over the set of namespaces that the term applies to. The term is applied to the union of the namespaces selected by this field and the ones listed in the namespaces field. null selector and null or empty namespaces list means "this pod's namespace". An empty selector ({}) matches all namespaces.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionNamespaceselectorMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodtemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface IssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface IssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * The OCSP server list is an X.509 v3 extension that defines a list of URLs of OCSP responders. The OCSP responders can be queried for the revocation status of an issued certificate. If not set, the certificate will be issued with no OCSP servers set. For example, an OCSP server URL could be "http://ocsp.int-x3.letsencrypt.org".
             */
            ocspServers?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface IssuerSpecSelfsigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface IssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1.IssuerSpecVaultAuth;
            /**
             * PEM-encoded CA bundle (base64-encoded) used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure M"ulti-tenancy. e.g: "ns1" More about namespaces can be found here https"://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface IssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1.IssuerSpecVaultAuthApprole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1.IssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1.IssuerSpecVaultAuthTokensecretref;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface IssuerSpecVaultAuthApprole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1.IssuerSpecVaultAuthApproleSecretref;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface IssuerSpecVaultAuthApproleSecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface IssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1.IssuerSpecVaultAuthKubernetesSecretref;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface IssuerSpecVaultAuthKubernetesSecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface IssuerSpecVaultAuthTokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface IssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1.IssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1.IssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1.IssuerSpecVenafiCloudApitokensecretref;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface IssuerSpecVenafiCloudApitokensecretref {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1.IssuerSpecVenafiTppCredentialsref;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface IssuerSpecVenafiTppCredentialsref {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the Issuer. This is set and managed automatically.
         */
        export interface IssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1.IssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1.IssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface IssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface IssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * If set, this represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.condition[x].observedGeneration is 9, the condition is out of date with respect to the current state of the Issuer.
             */
            observedGeneration?: number;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of (`True`, `False`, `Unknown`).
             */
            status: string;
            /**
             * Type of the condition, known values are (`Ready`).
             */
            type: string;
        }
    }
}

export namespace fluvio {
    export namespace v1 {
        export interface DerivedStreamSpec {
            input: any;
            steps?: any[];
        }

        export interface ManagedConnectorSpec {
            name: string;
            parameters?: {[key: string]: any};
            secrets?: {[key: string]: any};
            topic?: string;
            type: string;
            version?: string;
        }

        export interface PartitionSpec {
            cleanupPolicy?: outputs.fluvio.v1.PartitionSpecCleanuppolicy;
            compressionType?: string;
            leader: number;
            replicas: number[];
            storage?: outputs.fluvio.v1.PartitionSpecStorage;
        }

        export interface PartitionSpecCleanuppolicy {
            segment?: outputs.fluvio.v1.PartitionSpecCleanuppolicySegment;
        }

        export interface PartitionSpecCleanuppolicySegment {
            timeInSeconds?: number;
        }

        export interface PartitionSpecStorage {
            maxPartitionSize?: number;
            segmentSize?: number;
        }

        export interface SmartModuleSpec {
            init_params?: outputs.fluvio.v1.SmartModuleSpecInit_params[];
            input_kind: string;
            output_kind: string;
            package?: outputs.fluvio.v1.SmartModuleSpecPackage;
            parameters?: outputs.fluvio.v1.SmartModuleSpecParameters[];
            source_code?: outputs.fluvio.v1.SmartModuleSpecSource_code;
            wasm: outputs.fluvio.v1.SmartModuleSpecWasm;
        }

        export interface SmartModuleSpecInit_params {
            input: string;
            name: string;
        }

        export interface SmartModuleSpecPackage {
            /**
             * The group of the package.
             */
            group?: string;
            /**
             * The name of the package.
             */
            name?: string;
            /**
             * The version of the package.
             */
            version?: string;
        }

        export interface SmartModuleSpecParameters {
            name?: string;
        }

        export interface SmartModuleSpecSource_code {
            language: string;
            payload: string;
        }

        export interface SmartModuleSpecWasm {
            format: string;
            payload: string;
        }

        export interface SpuGroupSpec {
            minId?: number;
            replicas: number;
            template?: outputs.fluvio.v1.SpuGroupSpecTemplate;
        }

        export interface SpuGroupSpecTemplate {
            spec: outputs.fluvio.v1.SpuGroupSpecTemplateSpec;
        }

        export interface SpuGroupSpecTemplateSpec {
            env?: outputs.fluvio.v1.SpuGroupSpecTemplateSpecEnv[];
            privateEndpoint?: outputs.fluvio.v1.SpuGroupSpecTemplateSpecPrivateendpoint;
            publicEndpoint?: outputs.fluvio.v1.SpuGroupSpecTemplateSpecPublicendpoint;
            rack?: string;
            replication?: outputs.fluvio.v1.SpuGroupSpecTemplateSpecReplication;
            storage?: outputs.fluvio.v1.SpuGroupSpecTemplateSpecStorage;
        }

        export interface SpuGroupSpecTemplateSpecEnv {
            name?: string;
            value?: string;
        }

        export interface SpuGroupSpecTemplateSpecPrivateendpoint {
            encryption?: string;
            port?: number;
        }

        export interface SpuGroupSpecTemplateSpecPublicendpoint {
            encryption?: string;
            port?: number;
        }

        export interface SpuGroupSpecTemplateSpecReplication {
            inSyncReplicaMin?: number;
        }

        export interface SpuGroupSpecTemplateSpecStorage {
            logDir?: string;
            size?: string;
        }

        export interface SpuSpec {
            privateEndpoint: outputs.fluvio.v1.SpuSpecPrivateendpoint;
            publicEndpoint: outputs.fluvio.v1.SpuSpecPublicendpoint;
            publicEndpointLocal?: outputs.fluvio.v1.SpuSpecPublicendpointlocal;
            rack?: string;
            spuId: number;
            spuType?: string;
        }

        export interface SpuSpecPrivateendpoint {
            encryption?: string;
            host: string;
            port?: number;
        }

        export interface SpuSpecPublicendpoint {
            encryption?: string;
            ingress?: outputs.fluvio.v1.SpuSpecPublicendpointIngress[];
            port: number;
        }

        export interface SpuSpecPublicendpointIngress {
            hostname?: string;
            ip?: string;
        }

        export interface SpuSpecPublicendpointlocal {
            encryption?: string;
            host: string;
            port?: number;
        }

        export interface TableFormatSpec {
            columns?: outputs.fluvio.v1.TableFormatSpecColumns[];
            inputFormat?: string;
            name: string;
            smartmodule?: string;
        }

        export interface TableFormatSpecColumns {
            alignment?: string;
            display?: boolean;
            format?: string;
            headerBgColor?: string;
            headerFgColor?: string;
            headerLabel?: string;
            keyPath?: string;
            primaryKey?: boolean;
            width?: number;
        }

        export interface TopicSpec {
            customReplicaAssignment?: outputs.fluvio.v1.TopicSpecCustomreplicaassignment[];
            ignoreRackAssignment?: boolean;
            partitions?: number;
            replicationFactor?: number;
            type?: string;
        }

        export interface TopicSpecCustomreplicaassignment {
            partition: outputs.fluvio.v1.TopicSpecCustomreplicaassignmentPartition;
        }

        export interface TopicSpecCustomreplicaassignmentPartition {
            id: number;
            replicas: number[];
        }
    }

    export namespace v2 {
        export interface SmartModuleSpec {
            meta?: outputs.fluvio.v2.SmartModuleSpecMeta;
            wasm: outputs.fluvio.v2.SmartModuleSpecWasm;
        }

        export interface SmartModuleSpecMeta {
            package: outputs.fluvio.v2.SmartModuleSpecMetaPackage;
            params?: outputs.fluvio.v2.SmartModuleSpecMetaParams[];
        }

        export interface SmartModuleSpecMetaPackage {
            /**
             * The version of the package.
             */
            apiVersion: string;
            /**
             * The description of the package.
             */
            description?: string;
            /**
             * The group of the package.
             */
            group: string;
            /**
             * The license of the package.
             */
            license?: string;
            /**
             * The name of the package.
             */
            name: string;
            /**
             * The repository of the package.
             */
            repository?: string;
            /**
             * The version of the package.
             */
            version: string;
        }

        export interface SmartModuleSpecMetaParams {
            description?: string;
            name: string;
            optional?: boolean;
        }

        export interface SmartModuleSpecWasm {
            format: string;
            payload: string;
        }

        export interface TopicSpec {
            cleanupPolicy?: outputs.fluvio.v2.TopicSpecCleanuppolicy;
            compressionType?: string;
            replicas?: any;
            storage?: outputs.fluvio.v2.TopicSpecStorage;
        }

        export interface TopicSpecCleanuppolicy {
            segment?: outputs.fluvio.v2.TopicSpecCleanuppolicySegment;
        }

        export interface TopicSpecCleanuppolicySegment {
            timeInSeconds?: number;
        }

        export interface TopicSpecStorage {
            maxPartitionSize?: number;
            segmentSize?: number;
        }

    }
}

export namespace linkerd {
    export namespace v1alpha1 {
        /**
         * Spec is the custom resource spec
         */
        export interface ServiceProfileSpec {
            dstOverrides?: outputs.linkerd.v1alpha1.ServiceProfileSpecDstoverrides[];
            opaquePorts?: string[];
            /**
             * RetryBudget describes the maximum number of retries that should be issued to this service.
             */
            retryBudget?: outputs.linkerd.v1alpha1.ServiceProfileSpecRetrybudget;
            routes: outputs.linkerd.v1alpha1.ServiceProfileSpecRoutes[];
        }

        /**
         * WeightedDst is a weighted alternate destination.
         */
        export interface ServiceProfileSpecDstoverrides {
            authority?: string;
            weight?: number | string;
        }

        /**
         * RetryBudget describes the maximum number of retries that should be issued to this service.
         */
        export interface ServiceProfileSpecRetrybudget {
            minRetriesPerSecond: number;
            retryRatio: number;
            ttl: string;
        }

        /**
         * RouteSpec specifies a Route resource.
         */
        export interface ServiceProfileSpecRoutes {
            /**
             * RequestMatch describes the conditions under which to match a Route.
             */
            condition: outputs.linkerd.v1alpha1.ServiceProfileSpecRoutesCondition;
            isRetryable?: boolean;
            name: string;
            responseClasses?: outputs.linkerd.v1alpha1.ServiceProfileSpecRoutesResponseclasses[];
            timeout?: string;
        }

        /**
         * RequestMatch describes the conditions under which to match a Route.
         */
        export interface ServiceProfileSpecRoutesCondition {
            all?: {[key: string]: any}[];
            any?: {[key: string]: any}[];
            method?: string;
            not?: {[key: string]: any}[];
            pathRegex?: string;
        }

        /**
         * ResponseClass describes how to classify a response (e.g. success or failures).
         */
        export interface ServiceProfileSpecRoutesResponseclasses {
            /**
             * ResponseMatch describes the conditions under which to classify a response.
             */
            condition: outputs.linkerd.v1alpha1.ServiceProfileSpecRoutesResponseclassesCondition;
            isFailure?: boolean;
        }

        /**
         * ResponseMatch describes the conditions under which to classify a response.
         */
        export interface ServiceProfileSpecRoutesResponseclassesCondition {
            all?: {[key: string]: any}[];
            any?: {[key: string]: any}[];
            not?: {[key: string]: any}[];
            /**
             * Range describes a range of integers (e.g. status codes).
             */
            status?: outputs.linkerd.v1alpha1.ServiceProfileSpecRoutesResponseclassesConditionStatus;
        }

        /**
         * Range describes a range of integers (e.g. status codes).
         */
        export interface ServiceProfileSpecRoutesResponseclassesConditionStatus {
            max?: number;
            min?: number;
        }
    }

    export namespace v1alpha2 {
        /**
         * Spec is the custom resource spec
         */
        export interface ServiceProfileSpec {
            dstOverrides?: outputs.linkerd.v1alpha2.ServiceProfileSpecDstoverrides[];
            opaquePorts?: string[];
            /**
             * RetryBudget describes the maximum number of retries that should be issued to this service.
             */
            retryBudget?: outputs.linkerd.v1alpha2.ServiceProfileSpecRetrybudget;
            routes?: outputs.linkerd.v1alpha2.ServiceProfileSpecRoutes[];
        }

        /**
         * WeightedDst is a weighted alternate destination.
         */
        export interface ServiceProfileSpecDstoverrides {
            authority?: string;
            weight?: number | string;
        }

        /**
         * RetryBudget describes the maximum number of retries that should be issued to this service.
         */
        export interface ServiceProfileSpecRetrybudget {
            minRetriesPerSecond: number;
            retryRatio: number;
            ttl: string;
        }

        /**
         * RouteSpec specifies a Route resource.
         */
        export interface ServiceProfileSpecRoutes {
            /**
             * RequestMatch describes the conditions under which to match a Route.
             */
            condition: outputs.linkerd.v1alpha2.ServiceProfileSpecRoutesCondition;
            isRetryable?: boolean;
            name: string;
            responseClasses?: outputs.linkerd.v1alpha2.ServiceProfileSpecRoutesResponseclasses[];
            timeout?: string;
        }

        /**
         * RequestMatch describes the conditions under which to match a Route.
         */
        export interface ServiceProfileSpecRoutesCondition {
            all?: {[key: string]: any}[];
            any?: {[key: string]: any}[];
            method?: string;
            not?: {[key: string]: any}[];
            pathRegex?: string;
        }

        /**
         * ResponseClass describes how to classify a response (e.g. success or failures).
         */
        export interface ServiceProfileSpecRoutesResponseclasses {
            /**
             * ResponseMatch describes the conditions under which to classify a response.
             */
            condition: outputs.linkerd.v1alpha2.ServiceProfileSpecRoutesResponseclassesCondition;
            isFailure?: boolean;
        }

        /**
         * ResponseMatch describes the conditions under which to classify a response.
         */
        export interface ServiceProfileSpecRoutesResponseclassesCondition {
            all?: {[key: string]: any}[];
            any?: {[key: string]: any}[];
            not?: {[key: string]: any}[];
            /**
             * Range describes a range of integers (e.g. status codes).
             */
            status?: outputs.linkerd.v1alpha2.ServiceProfileSpecRoutesResponseclassesConditionStatus;
        }

        /**
         * Range describes a range of integers (e.g. status codes).
         */
        export interface ServiceProfileSpecRoutesResponseclassesConditionStatus {
            max?: number;
            min?: number;
        }
    }
}

export namespace metallb {
    export namespace v1alpha1 {
        /**
         * AddressPoolSpec defines the desired state of AddressPool.
         */
        export interface AddressPoolSpec {
            /**
             * A list of IP address ranges over which MetalLB has authority. You can list multiple ranges in a single pool, they will all share the same settings. Each range can be either a CIDR prefix, or an explicit start-end range of IPs.
             */
            addresses: string[];
            /**
             * AutoAssign flag used to prevent MetallB from automatic allocation for a pool.
             */
            autoAssign?: boolean;
            /**
             * When an IP is allocated from this pool, how should it be translated into BGP announcements?
             */
            bgpAdvertisements?: outputs.metallb.v1alpha1.AddressPoolSpecBgpadvertisements[];
            /**
             * Protocol can be used to select how the announcement is done.
             */
            protocol: string;
        }
        /**
         * addressPoolSpecProvideDefaults sets the appropriate defaults for AddressPoolSpec
         */
        export function addressPoolSpecProvideDefaults(val: AddressPoolSpec): AddressPoolSpec {
            return {
                ...val,
                autoAssign: (val.autoAssign) ?? true,
            };
        }

        export interface AddressPoolSpecBgpadvertisements {
            /**
             * The aggregation-length advertisement option lets you âroll upâ the /32s into a larger prefix.
             */
            aggregationLength?: number;
            /**
             * Optional, defaults to 128 (i.e. no aggregation) if not specified.
             */
            aggregationLengthV6?: number;
            /**
             * BGP communities
             */
            communities?: string[];
            /**
             * BGP LOCAL_PREF attribute which is used by BGP best path algorithm, Path with higher localpref is preferred over one with lower localpref.
             */
            localPref?: number;
        }
        /**
         * addressPoolSpecBgpadvertisementsProvideDefaults sets the appropriate defaults for AddressPoolSpecBgpadvertisements
         */
        export function addressPoolSpecBgpadvertisementsProvideDefaults(val: AddressPoolSpecBgpadvertisements): AddressPoolSpecBgpadvertisements {
            return {
                ...val,
                aggregationLength: (val.aggregationLength) ?? 32,
                aggregationLengthV6: (val.aggregationLengthV6) ?? 128,
            };
        }

    }

    export namespace v1beta1 {
        /**
         * AddressPoolSpec defines the desired state of AddressPool.
         */
        export interface AddressPoolSpec {
            /**
             * A list of IP address ranges over which MetalLB has authority. You can list multiple ranges in a single pool, they will all share the same settings. Each range can be either a CIDR prefix, or an explicit start-end range of IPs.
             */
            addresses: string[];
            /**
             * AutoAssign flag used to prevent MetallB from automatic allocation for a pool.
             */
            autoAssign?: boolean;
            /**
             * Drives how an IP allocated from this pool should translated into BGP announcements.
             */
            bgpAdvertisements?: outputs.metallb.v1beta1.AddressPoolSpecBgpadvertisements[];
            /**
             * Protocol can be used to select how the announcement is done.
             */
            protocol: string;
        }
        /**
         * addressPoolSpecProvideDefaults sets the appropriate defaults for AddressPoolSpec
         */
        export function addressPoolSpecProvideDefaults(val: AddressPoolSpec): AddressPoolSpec {
            return {
                ...val,
                autoAssign: (val.autoAssign) ?? true,
            };
        }

        export interface AddressPoolSpecBgpadvertisements {
            /**
             * The aggregation-length advertisement option lets you âroll upâ the /32s into a larger prefix.
             */
            aggregationLength?: number;
            /**
             * Optional, defaults to 128 (i.e. no aggregation) if not specified.
             */
            aggregationLengthV6?: number;
            /**
             * BGP communities to be associated with the given advertisement.
             */
            communities?: string[];
            /**
             * BGP LOCAL_PREF attribute which is used by BGP best path algorithm, Path with higher localpref is preferred over one with lower localpref.
             */
            localPref?: number;
        }
        /**
         * addressPoolSpecBgpadvertisementsProvideDefaults sets the appropriate defaults for AddressPoolSpecBgpadvertisements
         */
        export function addressPoolSpecBgpadvertisementsProvideDefaults(val: AddressPoolSpecBgpadvertisements): AddressPoolSpecBgpadvertisements {
            return {
                ...val,
                aggregationLength: (val.aggregationLength) ?? 32,
                aggregationLengthV6: (val.aggregationLengthV6) ?? 128,
            };
        }

        /**
         * BFDProfileSpec defines the desired state of BFDProfile.
         */
        export interface BFDProfileSpec {
            /**
             * Configures the detection multiplier to determine packet loss. The remote transmission interval will be multiplied by this value to determine the connection loss detection timer.
             */
            detectMultiplier?: number;
            /**
             * Configures the minimal echo receive transmission interval that this system is capable of handling in milliseconds. Defaults to 50ms
             */
            echoInterval?: number;
            /**
             * Enables or disables the echo transmission mode. This mode is disabled by default, and not supported on multi hops setups.
             */
            echoMode?: boolean;
            /**
             * For multi hop sessions only: configure the minimum expected TTL for an incoming BFD control packet.
             */
            minimumTtl?: number;
            /**
             * Mark session as passive: a passive session will not attempt to start the connection and will wait for control packets from peer before it begins replying.
             */
            passiveMode?: boolean;
            /**
             * The minimum interval that this system is capable of receiving control packets in milliseconds. Defaults to 300ms.
             */
            receiveInterval?: number;
            /**
             * The minimum transmission interval (less jitter) that this system wants to use to send BFD control packets in milliseconds. Defaults to 300ms
             */
            transmitInterval?: number;
        }

        /**
         * BGPAdvertisementSpec defines the desired state of BGPAdvertisement.
         */
        export interface BGPAdvertisementSpec {
            /**
             * The aggregation-length advertisement option lets you âroll upâ the /32s into a larger prefix. Defaults to 32. Works for IPv4 addresses.
             */
            aggregationLength?: number;
            /**
             * The aggregation-length advertisement option lets you âroll upâ the /128s into a larger prefix. Defaults to 128. Works for IPv6 addresses.
             */
            aggregationLengthV6?: number;
            /**
             * The BGP communities to be associated with the announcement. Each item can be a community of the form 1234:1234 or the name of an alias defined in the Community CRD.
             */
            communities?: string[];
            /**
             * A selector for the IPAddressPools which would get advertised via this advertisement. If no IPAddressPool is selected by this or by the list, the advertisement is applied to all the IPAddressPools.
             */
            ipAddressPoolSelectors?: outputs.metallb.v1beta1.BGPAdvertisementSpecIpaddresspoolselectors[];
            /**
             * The list of IPAddressPools to advertise via this advertisement, selected by name.
             */
            ipAddressPools?: string[];
            /**
             * The BGP LOCAL_PREF attribute which is used by BGP best path algorithm, Path with higher localpref is preferred over one with lower localpref.
             */
            localPref?: number;
            /**
             * NodeSelectors allows to limit the nodes to announce as next hops for the LoadBalancer IP. When empty, all the nodes having  are announced as next hops.
             */
            nodeSelectors?: outputs.metallb.v1beta1.BGPAdvertisementSpecNodeselectors[];
            /**
             * Peers limits the bgppeer to advertise the ips of the selected pools to. When empty, the loadbalancer IP is announced to all the BGPPeers configured.
             */
            peers?: string[];
        }
        /**
         * bgpadvertisementSpecProvideDefaults sets the appropriate defaults for BGPAdvertisementSpec
         */
        export function bgpadvertisementSpecProvideDefaults(val: BGPAdvertisementSpec): BGPAdvertisementSpec {
            return {
                ...val,
                aggregationLength: (val.aggregationLength) ?? 32,
                aggregationLengthV6: (val.aggregationLengthV6) ?? 128,
            };
        }

        /**
         * A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
         */
        export interface BGPAdvertisementSpecIpaddresspoolselectors {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.metallb.v1beta1.BGPAdvertisementSpecIpaddresspoolselectorsMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface BGPAdvertisementSpecIpaddresspoolselectorsMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
         */
        export interface BGPAdvertisementSpecNodeselectors {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.metallb.v1beta1.BGPAdvertisementSpecNodeselectorsMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface BGPAdvertisementSpecNodeselectorsMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * BGPPeerSpec defines the desired state of Peer.
         */
        export interface BGPPeerSpec {
            bfdProfile?: string;
            /**
             * EBGP peer is multi-hops away
             */
            ebgpMultiHop?: boolean;
            /**
             * Requested BGP hold time, per RFC4271.
             */
            holdTime?: string;
            /**
             * Requested BGP keepalive time, per RFC4271.
             */
            keepaliveTime?: string;
            /**
             * AS number to use for the local end of the session.
             */
            myASN: number;
            /**
             * Only connect to this peer on nodes that match one of these selectors.
             */
            nodeSelectors?: outputs.metallb.v1beta1.BGPPeerSpecNodeselectors[];
            /**
             * Authentication password for routers enforcing TCP MD5 authenticated sessions
             */
            password?: string;
            /**
             * AS number to expect from the remote end of the session.
             */
            peerASN: number;
            /**
             * Address to dial when establishing the session.
             */
            peerAddress: string;
            /**
             * Port to dial when establishing the session.
             */
            peerPort?: number;
            /**
             * BGP router ID to advertise to the peer
             */
            routerID?: string;
            /**
             * Source address to use when establishing the session.
             */
            sourceAddress?: string;
        }

        export interface BGPPeerSpecNodeselectors {
            matchExpressions?: outputs.metallb.v1beta1.BGPPeerSpecNodeselectorsMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BGPPeerSpecNodeselectorsMatchexpressions {
            key: string;
            operator: string;
            values: string[];
        }

        /**
         * CommunitySpec defines the desired state of Community.
         */
        export interface CommunitySpec {
            communities?: outputs.metallb.v1beta1.CommunitySpecCommunities[];
        }

        export interface CommunitySpecCommunities {
            /**
             * The name of the alias for the community.
             */
            name?: string;
            /**
             * The BGP community value corresponding to the given name.
             */
            value?: string;
        }

        /**
         * IPAddressPoolSpec defines the desired state of IPAddressPool.
         */
        export interface IPAddressPoolSpec {
            /**
             * A list of IP address ranges over which MetalLB has authority. You can list multiple ranges in a single pool, they will all share the same settings. Each range can be either a CIDR prefix, or an explicit start-end range of IPs.
             */
            addresses: string[];
            /**
             * AutoAssign flag used to prevent MetallB from automatic allocation for a pool.
             */
            autoAssign?: boolean;
            /**
             * AvoidBuggyIPs prevents addresses ending with .0 and .255 to be used by a pool.
             */
            avoidBuggyIPs?: boolean;
        }
        /**
         * ipaddressPoolSpecProvideDefaults sets the appropriate defaults for IPAddressPoolSpec
         */
        export function ipaddressPoolSpecProvideDefaults(val: IPAddressPoolSpec): IPAddressPoolSpec {
            return {
                ...val,
                autoAssign: (val.autoAssign) ?? true,
                avoidBuggyIPs: (val.avoidBuggyIPs) ?? false,
            };
        }

        /**
         * L2AdvertisementSpec defines the desired state of L2Advertisement.
         */
        export interface L2AdvertisementSpec {
            /**
             * A selector for the IPAddressPools which would get advertised via this advertisement. If no IPAddressPool is selected by this or by the list, the advertisement is applied to all the IPAddressPools.
             */
            ipAddressPoolSelectors?: outputs.metallb.v1beta1.L2AdvertisementSpecIpaddresspoolselectors[];
            /**
             * The list of IPAddressPools to advertise via this advertisement, selected by name.
             */
            ipAddressPools?: string[];
            /**
             * NodeSelectors allows to limit the nodes to announce as next hops for the LoadBalancer IP. When empty, all the nodes having  are announced as next hops.
             */
            nodeSelectors?: outputs.metallb.v1beta1.L2AdvertisementSpecNodeselectors[];
        }

        /**
         * A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
         */
        export interface L2AdvertisementSpecIpaddresspoolselectors {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.metallb.v1beta1.L2AdvertisementSpecIpaddresspoolselectorsMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface L2AdvertisementSpecIpaddresspoolselectorsMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
         */
        export interface L2AdvertisementSpecNodeselectors {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.metallb.v1beta1.L2AdvertisementSpecNodeselectorsMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface L2AdvertisementSpecNodeselectorsMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

    }

    export namespace v1beta2 {
        /**
         * BGPPeerSpec defines the desired state of Peer.
         */
        export interface BGPPeerSpec {
            /**
             * The name of the BFD Profile to be used for the BFD session associated to the BGP session. If not set, the BFD session won't be set up.
             */
            bfdProfile?: string;
            /**
             * To set if the BGPPeer is multi-hops away. Needed for FRR mode only.
             */
            ebgpMultiHop?: boolean;
            /**
             * Requested BGP hold time, per RFC4271.
             */
            holdTime?: string;
            /**
             * Requested BGP keepalive time, per RFC4271.
             */
            keepaliveTime?: string;
            /**
             * AS number to use for the local end of the session.
             */
            myASN: number;
            /**
             * Only connect to this peer on nodes that match one of these selectors.
             */
            nodeSelectors?: outputs.metallb.v1beta2.BGPPeerSpecNodeselectors[];
            /**
             * Authentication password for routers enforcing TCP MD5 authenticated sessions
             */
            password?: string;
            /**
             * passwordSecret is name of the authentication secret for BGP Peer. the secret must be of type "kubernetes.io/basic-auth", and created in the same namespace as the MetalLB deployment. The password is stored in the secret as the key "password".
             */
            passwordSecret?: outputs.metallb.v1beta2.BGPPeerSpecPasswordsecret;
            /**
             * AS number to expect from the remote end of the session.
             */
            peerASN: number;
            /**
             * Address to dial when establishing the session.
             */
            peerAddress: string;
            /**
             * Port to dial when establishing the session.
             */
            peerPort?: number;
            /**
             * BGP router ID to advertise to the peer
             */
            routerID?: string;
            /**
             * Source address to use when establishing the session.
             */
            sourceAddress?: string;
        }
        /**
         * bgppeerSpecProvideDefaults sets the appropriate defaults for BGPPeerSpec
         */
        export function bgppeerSpecProvideDefaults(val: BGPPeerSpec): BGPPeerSpec {
            return {
                ...val,
                peerPort: (val.peerPort) ?? 179,
            };
        }

        /**
         * A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all objects. A null label selector matches no objects.
         */
        export interface BGPPeerSpecNodeselectors {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.metallb.v1beta2.BGPPeerSpecNodeselectorsMatchexpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface BGPPeerSpecNodeselectorsMatchexpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * passwordSecret is name of the authentication secret for BGP Peer. the secret must be of type "kubernetes.io/basic-auth", and created in the same namespace as the MetalLB deployment. The password is stored in the secret as the key "password".
         */
        export interface BGPPeerSpecPasswordsecret {
            /**
             * Name is unique within a namespace to reference a secret resource.
             */
            name?: string;
            /**
             * Namespace defines the space within which the secret name must be unique.
             */
            namespace?: string;
        }

    }
}

export namespace objectbucket {
    export namespace v1alpha1 {
        export interface ObjectBucketClaimSpec {
            additionalConfig?: {[key: string]: any};
            bucketName?: string;
            generateBucketName?: string;
            objectBucketName?: string;
            storageClassName?: string;
        }

        export interface ObjectBucketSpec {
            additionalState?: {[key: string]: any};
            authentication?: {[key: string]: any};
            claimRef?: {[key: string]: any};
            endpoint?: outputs.objectbucket.v1alpha1.ObjectBucketSpecEndpoint;
            reclaimPolicy?: string;
            storageClassName?: string;
        }

        export interface ObjectBucketSpecEndpoint {
            additionalConfig?: {[key: string]: any};
            bucketHost?: string;
            bucketName?: string;
            bucketPort?: number;
            region?: string;
            subRegion?: string;
        }

    }
}

export namespace pingcap {
    export namespace v1alpha1 {
        export interface BackupScheduleSpec {
            backupTemplate: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplate;
            imagePullSecrets?: outputs.pingcap.v1alpha1.BackupScheduleSpecImagepullsecrets[];
            maxBackups?: number;
            maxReservedTime?: string;
            pause?: boolean;
            schedule: string;
            storageClassName?: string;
            storageSize?: string;
        }
        /**
         * backupScheduleSpecProvideDefaults sets the appropriate defaults for BackupScheduleSpec
         */
        export function backupScheduleSpecProvideDefaults(val: BackupScheduleSpec): BackupScheduleSpec {
            return {
                ...val,
                backupTemplate: outputs.pingcap.v1alpha1.backupScheduleSpecBackuptemplateProvideDefaults(val.backupTemplate),
            };
        }

        export interface BackupScheduleSpecBackuptemplate {
            affinity?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinity;
            azblob?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAzblob;
            backupType?: string;
            br?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateBr;
            cleanOption?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateCleanoption;
            cleanPolicy?: string;
            dumpling?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateDumpling;
            env?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateEnv[];
            from?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateFrom;
            gcs?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateGcs;
            imagePullSecrets?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateImagepullsecrets[];
            local?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocal;
            podSecurityContext?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplatePodsecuritycontext;
            priorityClassName?: string;
            resources?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateResources;
            s3?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateS3;
            serviceAccount?: string;
            storageClassName?: string;
            storageSize?: string;
            tableFilter?: string[];
            tikvGCLifeTime?: string;
            tolerations?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateTolerations[];
            toolImage?: string;
            useKMS?: boolean;
        }
        /**
         * backupScheduleSpecBackuptemplateProvideDefaults sets the appropriate defaults for BackupScheduleSpecBackuptemplate
         */
        export function backupScheduleSpecBackuptemplateProvideDefaults(val: BackupScheduleSpecBackuptemplate): BackupScheduleSpecBackuptemplate {
            return {
                ...val,
                cleanOption: (val.cleanOption ? outputs.pingcap.v1alpha1.backupScheduleSpecBackuptemplateCleanoptionProvideDefaults(val.cleanOption) : undefined),
            };
        }

        export interface BackupScheduleSpecBackuptemplateAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinity;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupScheduleSpecBackuptemplateAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateAzblob {
            accessTier?: string;
            container?: string;
            path?: string;
            prefix?: string;
            secretName?: string;
        }

        export interface BackupScheduleSpecBackuptemplateBr {
            checksum?: boolean;
            cluster: string;
            clusterNamespace?: string;
            concurrency?: number;
            db?: string;
            logLevel?: string;
            onLine?: boolean;
            options?: string[];
            rateLimit?: number;
            sendCredToTikv?: boolean;
            statusAddr?: string;
            table?: string;
            timeAgo?: string;
        }

        export interface BackupScheduleSpecBackuptemplateCleanoption {
            backoffEnabled?: boolean;
            batchConcurrency?: number;
            disableBatchConcurrency?: boolean;
            pageSize?: number;
            retryCount?: number;
            routineConcurrency?: number;
        }
        /**
         * backupScheduleSpecBackuptemplateCleanoptionProvideDefaults sets the appropriate defaults for BackupScheduleSpecBackuptemplateCleanoption
         */
        export function backupScheduleSpecBackuptemplateCleanoptionProvideDefaults(val: BackupScheduleSpecBackuptemplateCleanoption): BackupScheduleSpecBackuptemplateCleanoption {
            return {
                ...val,
                retryCount: (val.retryCount) ?? 5,
            };
        }

        export interface BackupScheduleSpecBackuptemplateDumpling {
            options?: string[];
            tableFilter?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateEnvValuefrom;
        }

        export interface BackupScheduleSpecBackuptemplateEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateEnvValuefromSecretkeyref;
        }

        export interface BackupScheduleSpecBackuptemplateEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface BackupScheduleSpecBackuptemplateEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface BackupScheduleSpecBackuptemplateEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateFrom {
            host: string;
            port?: number;
            secretName: string;
            tlsClientSecretName?: string;
            user?: string;
        }

        export interface BackupScheduleSpecBackuptemplateGcs {
            bucket?: string;
            bucketAcl?: string;
            location?: string;
            objectAcl?: string;
            path?: string;
            prefix?: string;
            projectId: string;
            secretName?: string;
            storageClass?: string;
        }

        export interface BackupScheduleSpecBackuptemplateImagepullsecrets {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocal {
            prefix?: string;
            volume: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolume;
            volumeMount: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumemount;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolume {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeCephfs;
            cinder?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeCinder;
            configMap?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeConfigmap;
            csi?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeral;
            fc?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeFc;
            flexVolume?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeHostpath;
            iscsi?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumePersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumePhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumePortworxvolume;
            projected?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjected;
            quobyte?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeQuobyte;
            rbd?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeRbd;
            scaleIO?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeScaleio;
            secret?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeSecret;
            storageos?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeVspherevolume;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeCephfsSecretref;
            user?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeCephfsSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeCinderSecretref;
            volumeID: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeCinderSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeCsiNodepublishsecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeDownwardapiItems[];
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeDownwardapiItemsResourcefieldref;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplate;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpec;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeFlexvolumeSecretref;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeFlexvolumeSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeHostpath {
            path: string;
            type?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeIscsiSecretref;
            targetPortal: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeIscsiSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumePersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumePhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumePortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSources[];
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesServiceaccounttoken;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapiItems[];
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeRbdSecretref;
            user?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeRbdSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeScaleioSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplateLocalVolumeStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeStorageosSecretref {
            name?: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumeVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface BackupScheduleSpecBackuptemplateLocalVolumemount {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface BackupScheduleSpecBackuptemplatePodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplatePodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplatePodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplatePodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.BackupScheduleSpecBackuptemplatePodsecuritycontextWindowsoptions;
        }

        export interface BackupScheduleSpecBackuptemplatePodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface BackupScheduleSpecBackuptemplatePodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface BackupScheduleSpecBackuptemplatePodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface BackupScheduleSpecBackuptemplatePodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface BackupScheduleSpecBackuptemplateResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface BackupScheduleSpecBackuptemplateS3 {
            acl?: string;
            bucket?: string;
            endpoint?: string;
            options?: string[];
            path?: string;
            prefix?: string;
            provider: string;
            region?: string;
            secretName?: string;
            sse?: string;
            storageClass?: string;
        }

        export interface BackupScheduleSpecBackuptemplateTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface BackupScheduleSpecImagepullsecrets {
            name?: string;
        }

        export interface BackupScheduleStatus {
            allBackupCleanTime?: string;
            lastBackup?: string;
            lastBackupTime?: string;
        }

        export interface BackupSpec {
            affinity?: outputs.pingcap.v1alpha1.BackupSpecAffinity;
            azblob?: outputs.pingcap.v1alpha1.BackupSpecAzblob;
            backupType?: string;
            br?: outputs.pingcap.v1alpha1.BackupSpecBr;
            cleanOption?: outputs.pingcap.v1alpha1.BackupSpecCleanoption;
            cleanPolicy?: string;
            dumpling?: outputs.pingcap.v1alpha1.BackupSpecDumpling;
            env?: outputs.pingcap.v1alpha1.BackupSpecEnv[];
            from?: outputs.pingcap.v1alpha1.BackupSpecFrom;
            gcs?: outputs.pingcap.v1alpha1.BackupSpecGcs;
            imagePullSecrets?: outputs.pingcap.v1alpha1.BackupSpecImagepullsecrets[];
            local?: outputs.pingcap.v1alpha1.BackupSpecLocal;
            podSecurityContext?: outputs.pingcap.v1alpha1.BackupSpecPodsecuritycontext;
            priorityClassName?: string;
            resources?: outputs.pingcap.v1alpha1.BackupSpecResources;
            s3?: outputs.pingcap.v1alpha1.BackupSpecS3;
            serviceAccount?: string;
            storageClassName?: string;
            storageSize?: string;
            tableFilter?: string[];
            tikvGCLifeTime?: string;
            tolerations?: outputs.pingcap.v1alpha1.BackupSpecTolerations[];
            toolImage?: string;
            useKMS?: boolean;
        }
        /**
         * backupSpecProvideDefaults sets the appropriate defaults for BackupSpec
         */
        export function backupSpecProvideDefaults(val: BackupSpec): BackupSpec {
            return {
                ...val,
                cleanOption: (val.cleanOption ? outputs.pingcap.v1alpha1.backupSpecCleanoptionProvideDefaults(val.cleanOption) : undefined),
            };
        }

        export interface BackupSpecAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinity;
        }

        export interface BackupSpecAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface BackupSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecAzblob {
            accessTier?: string;
            container?: string;
            path?: string;
            prefix?: string;
            secretName?: string;
        }

        export interface BackupSpecBr {
            checksum?: boolean;
            cluster: string;
            clusterNamespace?: string;
            concurrency?: number;
            db?: string;
            logLevel?: string;
            onLine?: boolean;
            options?: string[];
            rateLimit?: number;
            sendCredToTikv?: boolean;
            statusAddr?: string;
            table?: string;
            timeAgo?: string;
        }

        export interface BackupSpecCleanoption {
            backoffEnabled?: boolean;
            batchConcurrency?: number;
            disableBatchConcurrency?: boolean;
            pageSize?: number;
            retryCount?: number;
            routineConcurrency?: number;
        }
        /**
         * backupSpecCleanoptionProvideDefaults sets the appropriate defaults for BackupSpecCleanoption
         */
        export function backupSpecCleanoptionProvideDefaults(val: BackupSpecCleanoption): BackupSpecCleanoption {
            return {
                ...val,
                retryCount: (val.retryCount) ?? 5,
            };
        }

        export interface BackupSpecDumpling {
            options?: string[];
            tableFilter?: string[];
        }

        export interface BackupSpecEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.BackupSpecEnvValuefrom;
        }

        export interface BackupSpecEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.BackupSpecEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.BackupSpecEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.BackupSpecEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.BackupSpecEnvValuefromSecretkeyref;
        }

        export interface BackupSpecEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface BackupSpecEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface BackupSpecEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface BackupSpecEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface BackupSpecFrom {
            host: string;
            port?: number;
            secretName: string;
            tlsClientSecretName?: string;
            user?: string;
        }

        export interface BackupSpecGcs {
            bucket?: string;
            bucketAcl?: string;
            location?: string;
            objectAcl?: string;
            path?: string;
            prefix?: string;
            projectId: string;
            secretName?: string;
            storageClass?: string;
        }

        export interface BackupSpecImagepullsecrets {
            name?: string;
        }

        export interface BackupSpecLocal {
            prefix?: string;
            volume: outputs.pingcap.v1alpha1.BackupSpecLocalVolume;
            volumeMount: outputs.pingcap.v1alpha1.BackupSpecLocalVolumemount;
        }

        export interface BackupSpecLocalVolume {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeCephfs;
            cinder?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeCinder;
            configMap?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeConfigmap;
            csi?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeral;
            fc?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeFc;
            flexVolume?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeHostpath;
            iscsi?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumePersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumePhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumePortworxvolume;
            projected?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjected;
            quobyte?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeQuobyte;
            rbd?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeRbd;
            scaleIO?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeScaleio;
            secret?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeSecret;
            storageos?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeVspherevolume;
        }

        export interface BackupSpecLocalVolumeAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface BackupSpecLocalVolumeAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface BackupSpecLocalVolumeAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface BackupSpecLocalVolumeCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeCephfsSecretref;
            user?: string;
        }

        export interface BackupSpecLocalVolumeCephfsSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeCinderSecretref;
            volumeID: string;
        }

        export interface BackupSpecLocalVolumeCinderSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface BackupSpecLocalVolumeConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupSpecLocalVolumeCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface BackupSpecLocalVolumeCsiNodepublishsecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeDownwardapiItems[];
        }

        export interface BackupSpecLocalVolumeDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeDownwardapiItemsResourcefieldref;
        }

        export interface BackupSpecLocalVolumeDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface BackupSpecLocalVolumeDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface BackupSpecLocalVolumeEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface BackupSpecLocalVolumeEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeralVolumeclaimtemplate;
        }

        export interface BackupSpecLocalVolumeEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpec;
        }

        export interface BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface BackupSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface BackupSpecLocalVolumeFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface BackupSpecLocalVolumeFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeFlexvolumeSecretref;
        }

        export interface BackupSpecLocalVolumeFlexvolumeSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface BackupSpecLocalVolumeGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface BackupSpecLocalVolumeGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface BackupSpecLocalVolumeGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface BackupSpecLocalVolumeHostpath {
            path: string;
            type?: string;
        }

        export interface BackupSpecLocalVolumeIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeIscsiSecretref;
            targetPortal: string;
        }

        export interface BackupSpecLocalVolumeIscsiSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface BackupSpecLocalVolumePersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface BackupSpecLocalVolumePhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface BackupSpecLocalVolumePortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface BackupSpecLocalVolumeProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSources[];
        }

        export interface BackupSpecLocalVolumeProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesServiceaccounttoken;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesDownwardapiItems[];
        }

        export interface BackupSpecLocalVolumeProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupSpecLocalVolumeProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface BackupSpecLocalVolumeQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface BackupSpecLocalVolumeRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeRbdSecretref;
            user?: string;
        }

        export interface BackupSpecLocalVolumeRbdSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface BackupSpecLocalVolumeScaleioSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface BackupSpecLocalVolumeSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface BackupSpecLocalVolumeStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.BackupSpecLocalVolumeStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface BackupSpecLocalVolumeStorageosSecretref {
            name?: string;
        }

        export interface BackupSpecLocalVolumeVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface BackupSpecLocalVolumemount {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface BackupSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.BackupSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.BackupSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.BackupSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.BackupSpecPodsecuritycontextWindowsoptions;
        }

        export interface BackupSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface BackupSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface BackupSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface BackupSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface BackupSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface BackupSpecS3 {
            acl?: string;
            bucket?: string;
            endpoint?: string;
            options?: string[];
            path?: string;
            prefix?: string;
            provider: string;
            region?: string;
            secretName?: string;
            sse?: string;
            storageClass?: string;
        }

        export interface BackupSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface BackupStatus {
            backupPath?: string;
            backupSize?: number;
            backupSizeReadable?: string;
            commitTs?: string;
            conditions?: outputs.pingcap.v1alpha1.BackupStatusConditions[];
            phase?: string;
            timeCompleted?: string;
            timeStarted?: string;
        }

        export interface BackupStatusConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface DMClusterSpec {
            affinity?: outputs.pingcap.v1alpha1.DMClusterSpecAffinity;
            annotations?: {[key: string]: string};
            configUpdateStrategy?: string;
            discovery?: outputs.pingcap.v1alpha1.DMClusterSpecDiscovery;
            dnsConfig?: outputs.pingcap.v1alpha1.DMClusterSpecDnsconfig;
            dnsPolicy?: string;
            enablePVReclaim?: boolean;
            hostNetwork?: boolean;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.DMClusterSpecImagepullsecrets[];
            labels?: {[key: string]: string};
            master?: outputs.pingcap.v1alpha1.DMClusterSpecMaster;
            nodeSelector?: {[key: string]: string};
            paused?: boolean;
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.DMClusterSpecPodsecuritycontext;
            priorityClassName?: string;
            pvReclaimPolicy?: string;
            schedulerName?: string;
            statefulSetUpdateStrategy?: string;
            suspendAction?: outputs.pingcap.v1alpha1.DMClusterSpecSuspendaction;
            timezone?: string;
            tlsClientSecretNames?: string[];
            tlsCluster?: outputs.pingcap.v1alpha1.DMClusterSpecTlscluster;
            tolerations?: outputs.pingcap.v1alpha1.DMClusterSpecTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.DMClusterSpecTopologyspreadconstraints[];
            version?: string;
            worker?: outputs.pingcap.v1alpha1.DMClusterSpecWorker;
        }
        /**
         * dmclusterSpecProvideDefaults sets the appropriate defaults for DMClusterSpec
         */
        export function dmclusterSpecProvideDefaults(val: DMClusterSpec): DMClusterSpec {
            return {
                ...val,
                imagePullPolicy: (val.imagePullPolicy) ?? "IfNotPresent",
                master: (val.master ? outputs.pingcap.v1alpha1.dmclusterSpecMasterProvideDefaults(val.master) : undefined),
                pvReclaimPolicy: (val.pvReclaimPolicy) ?? "Retain",
                worker: (val.worker ? outputs.pingcap.v1alpha1.dmclusterSpecWorkerProvideDefaults(val.worker) : undefined),
            };
        }

        export interface DMClusterSpecAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinity;
        }

        export interface DMClusterSpecAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscovery {
            additionalContainers?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumes[];
            address?: string;
            affinity?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinity;
            annotations?: {[key: string]: string};
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryPodsecuritycontext;
            priorityClassName?: string;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            statefulSetUpdateStrategy?: string;
            suspendAction?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoverySuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryTopologyspreadconstraints[];
            version?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvValuefrom;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersEnvfromSecretref;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestop;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * dmclusterSpecDiscoveryAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for DMClusterSpecDiscoveryAdditionalcontainersPorts
         */
        export function dmclusterSpecDiscoveryAdditionalcontainersPortsProvideDefaults(val: DMClusterSpecDiscoveryAdditionalcontainersPorts): DMClusterSpecDiscoveryAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesVspherevolume;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesDownwardapiItems[];
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesFlexvolumeSecretref;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSources[];
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface DMClusterSpecDiscoveryAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinity;
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecDiscoveryDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryDnsconfigOptions[];
            searches?: string[];
        }

        export interface DMClusterSpecDiscoveryDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface DMClusterSpecDiscoveryEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvValuefrom;
        }

        export interface DMClusterSpecDiscoveryEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecDiscoveryEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecDiscoveryEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecDiscoveryEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryEnvfromSecretref;
        }

        export interface DMClusterSpecDiscoveryEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryImagepullsecrets {
            name?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvValuefrom;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersEnvfromSecretref;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePrestop;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * dmclusterSpecDiscoveryInitcontainersPortsProvideDefaults sets the appropriate defaults for DMClusterSpecDiscoveryInitcontainersPorts
         */
        export function dmclusterSpecDiscoveryInitcontainersPortsProvideDefaults(val: DMClusterSpecDiscoveryInitcontainersPorts): DMClusterSpecDiscoveryInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface DMClusterSpecDiscoveryInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecDiscoveryInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecDiscoveryInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersSecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecDiscoveryInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface DMClusterSpecDiscoveryInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecDiscoveryInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecDiscoveryInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface DMClusterSpecDiscoveryInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecDiscoveryPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecDiscoveryPodsecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecDiscoveryPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecDiscoveryPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecDiscoveryPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface DMClusterSpecDiscoveryPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecDiscoverySuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface DMClusterSpecDiscoveryTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface DMClusterSpecDiscoveryTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface DMClusterSpecDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.DMClusterSpecDnsconfigOptions[];
            searches?: string[];
        }

        export interface DMClusterSpecDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface DMClusterSpecImagepullsecrets {
            name?: string;
        }

        export interface DMClusterSpecMaster {
            additionalContainers?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dataSubDir?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.DMClusterSpecMasterDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.DMClusterSpecMasterImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            maxFailoverCount?: number;
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.DMClusterSpecMasterPodsecuritycontext;
            priorityClassName?: string;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            service?: outputs.pingcap.v1alpha1.DMClusterSpecMasterService;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageSize?: string;
            suspendAction?: outputs.pingcap.v1alpha1.DMClusterSpecMasterSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.DMClusterSpecMasterTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.DMClusterSpecMasterTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * dmclusterSpecMasterProvideDefaults sets the appropriate defaults for DMClusterSpecMaster
         */
        export function dmclusterSpecMasterProvideDefaults(val: DMClusterSpecMaster): DMClusterSpecMaster {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/dm",
            };
        }

        export interface DMClusterSpecMasterAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvValuefrom;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersEnvfromSecretref;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePrestop;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * dmclusterSpecMasterAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for DMClusterSpecMasterAdditionalcontainersPorts
         */
        export function dmclusterSpecMasterAdditionalcontainersPortsProvideDefaults(val: DMClusterSpecMasterAdditionalcontainersPorts): DMClusterSpecMasterAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface DMClusterSpecMasterAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecMasterAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecMasterAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecMasterAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface DMClusterSpecMasterAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecMasterAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface DMClusterSpecMasterAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesVspherevolume;
        }

        export interface DMClusterSpecMasterAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface DMClusterSpecMasterAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesDownwardapiItems[];
        }

        export interface DMClusterSpecMasterAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface DMClusterSpecMasterAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecMasterAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface DMClusterSpecMasterAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesFlexvolumeSecretref;
        }

        export interface DMClusterSpecMasterAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSources[];
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface DMClusterSpecMasterAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface DMClusterSpecMasterAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinity;
        }

        export interface DMClusterSpecMasterAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecMasterAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecMasterAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecMasterAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecMasterAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecMasterDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.DMClusterSpecMasterDnsconfigOptions[];
            searches?: string[];
        }

        export interface DMClusterSpecMasterDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface DMClusterSpecMasterEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvValuefrom;
        }

        export interface DMClusterSpecMasterEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecMasterEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecMasterEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecMasterEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterEnvfromSecretref;
        }

        export interface DMClusterSpecMasterEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterImagepullsecrets {
            name?: string;
        }

        export interface DMClusterSpecMasterInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface DMClusterSpecMasterInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvValuefrom;
        }

        export interface DMClusterSpecMasterInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecMasterInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecMasterInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecMasterInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersEnvfromSecretref;
        }

        export interface DMClusterSpecMasterInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecMasterInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePrestop;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecMasterInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * dmclusterSpecMasterInitcontainersPortsProvideDefaults sets the appropriate defaults for DMClusterSpecMasterInitcontainersPorts
         */
        export function dmclusterSpecMasterInitcontainersPortsProvideDefaults(val: DMClusterSpecMasterInitcontainersPorts): DMClusterSpecMasterInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface DMClusterSpecMasterInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecMasterInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecMasterInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersSecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecMasterInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface DMClusterSpecMasterInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecMasterInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecMasterInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecMasterInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecMasterInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecMasterInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecMasterInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecMasterInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecMasterInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface DMClusterSpecMasterInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecMasterPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecMasterPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.DMClusterSpecMasterPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecMasterPodsecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecMasterPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecMasterPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecMasterPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface DMClusterSpecMasterPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecMasterService {
            annotations?: {[key: string]: string};
            clusterIP?: string;
            externalTrafficPolicy?: string;
            labels?: {[key: string]: string};
            loadBalancerIP?: string;
            loadBalancerSourceRanges?: string[];
            masterNodePort?: number;
            port?: number;
            portName?: string;
            type?: string;
        }

        export interface DMClusterSpecMasterSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface DMClusterSpecMasterTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface DMClusterSpecMasterTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface DMClusterSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.DMClusterSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecPodsecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface DMClusterSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface DMClusterSpecTlscluster {
            enabled?: boolean;
        }

        export interface DMClusterSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface DMClusterSpecTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface DMClusterSpecWorker {
            additionalContainers?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dataSubDir?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvfrom[];
            failover?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerFailover;
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            maxFailoverCount?: number;
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerPodsecuritycontext;
            priorityClassName?: string;
            recoverFailover?: boolean;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageSize?: string;
            suspendAction?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * dmclusterSpecWorkerProvideDefaults sets the appropriate defaults for DMClusterSpecWorker
         */
        export function dmclusterSpecWorkerProvideDefaults(val: DMClusterSpecWorker): DMClusterSpecWorker {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/dm",
            };
        }

        export interface DMClusterSpecWorkerAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvValuefrom;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersEnvfromSecretref;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePrestop;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * dmclusterSpecWorkerAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for DMClusterSpecWorkerAdditionalcontainersPorts
         */
        export function dmclusterSpecWorkerAdditionalcontainersPortsProvideDefaults(val: DMClusterSpecWorkerAdditionalcontainersPorts): DMClusterSpecWorkerAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface DMClusterSpecWorkerAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecWorkerAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface DMClusterSpecWorkerAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesVspherevolume;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface DMClusterSpecWorkerAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesDownwardapiItems[];
        }

        export interface DMClusterSpecWorkerAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecWorkerAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface DMClusterSpecWorkerAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesFlexvolumeSecretref;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSources[];
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface DMClusterSpecWorkerAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface DMClusterSpecWorkerAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinity;
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecWorkerAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface DMClusterSpecWorkerAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface DMClusterSpecWorkerDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerDnsconfigOptions[];
            searches?: string[];
        }

        export interface DMClusterSpecWorkerDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface DMClusterSpecWorkerEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvValuefrom;
        }

        export interface DMClusterSpecWorkerEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecWorkerEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecWorkerEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecWorkerEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerEnvfromSecretref;
        }

        export interface DMClusterSpecWorkerEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerFailover {
            recoverByUID?: string;
        }

        export interface DMClusterSpecWorkerImagepullsecrets {
            name?: string;
        }

        export interface DMClusterSpecWorkerInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvValuefrom;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvValuefromSecretkeyref;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersEnvfromSecretref;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePrestop;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecWorkerInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * dmclusterSpecWorkerInitcontainersPortsProvideDefaults sets the appropriate defaults for DMClusterSpecWorkerInitcontainersPorts
         */
        export function dmclusterSpecWorkerInitcontainersPortsProvideDefaults(val: DMClusterSpecWorkerInitcontainersPorts): DMClusterSpecWorkerInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface DMClusterSpecWorkerInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecWorkerInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface DMClusterSpecWorkerInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersSecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecWorkerInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface DMClusterSpecWorkerInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecWorkerInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface DMClusterSpecWorkerInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface DMClusterSpecWorkerInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface DMClusterSpecWorkerInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface DMClusterSpecWorkerInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface DMClusterSpecWorkerInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface DMClusterSpecWorkerPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.DMClusterSpecWorkerPodsecuritycontextWindowsoptions;
        }

        export interface DMClusterSpecWorkerPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface DMClusterSpecWorkerPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface DMClusterSpecWorkerPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface DMClusterSpecWorkerPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface DMClusterSpecWorkerSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface DMClusterSpecWorkerTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface DMClusterSpecWorkerTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface DMClusterStatus {
            conditions?: outputs.pingcap.v1alpha1.DMClusterStatusConditions[];
            master?: outputs.pingcap.v1alpha1.DMClusterStatusMaster;
            worker?: outputs.pingcap.v1alpha1.DMClusterStatusWorker;
        }

        export interface DMClusterStatusConditions {
            lastTransitionTime?: string;
            lastUpdateTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface DMClusterStatusMaster {
            conditions?: outputs.pingcap.v1alpha1.DMClusterStatusMasterConditions[];
            failureMembers?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusMasterFailuremembers};
            image?: string;
            leader?: outputs.pingcap.v1alpha1.DMClusterStatusMasterLeader;
            members?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusMasterMembers};
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.DMClusterStatusMasterStatefulset;
            synced?: boolean;
            unjoinedMembers?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusMasterUnjoinedmembers};
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusMasterVolumes};
        }

        export interface DMClusterStatusMasterConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface DMClusterStatusMasterFailuremembers {
            createdAt?: string;
            memberDeleted?: boolean;
            memberID?: string;
            podName?: string;
            pvcUID?: string;
        }

        export interface DMClusterStatusMasterLeader {
            clientURL: string;
            health: boolean;
            id: string;
            lastTransitionTime?: string;
            name: string;
        }

        export interface DMClusterStatusMasterMembers {
            clientURL: string;
            health: boolean;
            id: string;
            lastTransitionTime?: string;
            name: string;
        }

        export interface DMClusterStatusMasterStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.DMClusterStatusMasterStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface DMClusterStatusMasterStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface DMClusterStatusMasterUnjoinedmembers {
            createdAt?: string;
            podName?: string;
            pvcUID?: string;
            pvcUIDSet?: {[key: string]: {[key: string]: any}};
        }

        export interface DMClusterStatusMasterVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface DMClusterStatusWorker {
            conditions?: outputs.pingcap.v1alpha1.DMClusterStatusWorkerConditions[];
            failoverUID?: string;
            failureMembers?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusWorkerFailuremembers};
            image?: string;
            members?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusWorkerMembers};
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.DMClusterStatusWorkerStatefulset;
            synced?: boolean;
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.DMClusterStatusWorkerVolumes};
        }

        export interface DMClusterStatusWorkerConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface DMClusterStatusWorkerFailuremembers {
            createdAt?: string;
            podName?: string;
        }

        export interface DMClusterStatusWorkerMembers {
            addr?: string;
            lastTransitionTime?: string;
            name?: string;
            stage: string;
        }

        export interface DMClusterStatusWorkerStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.DMClusterStatusWorkerStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface DMClusterStatusWorkerStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface DMClusterStatusWorkerVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface RestoreSpec {
            affinity?: outputs.pingcap.v1alpha1.RestoreSpecAffinity;
            azblob?: outputs.pingcap.v1alpha1.RestoreSpecAzblob;
            backupType?: string;
            br?: outputs.pingcap.v1alpha1.RestoreSpecBr;
            env?: outputs.pingcap.v1alpha1.RestoreSpecEnv[];
            gcs?: outputs.pingcap.v1alpha1.RestoreSpecGcs;
            imagePullSecrets?: outputs.pingcap.v1alpha1.RestoreSpecImagepullsecrets[];
            local?: outputs.pingcap.v1alpha1.RestoreSpecLocal;
            podSecurityContext?: outputs.pingcap.v1alpha1.RestoreSpecPodsecuritycontext;
            priorityClassName?: string;
            resources?: outputs.pingcap.v1alpha1.RestoreSpecResources;
            s3?: outputs.pingcap.v1alpha1.RestoreSpecS3;
            serviceAccount?: string;
            storageClassName?: string;
            storageSize?: string;
            tableFilter?: string[];
            tikvGCLifeTime?: string;
            to?: outputs.pingcap.v1alpha1.RestoreSpecTo;
            tolerations?: outputs.pingcap.v1alpha1.RestoreSpecTolerations[];
            toolImage?: string;
            useKMS?: boolean;
        }

        export interface RestoreSpecAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinity;
        }

        export interface RestoreSpecAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface RestoreSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface RestoreSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface RestoreSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface RestoreSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface RestoreSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface RestoreSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecAzblob {
            accessTier?: string;
            container?: string;
            path?: string;
            prefix?: string;
            secretName?: string;
        }

        export interface RestoreSpecBr {
            checksum?: boolean;
            cluster: string;
            clusterNamespace?: string;
            concurrency?: number;
            db?: string;
            logLevel?: string;
            onLine?: boolean;
            options?: string[];
            rateLimit?: number;
            sendCredToTikv?: boolean;
            statusAddr?: string;
            table?: string;
            timeAgo?: string;
        }

        export interface RestoreSpecEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.RestoreSpecEnvValuefrom;
        }

        export interface RestoreSpecEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.RestoreSpecEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.RestoreSpecEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.RestoreSpecEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.RestoreSpecEnvValuefromSecretkeyref;
        }

        export interface RestoreSpecEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface RestoreSpecEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface RestoreSpecEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface RestoreSpecEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface RestoreSpecGcs {
            bucket?: string;
            bucketAcl?: string;
            location?: string;
            objectAcl?: string;
            path?: string;
            prefix?: string;
            projectId: string;
            secretName?: string;
            storageClass?: string;
        }

        export interface RestoreSpecImagepullsecrets {
            name?: string;
        }

        export interface RestoreSpecLocal {
            prefix?: string;
            volume: outputs.pingcap.v1alpha1.RestoreSpecLocalVolume;
            volumeMount: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumemount;
        }

        export interface RestoreSpecLocalVolume {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeCephfs;
            cinder?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeCinder;
            configMap?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeConfigmap;
            csi?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeral;
            fc?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeFc;
            flexVolume?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeHostpath;
            iscsi?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumePersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumePhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumePortworxvolume;
            projected?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjected;
            quobyte?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeQuobyte;
            rbd?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeRbd;
            scaleIO?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeScaleio;
            secret?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeSecret;
            storageos?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeVspherevolume;
        }

        export interface RestoreSpecLocalVolumeAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface RestoreSpecLocalVolumeAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface RestoreSpecLocalVolumeAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface RestoreSpecLocalVolumeCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeCephfsSecretref;
            user?: string;
        }

        export interface RestoreSpecLocalVolumeCephfsSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeCinderSecretref;
            volumeID: string;
        }

        export interface RestoreSpecLocalVolumeCinderSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface RestoreSpecLocalVolumeConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface RestoreSpecLocalVolumeCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface RestoreSpecLocalVolumeCsiNodepublishsecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeDownwardapiItems[];
        }

        export interface RestoreSpecLocalVolumeDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeDownwardapiItemsResourcefieldref;
        }

        export interface RestoreSpecLocalVolumeDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface RestoreSpecLocalVolumeDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface RestoreSpecLocalVolumeEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface RestoreSpecLocalVolumeEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeralVolumeclaimtemplate;
        }

        export interface RestoreSpecLocalVolumeEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpec;
        }

        export interface RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface RestoreSpecLocalVolumeEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface RestoreSpecLocalVolumeFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface RestoreSpecLocalVolumeFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeFlexvolumeSecretref;
        }

        export interface RestoreSpecLocalVolumeFlexvolumeSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface RestoreSpecLocalVolumeGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface RestoreSpecLocalVolumeGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface RestoreSpecLocalVolumeGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface RestoreSpecLocalVolumeHostpath {
            path: string;
            type?: string;
        }

        export interface RestoreSpecLocalVolumeIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeIscsiSecretref;
            targetPortal: string;
        }

        export interface RestoreSpecLocalVolumeIscsiSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface RestoreSpecLocalVolumePersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface RestoreSpecLocalVolumePhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface RestoreSpecLocalVolumePortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface RestoreSpecLocalVolumeProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSources[];
        }

        export interface RestoreSpecLocalVolumeProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesServiceaccounttoken;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesDownwardapiItems[];
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface RestoreSpecLocalVolumeProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface RestoreSpecLocalVolumeQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface RestoreSpecLocalVolumeRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeRbdSecretref;
            user?: string;
        }

        export interface RestoreSpecLocalVolumeRbdSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface RestoreSpecLocalVolumeScaleioSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface RestoreSpecLocalVolumeSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface RestoreSpecLocalVolumeStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.RestoreSpecLocalVolumeStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface RestoreSpecLocalVolumeStorageosSecretref {
            name?: string;
        }

        export interface RestoreSpecLocalVolumeVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface RestoreSpecLocalVolumemount {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface RestoreSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.RestoreSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.RestoreSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.RestoreSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.RestoreSpecPodsecuritycontextWindowsoptions;
        }

        export interface RestoreSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface RestoreSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface RestoreSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface RestoreSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface RestoreSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface RestoreSpecS3 {
            acl?: string;
            bucket?: string;
            endpoint?: string;
            options?: string[];
            path?: string;
            prefix?: string;
            provider: string;
            region?: string;
            secretName?: string;
            sse?: string;
            storageClass?: string;
        }

        export interface RestoreSpecTo {
            host: string;
            port?: number;
            secretName: string;
            tlsClientSecretName?: string;
            user?: string;
        }

        export interface RestoreSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface RestoreStatus {
            commitTs?: string;
            conditions?: outputs.pingcap.v1alpha1.RestoreStatusConditions[];
            phase?: string;
            timeCompleted?: string;
            timeStarted?: string;
        }

        export interface RestoreStatusConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterAutoScalerSpec {
            cluster: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecCluster;
            tidb?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTidb;
            tikv?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTikv;
        }

        export interface TidbClusterAutoScalerSpecCluster {
            clusterDomain?: string;
            name: string;
            namespace?: string;
        }

        export interface TidbClusterAutoScalerSpecTidb {
            external?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTidbExternal;
            resources?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTidbResources};
            rules?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTidbRules};
            scaleInIntervalSeconds?: number;
            scaleOutIntervalSeconds?: number;
        }

        export interface TidbClusterAutoScalerSpecTidbExternal {
            endpoint?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTidbExternalEndpoint;
            maxReplicas: number;
        }

        export interface TidbClusterAutoScalerSpecTidbExternalEndpoint {
            host: string;
            path: string;
            port: number;
            tlsSecret?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTidbExternalEndpointTlssecret;
        }

        export interface TidbClusterAutoScalerSpecTidbExternalEndpointTlssecret {
            name: string;
            namespace: string;
        }

        export interface TidbClusterAutoScalerSpecTidbResources {
            count?: number;
            cpu: number | string;
            memory: number | string;
            storage?: number | string;
        }

        export interface TidbClusterAutoScalerSpecTidbRules {
            max_threshold: number;
            min_threshold?: number;
            resource_types?: string[];
        }

        export interface TidbClusterAutoScalerSpecTikv {
            external?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTikvExternal;
            resources?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTikvResources};
            rules?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTikvRules};
            scaleInIntervalSeconds?: number;
            scaleOutIntervalSeconds?: number;
        }

        export interface TidbClusterAutoScalerSpecTikvExternal {
            endpoint?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTikvExternalEndpoint;
            maxReplicas: number;
        }

        export interface TidbClusterAutoScalerSpecTikvExternalEndpoint {
            host: string;
            path: string;
            port: number;
            tlsSecret?: outputs.pingcap.v1alpha1.TidbClusterAutoScalerSpecTikvExternalEndpointTlssecret;
        }

        export interface TidbClusterAutoScalerSpecTikvExternalEndpointTlssecret {
            name: string;
            namespace: string;
        }

        export interface TidbClusterAutoScalerSpecTikvResources {
            count?: number;
            cpu: number | string;
            memory: number | string;
            storage?: number | string;
        }

        export interface TidbClusterAutoScalerSpecTikvRules {
            max_threshold: number;
            min_threshold?: number;
            resource_types?: string[];
        }

        export interface TidbClusterAutoScalerStatus {
            tidb?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterAutoScalerStatusTidb};
            tikv?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterAutoScalerStatusTikv};
        }

        export interface TidbClusterAutoScalerStatusTidb {
            lastAutoScalingTimestamp?: string;
        }

        export interface TidbClusterAutoScalerStatusTikv {
            lastAutoScalingTimestamp?: string;
        }

        export interface TidbClusterSpec {
            acrossK8s?: boolean;
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinity;
            annotations?: {[key: string]: string};
            cluster?: outputs.pingcap.v1alpha1.TidbClusterSpecCluster;
            clusterDomain?: string;
            configUpdateStrategy?: string;
            discovery?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscovery;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecDnsconfig;
            dnsPolicy?: string;
            enableDynamicConfiguration?: boolean;
            enablePVReclaim?: boolean;
            helper?: outputs.pingcap.v1alpha1.TidbClusterSpecHelper;
            hostNetwork?: boolean;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecImagepullsecrets[];
            labels?: {[key: string]: string};
            nodeSelector?: {[key: string]: string};
            paused?: boolean;
            pd?: outputs.pingcap.v1alpha1.TidbClusterSpecPd;
            pdAddresses?: string[];
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPodsecuritycontext;
            priorityClassName?: string;
            pump?: outputs.pingcap.v1alpha1.TidbClusterSpecPump;
            pvReclaimPolicy?: string;
            schedulerName?: string;
            serviceAccount?: string;
            services?: outputs.pingcap.v1alpha1.TidbClusterSpecServices[];
            statefulSetUpdateStrategy?: string;
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecSuspendaction;
            ticdc?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdc;
            tidb?: outputs.pingcap.v1alpha1.TidbClusterSpecTidb;
            tiflash?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflash;
            tikv?: outputs.pingcap.v1alpha1.TidbClusterSpecTikv;
            timezone?: string;
            tlsCluster?: outputs.pingcap.v1alpha1.TidbClusterSpecTlscluster;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecProvideDefaults sets the appropriate defaults for TidbClusterSpec
         */
        export function tidbClusterSpecProvideDefaults(val: TidbClusterSpec): TidbClusterSpec {
            return {
                ...val,
                imagePullPolicy: (val.imagePullPolicy) ?? "IfNotPresent",
                pd: (val.pd ? outputs.pingcap.v1alpha1.tidbClusterSpecPdProvideDefaults(val.pd) : undefined),
                pump: (val.pump ? outputs.pingcap.v1alpha1.tidbClusterSpecPumpProvideDefaults(val.pump) : undefined),
                pvReclaimPolicy: (val.pvReclaimPolicy) ?? "Retain",
                ticdc: (val.ticdc ? outputs.pingcap.v1alpha1.tidbClusterSpecTicdcProvideDefaults(val.ticdc) : undefined),
                tidb: (val.tidb ? outputs.pingcap.v1alpha1.tidbClusterSpecTidbProvideDefaults(val.tidb) : undefined),
                tiflash: (val.tiflash ? outputs.pingcap.v1alpha1.tidbClusterSpecTiflashProvideDefaults(val.tiflash) : undefined),
                tikv: (val.tikv ? outputs.pingcap.v1alpha1.tidbClusterSpecTikvProvideDefaults(val.tikv) : undefined),
            };
        }

        export interface TidbClusterSpecAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecCluster {
            clusterDomain?: string;
            name: string;
            namespace?: string;
        }

        export interface TidbClusterSpecDiscovery {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinity;
            annotations?: {[key: string]: string};
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryPodsecuritycontext;
            priorityClassName?: string;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            statefulSetUpdateStrategy?: string;
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoverySuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryTopologyspreadconstraints[];
            version?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecDiscoveryAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecDiscoveryAdditionalcontainersPorts
         */
        export function tidbClusterSpecDiscoveryAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecDiscoveryAdditionalcontainersPorts): TidbClusterSpecDiscoveryAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecDiscoveryAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecDiscoveryAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecDiscoveryAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecDiscoveryDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecDiscoveryDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecDiscoveryEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvValuefrom;
        }

        export interface TidbClusterSpecDiscoveryEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecDiscoveryEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecDiscoveryEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecDiscoveryEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryEnvfromSecretref;
        }

        export interface TidbClusterSpecDiscoveryEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecDiscoveryInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecDiscoveryInitcontainersPorts
         */
        export function tidbClusterSpecDiscoveryInitcontainersPortsProvideDefaults(val: TidbClusterSpecDiscoveryInitcontainersPorts): TidbClusterSpecDiscoveryInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecDiscoveryInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecDiscoveryInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecDiscoveryInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecDiscoveryInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecDiscoveryInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecDiscoveryPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecDiscoveryPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecDiscoveryPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecDiscoveryPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecDiscoveryPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecDiscoveryPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecDiscoverySuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecDiscoveryTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecDiscoveryTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecHelper {
            image?: string;
            imagePullPolicy?: string;
        }

        export interface TidbClusterSpecImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecPd {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dataSubDir?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecPdDnsconfig;
            dnsPolicy?: string;
            enableDashboardInternalProxy?: boolean;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecPdImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            maxFailoverCount?: number;
            mountClusterClientSecret?: boolean;
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPdPodsecuritycontext;
            priorityClassName?: string;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            service?: outputs.pingcap.v1alpha1.TidbClusterSpecPdService;
            serviceAccount?: string;
            startUpScriptVersion?: string;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecPdStoragevolumes[];
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecPdSuspendaction;
            terminationGracePeriodSeconds?: number;
            tlsClientSecretName?: string;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecPdTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecPdTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecPdProvideDefaults sets the appropriate defaults for TidbClusterSpecPd
         */
        export function tidbClusterSpecPdProvideDefaults(val: TidbClusterSpecPd): TidbClusterSpecPd {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/pd",
            };
        }

        export interface TidbClusterSpecPdAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecPdAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecPdAdditionalcontainersPorts
         */
        export function tidbClusterSpecPdAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecPdAdditionalcontainersPorts): TidbClusterSpecPdAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecPdAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPdAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecPdAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPdAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecPdAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPdAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecPdAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecPdAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecPdAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecPdAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecPdAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPdAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecPdAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecPdAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPdAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecPdAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecPdAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPdAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPdAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPdAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPdAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPdDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecPdDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecPdDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecPdEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvValuefrom;
        }

        export interface TidbClusterSpecPdEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecPdEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPdEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPdEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdEnvfromSecretref;
        }

        export interface TidbClusterSpecPdEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecPdInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecPdInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecPdInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecPdInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPdInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPdInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecPdInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPdInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPdInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecPdInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecPdInitcontainersPorts
         */
        export function tidbClusterSpecPdInitcontainersPortsProvideDefaults(val: TidbClusterSpecPdInitcontainersPorts): TidbClusterSpecPdInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecPdInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPdInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecPdInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPdInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecPdInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPdInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPdInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPdInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPdInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPdInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPdInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPdInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPdInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecPdInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecPdPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPdPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecPdPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPdPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPdPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPdPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPdPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPdPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPdService {
            annotations?: {[key: string]: string};
            clusterIP?: string;
            labels?: {[key: string]: string};
            loadBalancerIP?: string;
            loadBalancerSourceRanges?: string[];
            port?: number;
            portName?: string;
            type?: string;
        }

        export interface TidbClusterSpecPdStoragevolumes {
            mountPath?: string;
            name: string;
            storageClassName?: string;
            storageSize: string;
        }

        export interface TidbClusterSpecPdSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecPdTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecPdTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPump {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpPodsecuritycontext;
            priorityClassName?: string;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            serviceAccount?: string;
            setTimeZone?: boolean;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecPumpProvideDefaults sets the appropriate defaults for TidbClusterSpecPump
         */
        export function tidbClusterSpecPumpProvideDefaults(val: TidbClusterSpecPump): TidbClusterSpecPump {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/tidb-binlog",
            };
        }

        export interface TidbClusterSpecPumpAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecPumpAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecPumpAdditionalcontainersPorts
         */
        export function tidbClusterSpecPumpAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecPumpAdditionalcontainersPorts): TidbClusterSpecPumpAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecPumpAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecPumpAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecPumpAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecPumpAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecPumpAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPumpAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecPumpAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecPumpAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecPumpAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPumpAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecPumpAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecPumpDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecPumpDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecPumpEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvValuefrom;
        }

        export interface TidbClusterSpecPumpEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecPumpEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPumpEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPumpEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpEnvfromSecretref;
        }

        export interface TidbClusterSpecPumpEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecPumpInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPumpInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecPumpInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecPumpInitcontainersPorts
         */
        export function tidbClusterSpecPumpInitcontainersPortsProvideDefaults(val: TidbClusterSpecPumpInitcontainersPorts): TidbClusterSpecPumpInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecPumpInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPumpInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecPumpInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPumpInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecPumpInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPumpInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecPumpInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecPumpInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecPumpInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecPumpInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecPumpInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecPumpPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecPumpPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecPumpPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecPumpPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecPumpPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecPumpPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecPumpSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecPumpTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecPumpTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecServices {
            name?: string;
            type?: string;
        }

        export interface TidbClusterSpecSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecTicdc {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvfrom[];
            gracefulShutdownTimeout?: string;
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcPodsecuritycontext;
            priorityClassName?: string;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            serviceAccount?: string;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcStoragevolumes[];
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcSuspendaction;
            terminationGracePeriodSeconds?: number;
            tlsClientSecretNames?: string[];
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecTicdcProvideDefaults sets the appropriate defaults for TidbClusterSpecTicdc
         */
        export function tidbClusterSpecTicdcProvideDefaults(val: TidbClusterSpecTicdc): TidbClusterSpecTicdc {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/ticdc",
            };
        }

        export interface TidbClusterSpecTicdcAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTicdcAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTicdcAdditionalcontainersPorts
         */
        export function tidbClusterSpecTicdcAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecTicdcAdditionalcontainersPorts): TidbClusterSpecTicdcAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTicdcAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTicdcAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecTicdcAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTicdcAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTicdcAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTicdcDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecTicdcDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecTicdcEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvValuefrom;
        }

        export interface TidbClusterSpecTicdcEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTicdcEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTicdcEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTicdcEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcEnvfromSecretref;
        }

        export interface TidbClusterSpecTicdcEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTicdcInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTicdcInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTicdcInitcontainersPorts
         */
        export function tidbClusterSpecTicdcInitcontainersPortsProvideDefaults(val: TidbClusterSpecTicdcInitcontainersPorts): TidbClusterSpecTicdcInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTicdcInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTicdcInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTicdcInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTicdcInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTicdcInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTicdcInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTicdcInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTicdcInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTicdcInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTicdcPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTicdcPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTicdcPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTicdcPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTicdcPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTicdcPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTicdcStoragevolumes {
            mountPath?: string;
            name: string;
            storageClassName?: string;
            storageSize: string;
        }

        export interface TidbClusterSpecTicdcSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecTicdcTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecTicdcTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecTidb {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            binlogEnabled?: boolean;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainers[];
            initializer?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitializer;
            labels?: {[key: string]: string};
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecycle;
            limits?: {[key: string]: number | string};
            maxFailoverCount?: number;
            nodeSelector?: {[key: string]: string};
            plugins?: string[];
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbPodsecuritycontext;
            priorityClassName?: string;
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbReadinessprobe;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            separateSlowLog?: boolean;
            service?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbService;
            serviceAccount?: string;
            slowLogTailer?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbSlowlogtailer;
            slowLogVolumeName?: string;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbStoragevolumes[];
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbSuspendaction;
            terminationGracePeriodSeconds?: number;
            tlsClient?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbTlsclient;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecTidbProvideDefaults sets the appropriate defaults for TidbClusterSpecTidb
         */
        export function tidbClusterSpecTidbProvideDefaults(val: TidbClusterSpecTidb): TidbClusterSpecTidb {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/tidb",
            };
        }

        export interface TidbClusterSpecTidbAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTidbAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTidbAdditionalcontainersPorts
         */
        export function tidbClusterSpecTidbAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecTidbAdditionalcontainersPorts): TidbClusterSpecTidbAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTidbAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTidbAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTidbAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecTidbAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecTidbAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTidbAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecTidbAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTidbAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecTidbAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTidbAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTidbAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTidbDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecTidbDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecTidbEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvValuefrom;
        }

        export interface TidbClusterSpecTidbEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTidbEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTidbEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTidbEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbEnvfromSecretref;
        }

        export interface TidbClusterSpecTidbEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecTidbInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTidbInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTidbInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTidbInitcontainersPorts
         */
        export function tidbClusterSpecTidbInitcontainersPortsProvideDefaults(val: TidbClusterSpecTidbInitcontainersPorts): TidbClusterSpecTidbInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTidbInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTidbInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTidbInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTidbInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTidbInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTidbInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTidbInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTidbInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTidbInitializer {
            createPassword?: boolean;
        }

        export interface TidbClusterSpecTidbLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePrestop;
        }

        export interface TidbClusterSpecTidbLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTidbLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTidbLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTidbLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTidbLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTidbPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTidbPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTidbPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTidbPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTidbPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTidbReadinessprobe {
            initialDelaySeconds?: number;
            periodSeconds?: number;
            type?: string;
        }

        export interface TidbClusterSpecTidbService {
            additionalPorts?: outputs.pingcap.v1alpha1.TidbClusterSpecTidbServiceAdditionalports[];
            annotations?: {[key: string]: string};
            clusterIP?: string;
            exposeStatus?: boolean;
            externalTrafficPolicy?: string;
            labels?: {[key: string]: string};
            loadBalancerIP?: string;
            loadBalancerSourceRanges?: string[];
            mysqlNodePort?: number;
            port?: number;
            portName?: string;
            statusNodePort?: number;
            type?: string;
        }

        export interface TidbClusterSpecTidbServiceAdditionalports {
            appProtocol?: string;
            name?: string;
            nodePort?: number;
            port: number;
            protocol?: string;
            targetPort?: number | string;
        }
        /**
         * tidbClusterSpecTidbServiceAdditionalportsProvideDefaults sets the appropriate defaults for TidbClusterSpecTidbServiceAdditionalports
         */
        export function tidbClusterSpecTidbServiceAdditionalportsProvideDefaults(val: TidbClusterSpecTidbServiceAdditionalports): TidbClusterSpecTidbServiceAdditionalports {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTidbSlowlogtailer {
            image?: string;
            imagePullPolicy?: string;
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTidbStoragevolumes {
            mountPath?: string;
            name: string;
            storageClassName?: string;
            storageSize: string;
        }

        export interface TidbClusterSpecTidbSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecTidbTlsclient {
            disableClientAuthn?: boolean;
            enabled?: boolean;
            skipInternalClientCA?: boolean;
        }

        export interface TidbClusterSpecTidbTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecTidbTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecTiflash {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashConfig;
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvfrom[];
            failover?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashFailover;
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainers[];
            initializer?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitializer;
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            logTailer?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashLogtailer;
            maxFailoverCount?: number;
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashPodsecuritycontext;
            priorityClassName?: string;
            privileged?: boolean;
            recoverFailover?: boolean;
            replicas: number;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            serviceAccount?: string;
            statefulSetUpdateStrategy?: string;
            storageClaims: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashStorageclaims[];
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecTiflashProvideDefaults sets the appropriate defaults for TidbClusterSpecTiflash
         */
        export function tidbClusterSpecTiflashProvideDefaults(val: TidbClusterSpecTiflash): TidbClusterSpecTiflash {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/tiflash",
            };
        }

        export interface TidbClusterSpecTiflashAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTiflashAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTiflashAdditionalcontainersPorts
         */
        export function tidbClusterSpecTiflashAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecTiflashAdditionalcontainersPorts): TidbClusterSpecTiflashAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTiflashAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTiflashAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecTiflashAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTiflashAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTiflashAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTiflashConfig {
            config?: {[key: string]: any};
            proxy?: {[key: string]: any};
        }

        export interface TidbClusterSpecTiflashDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecTiflashDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecTiflashEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvValuefrom;
        }

        export interface TidbClusterSpecTiflashEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTiflashEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTiflashEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTiflashEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashEnvfromSecretref;
        }

        export interface TidbClusterSpecTiflashEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashFailover {
            recoverByUID?: string;
        }

        export interface TidbClusterSpecTiflashImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTiflashInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTiflashInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTiflashInitcontainersPorts
         */
        export function tidbClusterSpecTiflashInitcontainersPortsProvideDefaults(val: TidbClusterSpecTiflashInitcontainersPorts): TidbClusterSpecTiflashInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTiflashInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTiflashInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTiflashInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTiflashInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTiflashInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTiflashInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTiflashInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTiflashInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTiflashInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTiflashInitializer {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTiflashLogtailer {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTiflashPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTiflashPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTiflashPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTiflashPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTiflashPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTiflashStorageclaims {
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTiflashStorageclaimsResources;
            storageClassName?: string;
        }

        export interface TidbClusterSpecTiflashStorageclaimsResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTiflashSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecTiflashTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecTiflashTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecTikv {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dataSubDir?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvDnsconfig;
            dnsPolicy?: string;
            enableNamedStatusPort?: boolean;
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvfrom[];
            evictLeaderTimeout?: string;
            failover?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvFailover;
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            logTailer?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvLogtailer;
            maxFailoverCount?: number;
            mountClusterClientSecret?: boolean;
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvPodsecuritycontext;
            priorityClassName?: string;
            privileged?: boolean;
            raftLogVolumeName?: string;
            recoverFailover?: boolean;
            replicas: number;
            requests?: {[key: string]: number | string};
            rocksDBLogVolumeName?: string;
            schedulerName?: string;
            separateRaftLog?: boolean;
            separateRocksDBLog?: boolean;
            serviceAccount?: string;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageVolumes?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvStoragevolumes[];
            storeLabels?: string[];
            suspendAction?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbClusterSpecTikvProvideDefaults sets the appropriate defaults for TidbClusterSpecTikv
         */
        export function tidbClusterSpecTikvProvideDefaults(val: TidbClusterSpecTikv): TidbClusterSpecTikv {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/tikv",
            };
        }

        export interface TidbClusterSpecTikvAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTikvAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTikvAdditionalcontainersPorts
         */
        export function tidbClusterSpecTikvAdditionalcontainersPortsProvideDefaults(val: TidbClusterSpecTikvAdditionalcontainersPorts): TidbClusterSpecTikvAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTikvAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTikvAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTikvAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesVspherevolume;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbClusterSpecTikvAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbClusterSpecTikvAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTikvAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbClusterSpecTikvAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSources[];
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbClusterSpecTikvAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbClusterSpecTikvAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinity;
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTikvAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbClusterSpecTikvAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbClusterSpecTikvDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbClusterSpecTikvDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbClusterSpecTikvEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvValuefrom;
        }

        export interface TidbClusterSpecTikvEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTikvEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTikvEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTikvEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvEnvfromSecretref;
        }

        export interface TidbClusterSpecTikvEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvFailover {
            recoverByUID?: string;
        }

        export interface TidbClusterSpecTikvImagepullsecrets {
            name?: string;
        }

        export interface TidbClusterSpecTikvInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvValuefrom;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersEnvfromSecretref;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePrestop;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTikvInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbClusterSpecTikvInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbClusterSpecTikvInitcontainersPorts
         */
        export function tidbClusterSpecTikvInitcontainersPortsProvideDefaults(val: TidbClusterSpecTikvInitcontainersPorts): TidbClusterSpecTikvInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbClusterSpecTikvInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTikvInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTikvInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTikvInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbClusterSpecTikvInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTikvInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbClusterSpecTikvInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbClusterSpecTikvInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbClusterSpecTikvInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbClusterSpecTikvInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbClusterSpecTikvInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbClusterSpecTikvLogtailer {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbClusterSpecTikvPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbClusterSpecTikvPodsecuritycontextWindowsoptions;
        }

        export interface TidbClusterSpecTikvPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbClusterSpecTikvPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbClusterSpecTikvPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbClusterSpecTikvPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbClusterSpecTikvStoragevolumes {
            mountPath?: string;
            name: string;
            storageClassName?: string;
            storageSize: string;
        }

        export interface TidbClusterSpecTikvSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbClusterSpecTikvTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecTikvTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterSpecTlscluster {
            enabled?: boolean;
        }

        export interface TidbClusterSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbClusterSpecTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbClusterStatus {
            "auto-scaler"?: outputs.pingcap.v1alpha1.TidbClusterStatusAutoScaler;
            clusterID?: string;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusConditions[];
            pd?: outputs.pingcap.v1alpha1.TidbClusterStatusPd;
            pump?: outputs.pingcap.v1alpha1.TidbClusterStatusPump;
            ticdc?: outputs.pingcap.v1alpha1.TidbClusterStatusTicdc;
            tidb?: outputs.pingcap.v1alpha1.TidbClusterStatusTidb;
            tiflash?: outputs.pingcap.v1alpha1.TidbClusterStatusTiflash;
            tikv?: outputs.pingcap.v1alpha1.TidbClusterStatusTikv;
        }

        export interface TidbClusterStatusAutoScaler {
            name: string;
            namespace: string;
        }

        export interface TidbClusterStatusConditions {
            lastTransitionTime?: string;
            lastUpdateTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusPd {
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusPdConditions[];
            failureMembers?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusPdFailuremembers};
            image?: string;
            leader?: outputs.pingcap.v1alpha1.TidbClusterStatusPdLeader;
            members?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusPdMembers};
            peerMembers?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusPdPeermembers};
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.TidbClusterStatusPdStatefulset;
            synced?: boolean;
            unjoinedMembers?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusPdUnjoinedmembers};
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusPdVolumes};
        }

        export interface TidbClusterStatusPdConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusPdFailuremembers {
            createdAt?: string;
            memberDeleted?: boolean;
            memberID?: string;
            podName?: string;
            pvcUID?: string;
            pvcUIDSet?: {[key: string]: {[key: string]: any}};
        }

        export interface TidbClusterStatusPdLeader {
            clientURL: string;
            health: boolean;
            id: string;
            lastTransitionTime?: string;
            name: string;
        }

        export interface TidbClusterStatusPdMembers {
            clientURL: string;
            health: boolean;
            id: string;
            lastTransitionTime?: string;
            name: string;
        }

        export interface TidbClusterStatusPdPeermembers {
            clientURL: string;
            health: boolean;
            id: string;
            lastTransitionTime?: string;
            name: string;
        }

        export interface TidbClusterStatusPdStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusPdStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbClusterStatusPdStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusPdUnjoinedmembers {
            createdAt?: string;
            podName?: string;
            pvcUID?: string;
            pvcUIDSet?: {[key: string]: {[key: string]: any}};
        }

        export interface TidbClusterStatusPdVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface TidbClusterStatusPump {
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusPumpConditions[];
            members?: outputs.pingcap.v1alpha1.TidbClusterStatusPumpMembers[];
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.TidbClusterStatusPumpStatefulset;
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusPumpVolumes};
        }

        export interface TidbClusterStatusPumpConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusPumpMembers {
            host: string;
            nodeId: string;
            state: string;
        }

        export interface TidbClusterStatusPumpStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusPumpStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbClusterStatusPumpStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusPumpVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface TidbClusterStatusTicdc {
            captures?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTicdcCaptures};
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTicdcConditions[];
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.TidbClusterStatusTicdcStatefulset;
            synced?: boolean;
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTicdcVolumes};
        }

        export interface TidbClusterStatusTicdcCaptures {
            id?: string;
            isOwner?: boolean;
            podName?: string;
            ready?: boolean;
            version?: string;
        }

        export interface TidbClusterStatusTicdcConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTicdcStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTicdcStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbClusterStatusTicdcStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTicdcVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface TidbClusterStatusTidb {
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTidbConditions[];
            failureMembers?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTidbFailuremembers};
            image?: string;
            members?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTidbMembers};
            passwordInitialized?: boolean;
            phase?: string;
            resignDDLOwnerRetryCount?: number;
            statefulSet?: outputs.pingcap.v1alpha1.TidbClusterStatusTidbStatefulset;
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTidbVolumes};
        }

        export interface TidbClusterStatusTidbConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTidbFailuremembers {
            createdAt?: string;
            podName?: string;
        }

        export interface TidbClusterStatusTidbMembers {
            health: boolean;
            lastTransitionTime?: string;
            name: string;
            node?: string;
        }

        export interface TidbClusterStatusTidbStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTidbStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbClusterStatusTidbStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTidbVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface TidbClusterStatusTiflash {
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashConditions[];
            failoverUID?: string;
            failureStores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashFailurestores};
            image?: string;
            peerStores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashPeerstores};
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashStatefulset;
            stores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashStores};
            synced?: boolean;
            tombstoneStores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashTombstonestores};
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashVolumes};
        }

        export interface TidbClusterStatusTiflashConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTiflashFailurestores {
            createdAt?: string;
            podName?: string;
            storeID?: string;
        }

        export interface TidbClusterStatusTiflashPeerstores {
            id: string;
            ip: string;
            lastTransitionTime?: string;
            leaderCount: number;
            podName: string;
            state: string;
        }

        export interface TidbClusterStatusTiflashStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTiflashStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbClusterStatusTiflashStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTiflashStores {
            id: string;
            ip: string;
            lastTransitionTime?: string;
            leaderCount: number;
            podName: string;
            state: string;
        }

        export interface TidbClusterStatusTiflashTombstonestores {
            id: string;
            ip: string;
            lastTransitionTime?: string;
            leaderCount: number;
            podName: string;
            state: string;
        }

        export interface TidbClusterStatusTiflashVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface TidbClusterStatusTikv {
            bootStrapped?: boolean;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTikvConditions[];
            evictLeader?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTikvEvictleader};
            failoverUID?: string;
            failureStores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTikvFailurestores};
            image?: string;
            peerStores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTikvPeerstores};
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.TidbClusterStatusTikvStatefulset;
            stores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTikvStores};
            synced?: boolean;
            tombstoneStores?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTikvTombstonestores};
            volumes?: {[key: string]: outputs.pingcap.v1alpha1.TidbClusterStatusTikvVolumes};
        }

        export interface TidbClusterStatusTikvConditions {
            lastTransitionTime: string;
            message: string;
            observedGeneration?: number;
            reason: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTikvEvictleader {
            beginTime?: string;
            podCreateTime?: string;
            value?: string;
        }

        export interface TidbClusterStatusTikvFailurestores {
            createdAt?: string;
            podName?: string;
            storeID?: string;
        }

        export interface TidbClusterStatusTikvPeerstores {
            id: string;
            ip: string;
            lastTransitionTime?: string;
            leaderCount: number;
            podName: string;
            state: string;
        }

        export interface TidbClusterStatusTikvStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbClusterStatusTikvStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbClusterStatusTikvStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbClusterStatusTikvStores {
            id: string;
            ip: string;
            lastTransitionTime?: string;
            leaderCount: number;
            podName: string;
            state: string;
        }

        export interface TidbClusterStatusTikvTombstonestores {
            id: string;
            ip: string;
            lastTransitionTime?: string;
            leaderCount: number;
            podName: string;
            state: string;
        }

        export interface TidbClusterStatusTikvVolumes {
            boundCount?: number;
            currentCapacity: number | string;
            currentCount?: number;
            name: string;
            resizedCapacity: number | string;
            resizedCount?: number;
        }

        export interface TidbInitializerSpec {
            cluster: outputs.pingcap.v1alpha1.TidbInitializerSpecCluster;
            image: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbInitializerSpecImagepullsecrets[];
            initSql?: string;
            initSqlConfigMap?: string;
            passwordSecret?: string;
            permitHost?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbInitializerSpecPodsecuritycontext;
            resources?: outputs.pingcap.v1alpha1.TidbInitializerSpecResources;
            timezone?: string;
            tlsClientSecretName?: string;
        }

        export interface TidbInitializerSpecCluster {
            clusterDomain?: string;
            name: string;
            namespace?: string;
        }

        export interface TidbInitializerSpecImagepullsecrets {
            name?: string;
        }

        export interface TidbInitializerSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbInitializerSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbInitializerSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbInitializerSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbInitializerSpecPodsecuritycontextWindowsoptions;
        }

        export interface TidbInitializerSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbInitializerSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbInitializerSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbInitializerSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbInitializerSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbInitializerStatus {
            active?: number;
            completionTime?: string;
            conditions?: outputs.pingcap.v1alpha1.TidbInitializerStatusConditions[];
            failed?: number;
            phase?: string;
            startTime?: string;
            succeeded?: number;
        }

        export interface TidbInitializerStatusConditions {
            lastProbeTime?: string;
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbMonitorSpec {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainers[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumes[];
            alertManagerRulesVersion?: string;
            alertmanagerURL?: string;
            annotations?: {[key: string]: string};
            clusterScoped?: boolean;
            clusters?: outputs.pingcap.v1alpha1.TidbMonitorSpecClusters[];
            dm?: outputs.pingcap.v1alpha1.TidbMonitorSpecDm;
            enableAlertRules?: boolean;
            externalLabels?: {[key: string]: string};
            grafana?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafana;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbMonitorSpecImagepullsecrets[];
            initializer: outputs.pingcap.v1alpha1.TidbMonitorSpecInitializer;
            kubePrometheusURL?: string;
            labels?: {[key: string]: string};
            nodeSelector?: {[key: string]: string};
            persistent?: boolean;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbMonitorSpecPodsecuritycontext;
            prometheus: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheus;
            prometheusReloader?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusreloader;
            pvReclaimPolicy?: string;
            reloader: outputs.pingcap.v1alpha1.TidbMonitorSpecReloader;
            replicaExternalLabelName?: string;
            replicas?: number;
            shards?: number;
            storage?: string;
            storageClassName?: string;
            thanos?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanos;
            timezone?: string;
            tolerations?: outputs.pingcap.v1alpha1.TidbMonitorSpecTolerations[];
        }
        /**
         * tidbMonitorSpecProvideDefaults sets the appropriate defaults for TidbMonitorSpec
         */
        export function tidbMonitorSpecProvideDefaults(val: TidbMonitorSpec): TidbMonitorSpec {
            return {
                ...val,
                pvReclaimPolicy: (val.pvReclaimPolicy) ?? "Retain",
            };
        }

        export interface TidbMonitorSpecAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvValuefrom;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbMonitorSpecAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbMonitorSpecAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbMonitorSpecAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbMonitorSpecAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbMonitorSpecAdditionalcontainersPorts
         */
        export function tidbMonitorSpecAdditionalcontainersPortsProvideDefaults(val: TidbMonitorSpecAdditionalcontainersPorts): TidbMonitorSpecAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbMonitorSpecAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbMonitorSpecAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbMonitorSpecAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbMonitorSpecAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbMonitorSpecAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbMonitorSpecAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbMonitorSpecAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbMonitorSpecAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbMonitorSpecAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbMonitorSpecAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbMonitorSpecAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesVspherevolume;
        }

        export interface TidbMonitorSpecAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbMonitorSpecAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbMonitorSpecAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbMonitorSpecAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbMonitorSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbMonitorSpecAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbMonitorSpecAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbMonitorSpecAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSources[];
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbMonitorSpecAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbMonitorSpecClusters {
            clusterDomain?: string;
            name: string;
            namespace?: string;
        }

        export interface TidbMonitorSpecDm {
            clusters: outputs.pingcap.v1alpha1.TidbMonitorSpecDmClusters[];
            initializer: outputs.pingcap.v1alpha1.TidbMonitorSpecDmInitializer;
        }

        export interface TidbMonitorSpecDmClusters {
            clusterDomain?: string;
            name: string;
            namespace?: string;
        }

        export interface TidbMonitorSpecDmInitializer {
            baseImage?: string;
            envs?: {[key: string]: string};
            imagePullPolicy?: string;
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
            version?: string;
        }

        export interface TidbMonitorSpecGrafana {
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafanaAdditionalvolumemounts[];
            baseImage?: string;
            envs?: {[key: string]: string};
            imagePullPolicy?: string;
            ingress?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafanaIngress;
            limits?: {[key: string]: number | string};
            logLevel?: string;
            password?: string;
            passwordSecret?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafanaPasswordsecret;
            requests?: {[key: string]: number | string};
            service?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafanaService;
            username?: string;
            usernameSecret?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafanaUsernamesecret;
            version?: string;
        }

        export interface TidbMonitorSpecGrafanaAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbMonitorSpecGrafanaIngress {
            annotations?: {[key: string]: string};
            hosts: string[];
            tls?: outputs.pingcap.v1alpha1.TidbMonitorSpecGrafanaIngressTls[];
        }

        export interface TidbMonitorSpecGrafanaIngressTls {
            hosts?: string[];
            secretName?: string;
        }

        export interface TidbMonitorSpecGrafanaPasswordsecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecGrafanaService {
            annotations?: {[key: string]: string};
            clusterIP?: string;
            labels?: {[key: string]: string};
            loadBalancerIP?: string;
            loadBalancerSourceRanges?: string[];
            port?: number;
            portName?: string;
            type?: string;
        }

        export interface TidbMonitorSpecGrafanaUsernamesecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecImagepullsecrets {
            name?: string;
        }

        export interface TidbMonitorSpecInitializer {
            baseImage?: string;
            envs?: {[key: string]: string};
            imagePullPolicy?: string;
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
            version?: string;
        }

        export interface TidbMonitorSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbMonitorSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbMonitorSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbMonitorSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbMonitorSpecPodsecuritycontextWindowsoptions;
        }

        export interface TidbMonitorSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbMonitorSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbMonitorSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbMonitorSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbMonitorSpecPrometheus {
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusAdditionalvolumemounts[];
            baseImage?: string;
            config?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusConfig;
            disableCompaction?: boolean;
            imagePullPolicy?: string;
            ingress?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusIngress;
            limits?: {[key: string]: number | string};
            logLevel?: string;
            remoteWrite?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewrite[];
            requests?: {[key: string]: number | string};
            reserveDays?: number;
            retentionTime?: string;
            service?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusService;
            version?: string;
        }

        export interface TidbMonitorSpecPrometheusAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbMonitorSpecPrometheusConfig {
            commandOptions?: string[];
            configMapRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusConfigConfigmapref;
            ruleConfigRef?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusConfigRuleconfigref;
        }

        export interface TidbMonitorSpecPrometheusConfigConfigmapref {
            name?: string;
            namespace?: string;
        }

        export interface TidbMonitorSpecPrometheusConfigRuleconfigref {
            name?: string;
            namespace?: string;
        }

        export interface TidbMonitorSpecPrometheusIngress {
            annotations?: {[key: string]: string};
            hosts: string[];
            tls?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusIngressTls[];
        }

        export interface TidbMonitorSpecPrometheusIngressTls {
            hosts?: string[];
            secretName?: string;
        }

        export interface TidbMonitorSpecPrometheusRemotewrite {
            basicAuth?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteBasicauth;
            bearerToken?: string;
            bearerTokenFile?: string;
            proxyUrl?: string;
            queueConfig?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteQueueconfig;
            remoteTimeout?: number;
            tlsConfig?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfig;
            url: string;
            writeRelabelConfigs?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteWriterelabelconfigs[];
        }

        export interface TidbMonitorSpecPrometheusRemotewriteBasicauth {
            password?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteBasicauthPassword;
            username?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteBasicauthUsername;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteBasicauthPassword {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteBasicauthUsername {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteQueueconfig {
            batchSendDeadline?: number;
            capacity?: number;
            maxBackoff?: number;
            maxRetries?: number;
            maxSamplesPerSend?: number;
            maxShards?: number;
            minBackoff?: number;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfig {
            ca?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigCa;
            caFile?: string;
            cert?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigCert;
            certFile?: string;
            insecureSkipVerify?: boolean;
            keyFile?: string;
            keySecret?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigKeysecret;
            serverName?: string;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigCa {
            configMap?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigCaConfigmap;
            secret?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigCaSecret;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigCaConfigmap {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigCaSecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigCert {
            configMap?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigCertConfigmap;
            secret?: outputs.pingcap.v1alpha1.TidbMonitorSpecPrometheusRemotewriteTlsconfigCertSecret;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigCertConfigmap {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigCertSecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteTlsconfigKeysecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecPrometheusRemotewriteWriterelabelconfigs {
            action?: string;
            modulus?: number;
            regex?: string;
            replacement?: string;
            separator?: string;
            sourceLabels?: string[];
            targetLabel?: string;
        }

        export interface TidbMonitorSpecPrometheusService {
            annotations?: {[key: string]: string};
            clusterIP?: string;
            labels?: {[key: string]: string};
            loadBalancerIP?: string;
            loadBalancerSourceRanges?: string[];
            port?: number;
            portName?: string;
            type?: string;
        }

        export interface TidbMonitorSpecPrometheusreloader {
            baseImage?: string;
            imagePullPolicy?: string;
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
            version?: string;
        }

        export interface TidbMonitorSpecReloader {
            baseImage?: string;
            imagePullPolicy?: string;
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
            service?: outputs.pingcap.v1alpha1.TidbMonitorSpecReloaderService;
            version?: string;
        }

        export interface TidbMonitorSpecReloaderService {
            annotations?: {[key: string]: string};
            clusterIP?: string;
            labels?: {[key: string]: string};
            loadBalancerIP?: string;
            loadBalancerSourceRanges?: string[];
            port?: number;
            portName?: string;
            type?: string;
        }

        export interface TidbMonitorSpecThanos {
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosAdditionalvolumemounts[];
            baseImage?: string;
            grpcServerTlsConfig?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfig;
            imagePullPolicy?: string;
            limits?: {[key: string]: number | string};
            listenLocal?: boolean;
            logFormat?: string;
            logLevel?: string;
            minTime?: string;
            objectStorageConfig?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosObjectstorageconfig;
            objectStorageConfigFile?: string;
            requests?: {[key: string]: number | string};
            routePrefix?: string;
            tracingConfig?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosTracingconfig;
            tracingConfigFile?: string;
            version?: string;
        }

        export interface TidbMonitorSpecThanosAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfig {
            ca?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigCa;
            caFile?: string;
            cert?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigCert;
            certFile?: string;
            insecureSkipVerify?: boolean;
            keyFile?: string;
            keySecret?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigKeysecret;
            serverName?: string;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigCa {
            configMap?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigCaConfigmap;
            secret?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigCaSecret;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigCaConfigmap {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigCaSecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigCert {
            configMap?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigCertConfigmap;
            secret?: outputs.pingcap.v1alpha1.TidbMonitorSpecThanosGrpcservertlsconfigCertSecret;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigCertConfigmap {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigCertSecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecThanosGrpcservertlsconfigKeysecret {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecThanosObjectstorageconfig {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecThanosTracingconfig {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbMonitorSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbMonitorStatus {
            deploymentStorageStatus?: outputs.pingcap.v1alpha1.TidbMonitorStatusDeploymentstoragestatus;
            statefulSet?: outputs.pingcap.v1alpha1.TidbMonitorStatusStatefulset;
        }

        export interface TidbMonitorStatusDeploymentstoragestatus {
            pvName?: string;
        }

        export interface TidbMonitorStatusStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbMonitorStatusStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbMonitorStatusStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }

        export interface TidbNGMonitoringSpec {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinity;
            annotations?: {[key: string]: string};
            clusterDomain?: string;
            clusters: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecClusters[];
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainers[];
            labels?: {[key: string]: string};
            ngMonitoring: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoring;
            nodeSelector?: {[key: string]: string};
            paused?: boolean;
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecPodsecuritycontext;
            priorityClassName?: string;
            pvReclaimPolicy?: string;
            schedulerName?: string;
            statefulSetUpdateStrategy?: string;
            suspendAction?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbNGMonitoringSpecProvideDefaults sets the appropriate defaults for TidbNGMonitoringSpec
         */
        export function tidbNGMonitoringSpecProvideDefaults(val: TidbNGMonitoringSpec): TidbNGMonitoringSpec {
            return {
                ...val,
                ngMonitoring: outputs.pingcap.v1alpha1.tidbNGMonitoringSpecNgmonitoringProvideDefaults(val.ngMonitoring),
                pvReclaimPolicy: (val.pvReclaimPolicy) ?? "Retain",
            };
        }

        export interface TidbNGMonitoringSpecAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvValuefrom;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbNGMonitoringSpecAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbNGMonitoringSpecAdditionalcontainersPorts
         */
        export function tidbNGMonitoringSpecAdditionalcontainersPortsProvideDefaults(val: TidbNGMonitoringSpecAdditionalcontainersPorts): TidbNGMonitoringSpecAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbNGMonitoringSpecAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesVspherevolume;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSources[];
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbNGMonitoringSpecAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinity;
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecClusters {
            clusterDomain?: string;
            name: string;
            namespace?: string;
        }

        export interface TidbNGMonitoringSpecDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbNGMonitoringSpecDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbNGMonitoringSpecEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvValuefrom;
        }

        export interface TidbNGMonitoringSpecEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvValuefromSecretkeyref;
        }

        export interface TidbNGMonitoringSpecEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecEnvfromSecretref;
        }

        export interface TidbNGMonitoringSpecEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecImagepullsecrets {
            name?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvValuefrom;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersEnvfromSecretref;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePrestop;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbNGMonitoringSpecInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbNGMonitoringSpecInitcontainersPorts
         */
        export function tidbNGMonitoringSpecInitcontainersPortsProvideDefaults(val: TidbNGMonitoringSpecInitcontainersPorts): TidbNGMonitoringSpecInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbNGMonitoringSpecInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbNGMonitoringSpecInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbNGMonitoringSpecInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbNGMonitoringSpecInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbNGMonitoringSpecInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoring {
            additionalContainers?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainers[];
            additionalVolumeMounts?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumemounts[];
            additionalVolumes?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumes[];
            affinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinity;
            annotations?: {[key: string]: string};
            baseImage?: string;
            config?: {[key: string]: any};
            configUpdateStrategy?: string;
            dnsConfig?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringDnsconfig;
            dnsPolicy?: string;
            env?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvfrom[];
            hostNetwork?: boolean;
            image?: string;
            imagePullPolicy?: string;
            imagePullSecrets?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringImagepullsecrets[];
            initContainers?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainers[];
            labels?: {[key: string]: string};
            limits?: {[key: string]: number | string};
            nodeSelector?: {[key: string]: string};
            podManagementPolicy?: string;
            podSecurityContext?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringPodsecuritycontext;
            priorityClassName?: string;
            requests?: {[key: string]: number | string};
            schedulerName?: string;
            statefulSetUpdateStrategy?: string;
            storageClassName?: string;
            storageVolumes?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringStoragevolumes[];
            suspendAction?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringSuspendaction;
            terminationGracePeriodSeconds?: number;
            tolerations?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringTolerations[];
            topologySpreadConstraints?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringTopologyspreadconstraints[];
            version?: string;
        }
        /**
         * tidbNGMonitoringSpecNgmonitoringProvideDefaults sets the appropriate defaults for TidbNGMonitoringSpecNgmonitoring
         */
        export function tidbNGMonitoringSpecNgmonitoringProvideDefaults(val: TidbNGMonitoringSpecNgmonitoring): TidbNGMonitoringSpecNgmonitoring {
            return {
                ...val,
                baseImage: (val.baseImage) ?? "pingcap/ng-monitoring",
            };
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefrom;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvfromSecretref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestop;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbNGMonitoringSpecNgmonitoringAdditionalcontainersPortsProvideDefaults sets the appropriate defaults for TidbNGMonitoringSpecNgmonitoringAdditionalcontainersPorts
         */
        export function tidbNGMonitoringSpecNgmonitoringAdditionalcontainersPortsProvideDefaults(val: TidbNGMonitoringSpecNgmonitoringAdditionalcontainersPorts): TidbNGMonitoringSpecNgmonitoringAdditionalcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumes {
            awsElasticBlockStore?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesAwselasticblockstore;
            azureDisk?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesAzuredisk;
            azureFile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesAzurefile;
            cephfs?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCephfs;
            cinder?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCinder;
            configMap?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesConfigmap;
            csi?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCsi;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapi;
            emptyDir?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEmptydir;
            ephemeral?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeral;
            fc?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFc;
            flexVolume?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFlexvolume;
            flocker?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFlocker;
            gcePersistentDisk?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesGcepersistentdisk;
            gitRepo?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesGitrepo;
            glusterfs?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesGlusterfs;
            hostPath?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesHostpath;
            iscsi?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesIscsi;
            name: string;
            nfs?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesNfs;
            persistentVolumeClaim?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesPersistentvolumeclaim;
            photonPersistentDisk?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesPhotonpersistentdisk;
            portworxVolume?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesPortworxvolume;
            projected?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjected;
            quobyte?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesQuobyte;
            rbd?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesRbd;
            scaleIO?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesScaleio;
            secret?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesSecret;
            storageos?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesStorageos;
            vsphereVolume?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesVspherevolume;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesAwselasticblockstore {
            fsType?: string;
            partition?: number;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesAzuredisk {
            cachingMode?: string;
            diskName: string;
            diskURI: string;
            fsType?: string;
            kind?: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesAzurefile {
            readOnly?: boolean;
            secretName: string;
            shareName: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCephfs {
            monitors: string[];
            path?: string;
            readOnly?: boolean;
            secretFile?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCephfsSecretref;
            user?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCephfsSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCinder {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCinderSecretref;
            volumeID: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCinderSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesConfigmap {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCsi {
            driver: string;
            fsType?: string;
            nodePublishSecretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCsiNodepublishsecretref;
            readOnly?: boolean;
            volumeAttributes?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesCsiNodepublishsecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapi {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapiItems[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapiItemsResourcefieldref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEmptydir {
            medium?: string;
            sizeLimit?: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeral {
            readOnly?: boolean;
            volumeClaimTemplate?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplate;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplate {
            metadata?: {[key: string]: any};
            spec: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpec;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpec {
            accessModes?: string[];
            dataSource?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource;
            resources?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources;
            selector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecDatasource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesEphemeralVolumeclaimtemplateSpecSelectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFc {
            fsType?: string;
            lun?: number;
            readOnly?: boolean;
            targetWWNs?: string[];
            wwids?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFlexvolume {
            driver: string;
            fsType?: string;
            options?: {[key: string]: string};
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFlexvolumeSecretref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFlexvolumeSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesFlocker {
            datasetName?: string;
            datasetUUID?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesGcepersistentdisk {
            fsType?: string;
            partition?: number;
            pdName: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesGitrepo {
            directory?: string;
            repository: string;
            revision?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesGlusterfs {
            endpoints: string;
            path: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesHostpath {
            path: string;
            type?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesIscsi {
            chapAuthDiscovery?: boolean;
            chapAuthSession?: boolean;
            fsType?: string;
            initiatorName?: string;
            iqn: string;
            iscsiInterface?: string;
            lun: number;
            portals?: string[];
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesIscsiSecretref;
            targetPortal: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesIscsiSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesNfs {
            path: string;
            readOnly?: boolean;
            server: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesPersistentvolumeclaim {
            claimName: string;
            readOnly?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesPhotonpersistentdisk {
            fsType?: string;
            pdID: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesPortworxvolume {
            fsType?: string;
            readOnly?: boolean;
            volumeID: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjected {
            defaultMode?: number;
            sources: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSources[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSources {
            configMap?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesConfigmap;
            downwardAPI?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapi;
            secret?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesSecret;
            serviceAccountToken?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesServiceaccounttoken;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesConfigmap {
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesConfigmapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesConfigmapItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapi {
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapiItems[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapiItems {
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref;
            mode?: number;
            path: string;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapiItemsFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesDownwardapiItemsResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesSecret {
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesSecretItems[];
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesProjectedSourcesServiceaccounttoken {
            audience?: string;
            expirationSeconds?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesQuobyte {
            group?: string;
            readOnly?: boolean;
            registry: string;
            tenant?: string;
            user?: string;
            volume: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesRbd {
            fsType?: string;
            image: string;
            keyring?: string;
            monitors: string[];
            pool?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesRbdSecretref;
            user?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesRbdSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesScaleio {
            fsType?: string;
            gateway: string;
            protectionDomain?: string;
            readOnly?: boolean;
            secretRef: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesScaleioSecretref;
            sslEnabled?: boolean;
            storageMode?: string;
            storagePool?: string;
            system: string;
            volumeName?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesScaleioSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesSecret {
            defaultMode?: number;
            items?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesSecretItems {
            key: string;
            mode?: number;
            path: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesStorageos {
            fsType?: string;
            readOnly?: boolean;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAdditionalvolumesStorageosSecretref;
            volumeName?: string;
            volumeNamespace?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesStorageosSecretref {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAdditionalvolumesVspherevolume {
            fsType?: string;
            storagePolicyID?: string;
            storagePolicyName?: string;
            volumePath: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinity {
            nodeAffinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinity;
            podAffinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinity;
            podAntiAffinity?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinity;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecution;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecution {
            preference: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference;
            weight: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreference {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityPreferredduringschedulingignoredduringexecutionPreferenceMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecution {
            nodeSelectorTerms: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectorterms {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions[];
            matchFields?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityNodeaffinityRequiredduringschedulingignoredduringexecutionNodeselectortermsMatchfields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecution {
            podAffinityTerm: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm;
            weight: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinityterm {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityPreferredduringschedulingignoredduringexecutionPodaffinitytermLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityRequiredduringschedulingignoredduringexecution {
            labelSelector?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselector {
            matchExpressions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions[];
            matchLabels?: {[key: string]: string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringAffinityPodantiaffinityRequiredduringschedulingignoredduringexecutionLabelselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringDnsconfig {
            nameservers?: string[];
            options?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringDnsconfigOptions[];
            searches?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringDnsconfigOptions {
            name?: string;
            value?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvValuefrom;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvValuefromSecretkeyref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringEnvfromSecretref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringImagepullsecrets {
            name?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainers {
            args?: string[];
            command?: string[];
            env?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnv[];
            envFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvfrom[];
            image?: string;
            imagePullPolicy?: string;
            lifecycle?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecycle;
            livenessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobe;
            name: string;
            ports?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersPorts[];
            readinessProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobe;
            resources?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersResources;
            securityContext?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontext;
            startupProbe?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobe;
            stdin?: boolean;
            stdinOnce?: boolean;
            terminationMessagePath?: string;
            terminationMessagePolicy?: string;
            tty?: boolean;
            volumeDevices?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersVolumedevices[];
            volumeMounts?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersVolumemounts[];
            workingDir?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnv {
            name: string;
            value?: string;
            valueFrom?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefrom;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefrom {
            configMapKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromConfigmapkeyref;
            fieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromFieldref;
            resourceFieldRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromResourcefieldref;
            secretKeyRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromSecretkeyref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromConfigmapkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromFieldref {
            apiVersion?: string;
            fieldPath: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromResourcefieldref {
            containerName?: string;
            divisor?: number | string;
            resource: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvValuefromSecretkeyref {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvfrom {
            configMapRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvfromConfigmapref;
            prefix?: string;
            secretRef?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersEnvfromSecretref;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvfromConfigmapref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersEnvfromSecretref {
            name?: string;
            optional?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecycle {
            postStart?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststart;
            preStop?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestop;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststart {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartTcpsocket;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePoststartTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestop {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopExec;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopHttpget;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopTcpsocket;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLifecyclePrestopTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersLivenessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersPorts {
            containerPort: number;
            hostIP?: string;
            hostPort?: number;
            name?: string;
            protocol?: string;
        }
        /**
         * tidbNGMonitoringSpecNgmonitoringInitcontainersPortsProvideDefaults sets the appropriate defaults for TidbNGMonitoringSpecNgmonitoringInitcontainersPorts
         */
        export function tidbNGMonitoringSpecNgmonitoringInitcontainersPortsProvideDefaults(val: TidbNGMonitoringSpecNgmonitoringInitcontainersPorts): TidbNGMonitoringSpecNgmonitoringInitcontainersPorts {
            return {
                ...val,
                protocol: (val.protocol) ?? "TCP",
            };
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersReadinessprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersResources {
            limits?: {[key: string]: number | string};
            requests?: {[key: string]: number | string};
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextSeccompprofile;
            windowsOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextWindowsoptions;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersSecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobe {
            exec?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeExec;
            failureThreshold?: number;
            httpGet?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeHttpget;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeTcpsocket;
            timeoutSeconds?: number;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeExec {
            command?: string[];
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeHttpget {
            host?: string;
            httpHeaders?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeHttpgetHttpheaders[];
            path?: string;
            port: number | string;
            scheme?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeHttpgetHttpheaders {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersStartupprobeTcpsocket {
            host?: string;
            port: number | string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersVolumedevices {
            devicePath: string;
            name: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringInitcontainersVolumemounts {
            mountPath: string;
            mountPropagation?: string;
            name: string;
            readOnly?: boolean;
            subPath?: string;
            subPathExpr?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecNgmonitoringPodsecuritycontextWindowsoptions;
        }

        export interface TidbNGMonitoringSpecNgmonitoringPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringStoragevolumes {
            mountPath?: string;
            name: string;
            storageClassName?: string;
            storageSize: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbNGMonitoringSpecNgmonitoringTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbNGMonitoringSpecNgmonitoringTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbNGMonitoringSpecPodsecuritycontext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecPodsecuritycontextSelinuxoptions;
            seccompProfile?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecPodsecuritycontextSeccompprofile;
            supplementalGroups?: number[];
            sysctls?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecPodsecuritycontextSysctls[];
            windowsOptions?: outputs.pingcap.v1alpha1.TidbNGMonitoringSpecPodsecuritycontextWindowsoptions;
        }

        export interface TidbNGMonitoringSpecPodsecuritycontextSeccompprofile {
            localhostProfile?: string;
            type: string;
        }

        export interface TidbNGMonitoringSpecPodsecuritycontextSelinuxoptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface TidbNGMonitoringSpecPodsecuritycontextSysctls {
            name: string;
            value: string;
        }

        export interface TidbNGMonitoringSpecPodsecuritycontextWindowsoptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface TidbNGMonitoringSpecSuspendaction {
            suspendStatefulSet?: boolean;
        }

        export interface TidbNGMonitoringSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface TidbNGMonitoringSpecTopologyspreadconstraints {
            topologyKey: string;
        }

        export interface TidbNGMonitoringStatus {
            ngMonitoring?: outputs.pingcap.v1alpha1.TidbNGMonitoringStatusNgmonitoring;
        }

        export interface TidbNGMonitoringStatusNgmonitoring {
            phase?: string;
            statefulSet?: outputs.pingcap.v1alpha1.TidbNGMonitoringStatusNgmonitoringStatefulset;
            synced?: boolean;
        }

        export interface TidbNGMonitoringStatusNgmonitoringStatefulset {
            collisionCount?: number;
            conditions?: outputs.pingcap.v1alpha1.TidbNGMonitoringStatusNgmonitoringStatefulsetConditions[];
            currentReplicas?: number;
            currentRevision?: string;
            observedGeneration?: number;
            readyReplicas?: number;
            replicas: number;
            updateRevision?: string;
            updatedReplicas?: number;
        }

        export interface TidbNGMonitoringStatusNgmonitoringStatefulsetConditions {
            lastTransitionTime?: string;
            message?: string;
            reason?: string;
            status: string;
            type: string;
        }
    }
}

export namespace policy {
    export namespace v1alpha1 {
        /**
         * Authorizes clients to communicate with Linkerd-proxied server resources.
         */
        export interface AuthorizationPolicySpec {
            /**
             * RequiredAuthenticationRefs enumerates a set of required authentications. ALL authentications must be satisfied for the authorization to apply. If any of the referred objects cannot be found, the authorization will be ignored.
             */
            requiredAuthenticationRefs: outputs.policy.v1alpha1.AuthorizationPolicySpecRequiredauthenticationrefs[];
            /**
             * TargetRef references a resource to which the authorization policy applies.
             */
            targetRef: outputs.policy.v1alpha1.AuthorizationPolicySpecTargetref;
        }

        export interface AuthorizationPolicySpecRequiredauthenticationrefs {
            /**
             * Group is the group of the referent. When empty, the Kubernetes core API group is inferred."
             */
            group?: string;
            /**
             * Kind is the kind of the referent.
             */
            kind: string;
            /**
             * Name is the name of the referent.
             */
            name: string;
            /**
             * Name is the name of the referent. When unspecified, this authentication refers to the local namespace.
             */
            namespace?: string;
        }

        /**
         * TargetRef references a resource to which the authorization policy applies.
         */
        export interface AuthorizationPolicySpecTargetref {
            /**
             * Group is the group of the referent. When empty, the Kubernetes core API group is inferred.
             */
            group?: string;
            /**
             * Kind is the kind of the referent.
             */
            kind: string;
            /**
             * Name is the name of the referent.
             */
            name: string;
        }

        /**
         * Spec defines the desired state of HTTPRoute.
         */
        export interface HTTPRouteSpec {
            /**
             * Hostnames defines a set of hostname that should match against the HTTP Host header to select a HTTPRoute to process the request. This matches the RFC 1123 definition of a hostname with 2 notable exceptions: 
             *  1. IPs are not allowed. 2. A hostname may be prefixed with a wildcard label (`*.`). The wildcard    label must appear by itself as the first label. 
             *  If a hostname is specified by both the Listener and HTTPRoute, there must be at least one intersecting hostname for the HTTPRoute to be attached to the Listener. For example: 
             *  * A Listener with `test.example.com` as the hostname matches HTTPRoutes   that have either not specified any hostnames, or have specified at   least one of `test.example.com` or `*.example.com`. * A Listener with `*.example.com` as the hostname matches HTTPRoutes   that have either not specified any hostnames or have specified at least   one hostname that matches the Listener hostname. For example,   `*.example.com`, `test.example.com`, and `foo.test.example.com` would   all match. On the other hand, `example.com` and `test.example.net` would   not match. 
             *  Hostnames that are prefixed with a wildcard label (`*.`) are interpreted as a suffix match. That means that a match for `*.example.com` would match both `test.example.com`, and `foo.test.example.com`, but not `example.com`. 
             *  If both the Listener and HTTPRoute have specified hostnames, any HTTPRoute hostnames that do not match the Listener hostname MUST be ignored. For example, if a Listener specified `*.example.com`, and the HTTPRoute specified `test.example.com` and `test.example.net`, `test.example.net` must not be considered for a match. 
             *  If both the Listener and HTTPRoute have specified hostnames, and none match with the criteria above, then the HTTPRoute is not accepted. The implementation must raise an 'Accepted' Condition with a status of `False` in the corresponding RouteParentStatus. 
             *  Support: Core
             */
            hostnames?: string[];
            /**
             * ParentRefs references the resources (usually Gateways) that a Route wants to be attached to. Note that the referenced parent resource needs to allow this for the attachment to be complete. For Gateways, that means the Gateway needs to allow attachment from Routes of this kind and namespace. 
             *  The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources such as one of the route kinds. 
             *  It is invalid to reference an identical parent more than once. It is valid to reference multiple distinct sections within the same parent resource, such as 2 Listeners within a Gateway. 
             *  It is possible to separately reference multiple distinct objects that may be collapsed by an implementation. For example, some implementations may choose to merge compatible Gateway Listeners together. If that is the case, the list of routes attached to those resources should also be merged.
             */
            parentRefs?: outputs.policy.v1alpha1.HTTPRouteSpecParentrefs[];
            /**
             * Rules are a list of HTTP matchers, filters and actions.
             */
            rules?: outputs.policy.v1alpha1.HTTPRouteSpecRules[];
        }

        /**
         * ParentReference identifies an API object (usually a Gateway) that can be considered a parent of this resource (usually a route). The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources, such as HTTPRoute. 
         *  The API object must be valid in the cluster; the Group and Kind must be registered in the cluster for this reference to be valid.
         */
        export interface HTTPRouteSpecParentrefs {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name. When both Port (experimental) and SectionName are specified, the name and port of the selected listener must match both specified values. 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * httprouteSpecParentrefsProvideDefaults sets the appropriate defaults for HTTPRouteSpecParentrefs
         */
        export function httprouteSpecParentrefsProvideDefaults(val: HTTPRouteSpecParentrefs): HTTPRouteSpecParentrefs {
            return {
                ...val,
                group: (val.group) ?? "policy.linkerd.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * HTTPRouteRule defines semantics for matching an HTTP request based on conditions (matches) and processing it (filters).
         */
        export interface HTTPRouteSpecRules {
            /**
             * Filters define the filters that are applied to requests that match this rule. 
             *  The effects of ordering of multiple behaviors are currently unspecified. This can change in the future based on feedback during the alpha stage. 
             *  C"onformance-levels at this level are defined based on the type of filter": 
             *  - ALL core filters MUST be supported by all implementations. - Implementers are encouraged to support extended filters. - Implementation-specific custom filters have no API guarantees across   implementations. 
             *  Specifying a core filter multiple times has unspecified or custom conformance. 
             *  All filters are expected to be compatible with each other except for the URLRewrite and RequestRedirect filters, which may not be combined. If an implementation can not support other combinations of filters, they must clearly document that limitation. In all cases where incompatible or unsupported filters are specified, implementations MUST add a warning condition to status. 
             *  Support: Core
             */
            filters?: outputs.policy.v1alpha1.HTTPRouteSpecRulesFilters[];
            /**
             * Matches define conditions used for matching the rule against incoming HTTP requests. Each match is independent, i.e. this rule will be matched if **any** one of the matches is satisfied. 
             *  For example, take the following matches configuration: 
             *  ``` matches: - path:     value: "/foo"   headers:   - name: "version"     value: "v2" - path:     value: "/v2/foo" ``` 
             *  For a request to match against this rule, a request must satisfy EITHER of the two conditions: 
             *  - path prefixed with `/foo` AND contains the header `version: v2` - path prefix of `/v2/foo` 
             *  See the documentation for HTTPRouteMatch on how to specify multiple match conditions that should be ANDed together. 
             *  If no matches are specified, the default is a prefix path match on "/", which has the effect of matching every HTTP request. 
             *  Proxy or Load Balancer routing configuration generated from HTTPRoutes MUST prioritize rules based on the following criteria, continuing on ties. Precedence must be given to the the Rule with the largest number of: 
             *  * Characters in a matching non-wildcard hostname. * Characters in a matching hostname. * Characters in a matching path. * Header matches. * Query param matches. 
             *  If ties still exist across multiple Routes, matching precedence MUST be determined in order of the following criteria, continuing on ties: 
             *  * The oldest Route based on creation timestamp. * The Route appearing first in alphabetical order by   "{namespace}/{name}". 
             *  If ties still exist within the Route that has been given precedence, matching precedence MUST be granted to the first matching rule meeting the above criteria. 
             *  When no rules matching a request have been successfully attached to the parent a request is coming from, a HTTP 404 status code MUST be returned.
             */
            matches?: outputs.policy.v1alpha1.HTTPRouteSpecRulesMatches[];
        }

        /**
         * HTTPRouteFilter defines processing steps that must be completed during the request or response lifecycle. HTTPRouteFilters are meant as an extension point to express processing that may be done in Gateway implementations. Some examples include request or response modification, implementing authentication strategies, rate-limiting, and traffic shaping. API guarantee/conformance is defined based on the type of the filter.
         */
        export interface HTTPRouteSpecRulesFilters {
            /**
             * RequestHeaderModifier defines a schema for a filter that modifies request headers. 
             *  Support: Core
             */
            requestHeaderModifier?: outputs.policy.v1alpha1.HTTPRouteSpecRulesFiltersRequestheadermodifier;
            /**
             * RequestRedirect defines a schema for a filter that responds to the request with an HTTP redirection. 
             *  Support: Core
             */
            requestRedirect?: outputs.policy.v1alpha1.HTTPRouteSpecRulesFiltersRequestredirect;
            /**
             * Type identifies the type of filter to apply. As with other API fields, types are classified into three conformance levels: 
             *  - Core: Filter types and their corresponding configuration defined by   "Support: Core" in this package, e.g. "RequestHeaderModifier". All   implementations must support core filters. 
             *
             *  
             */
            type: string;
        }
        /**
         * httprouteSpecRulesFiltersProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesFilters
         */
        export function httprouteSpecRulesFiltersProvideDefaults(val: HTTPRouteSpecRulesFilters): HTTPRouteSpecRulesFilters {
            return {
                ...val,
                requestRedirect: (val.requestRedirect ? outputs.policy.v1alpha1.httprouteSpecRulesFiltersRequestredirectProvideDefaults(val.requestRedirect) : undefined),
            };
        }

        /**
         * RequestHeaderModifier defines a schema for a filter that modifies request headers. 
         *  Support: Core
         */
        export interface HTTPRouteSpecRulesFiltersRequestheadermodifier {
            /**
             * Add adds the given header(s) (name, value) to the request before the action. It appends to any existing values associated with the header name. 
             *  Input:   GET /foo HTTP/1.1   "my-header": foo 
             *  Config:   add:   - name: ""my-header"     value": "bar" 
             *  Output:   GET /foo HTTP/1.1   "my-header: foo   my-header": bar
             */
            add?: outputs.policy.v1alpha1.HTTPRouteSpecRulesFiltersRequestheadermodifierAdd[];
            /**
             * Remove the given header(s) from the HTTP request before the action. The value of Remove is a list of HTTP header names. Note that the header names are "case-insensitive (see https"://datatracker.ietf.org/doc/html/rfc2616#section-4.2). 
             *  Input:   GET /foo HTTP/1.1   my-header1: foo   my-header2: bar   my-header3: baz 
             *  Config:   remove: ["my-header1", "my-header3"] 
             *  Output:   GET /foo HTTP/1.1   my-header2: bar
             */
            remove?: string[];
            /**
             * Set overwrites the request with the given header (name, value) before the action. 
             *  Input:   GET /foo HTTP/1.1   "my-header": foo 
             *  Config:   set:   - name: ""my-header"     value": "bar" 
             *  Output:   GET /foo HTTP/1.1   "my-header": bar
             */
            set?: outputs.policy.v1alpha1.HTTPRouteSpecRulesFiltersRequestheadermodifierSet[];
        }

        /**
         * HTTPHeader represents an HTTP Header name and value as defined by RFC 7230.
         */
        export interface HTTPRouteSpecRulesFiltersRequestheadermodifierAdd {
            /**
             * Name is the name of the HTTP Header to be matched. Name matching MUST be case insensitive. (See https://tools.ietf.org/html/rfc7230#section-3.2). 
             *  If multiple entries specify equivalent header names, the first entry with an equivalent name MUST be considered for a match. Subsequent entries with an equivalent header name MUST be ignored. Due to the case-insensitivity of header names, "foo" and "Foo" are considered equivalent.
             */
            name: string;
            /**
             * Value is the value of HTTP Header to be matched.
             */
            value: string;
        }

        /**
         * HTTPHeader represents an HTTP Header name and value as defined by RFC 7230.
         */
        export interface HTTPRouteSpecRulesFiltersRequestheadermodifierSet {
            /**
             * Name is the name of the HTTP Header to be matched. Name matching MUST be case insensitive. (See https://tools.ietf.org/html/rfc7230#section-3.2). 
             *  If multiple entries specify equivalent header names, the first entry with an equivalent name MUST be considered for a match. Subsequent entries with an equivalent header name MUST be ignored. Due to the case-insensitivity of header names, "foo" and "Foo" are considered equivalent.
             */
            name: string;
            /**
             * Value is the value of HTTP Header to be matched.
             */
            value: string;
        }

        /**
         * RequestRedirect defines a schema for a filter that responds to the request with an HTTP redirection. 
         *  Support: Core
         */
        export interface HTTPRouteSpecRulesFiltersRequestredirect {
            /**
             * Hostname is the hostname to be used in the value of the `Location` header in the response. When empty, the hostname of the request is used. 
             *  Support: Core
             */
            hostname?: string;
            /**
             * Port is the port to be used in the value of the `Location` header in the response. When empty, port (if specified) of the request is used. 
             *  Support: Extended
             */
            port?: number;
            /**
             * Scheme is the scheme to be used in the value of the `Location` header in the response. When empty, the scheme of the request is used. 
             *  Support: Extended
             */
            scheme?: string;
            /**
             * StatusCode is the HTTP status code to be used in response. 
             *  Support: Core
             */
            statusCode?: number;
        }
        /**
         * httprouteSpecRulesFiltersRequestredirectProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesFiltersRequestredirect
         */
        export function httprouteSpecRulesFiltersRequestredirectProvideDefaults(val: HTTPRouteSpecRulesFiltersRequestredirect): HTTPRouteSpecRulesFiltersRequestredirect {
            return {
                ...val,
                statusCode: (val.statusCode) ?? 302,
            };
        }

        /**
         * HTTPRouteMatch defines the predicate used to match requests to a given action. Multiple match types are ANDed together, i.e. the match will evaluate to true only if all conditions are satisfied. 
         *  For example, the match below will match a HTTP request only if its path starts with `/foo` AND it contains the `version: v1` header: 
         *  ``` match:   path:     value: "/foo"   headers:   - name: "version"     value "v1" ```
         */
        export interface HTTPRouteSpecRulesMatches {
            /**
             * Headers specifies HTTP request header matchers. Multiple match values are ANDed together, meaning, a request must match all the specified headers to select the route.
             */
            headers?: outputs.policy.v1alpha1.HTTPRouteSpecRulesMatchesHeaders[];
            /**
             * Method specifies HTTP method matcher. When specified, this route will be matched only if the request has the specified method. 
             *  Support: Extended
             */
            method?: string;
            /**
             * Path specifies a HTTP request path matcher. If this field is not specified, a default prefix match on the "/" path is provided.
             */
            path?: outputs.policy.v1alpha1.HTTPRouteSpecRulesMatchesPath;
            /**
             * QueryParams specifies HTTP query parameter matchers. Multiple match values are ANDed together, meaning, a request must match all the specified query parameters to select the route.
             */
            queryParams?: outputs.policy.v1alpha1.HTTPRouteSpecRulesMatchesQueryparams[];
        }
        /**
         * httprouteSpecRulesMatchesProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatches
         */
        export function httprouteSpecRulesMatchesProvideDefaults(val: HTTPRouteSpecRulesMatches): HTTPRouteSpecRulesMatches {
            return {
                ...val,
                path: (val.path ? outputs.policy.v1alpha1.httprouteSpecRulesMatchesPathProvideDefaults(val.path) : undefined),
            };
        }

        /**
         * HTTPHeaderMatch describes how to select a HTTP route by matching HTTP request headers.
         */
        export interface HTTPRouteSpecRulesMatchesHeaders {
            /**
             * Name is the name of the HTTP Header to be matched. Name matching MUST be case insensitive. (See https://tools.ietf.org/html/rfc7230#section-3.2). 
             *  If multiple entries specify equivalent header names, only the first entry with an equivalent name MUST be considered for a match. Subsequent entries with an equivalent header name MUST be ignored. Due to the case-insensitivity of header names, "foo" and "Foo" are considered equivalent. 
             *  When a header is repeated in an HTTP request, it is "implementation-specific behavior as to how this is represented. Generally, proxies should follow the guidance from the RFC: https"://www.rfc-editor.org/rfc/rfc7230.html#section-3.2.2 regarding processing a repeated header, with special handling for "Set-Cookie".
             */
            name: string;
            /**
             * Type specifies how to match against the value of the header. 
             *  Support: Core (Exact) 
             *  Support: Custom (RegularExpression) 
             *  Since RegularExpression HeaderMatchType has custom conformance, implementations can support POSIX, PCRE or any other dialects of regular expressions. Please read the implementation's documentation to determine the supported dialect.
             */
            type?: string;
            /**
             * Value is the value of HTTP Header to be matched.
             */
            value: string;
        }
        /**
         * httprouteSpecRulesMatchesHeadersProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatchesHeaders
         */
        export function httprouteSpecRulesMatchesHeadersProvideDefaults(val: HTTPRouteSpecRulesMatchesHeaders): HTTPRouteSpecRulesMatchesHeaders {
            return {
                ...val,
                type: (val.type) ?? "Exact",
            };
        }

        /**
         * Path specifies a HTTP request path matcher. If this field is not specified, a default prefix match on the "/" path is provided.
         */
        export interface HTTPRouteSpecRulesMatchesPath {
            /**
             * Type specifies how to match against the path Value. 
             *  Support: Core (Exact, PathPrefix) 
             *  Support: Custom (RegularExpression)
             */
            type?: string;
            /**
             * Value of the HTTP path to match against.
             */
            value?: string;
        }
        /**
         * httprouteSpecRulesMatchesPathProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatchesPath
         */
        export function httprouteSpecRulesMatchesPathProvideDefaults(val: HTTPRouteSpecRulesMatchesPath): HTTPRouteSpecRulesMatchesPath {
            return {
                ...val,
                type: (val.type) ?? "PathPrefix",
                value: (val.value) ?? "/",
            };
        }

        /**
         * HTTPQueryParamMatch describes how to select a HTTP route by matching HTTP query parameters.
         */
        export interface HTTPRouteSpecRulesMatchesQueryparams {
            /**
             * Name is the name of the HTTP query param to be matched. This must be an exact string match. (See https://tools.ietf.org/html/rfc7230#section-2.7.3).
             */
            name: string;
            /**
             * Type specifies how to match against the value of the query parameter. 
             *  Support: Extended (Exact) 
             *  Support: Custom (RegularExpression) 
             *  Since RegularExpression QueryParamMatchType has custom conformance, implementations can support POSIX, PCRE or any other dialects of regular expressions. Please read the implementation's documentation to determine the supported dialect.
             */
            type?: string;
            /**
             * Value is the value of HTTP query param to be matched.
             */
            value: string;
        }
        /**
         * httprouteSpecRulesMatchesQueryparamsProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatchesQueryparams
         */
        export function httprouteSpecRulesMatchesQueryparamsProvideDefaults(val: HTTPRouteSpecRulesMatchesQueryparams): HTTPRouteSpecRulesMatchesQueryparams {
            return {
                ...val,
                type: (val.type) ?? "Exact",
            };
        }

        /**
         * Status defines the current state of HTTPRoute.
         */
        export interface HTTPRouteStatus {
            /**
             * Parents is a list of parent resources (usually Gateways) that are associated with the route, and the status of the route with respect to each parent. When this route attaches to a parent, the controller that manages the parent must add an entry to this list when the controller first sees the route and should update the entry as appropriate when the route or gateway is modified. 
             *  Note that parent references that cannot be resolved by an implementation of this API will not be added to this list. Implementations of this API can only populate Route status for the Gateways/parent resources they are responsible for. 
             *  A maximum of 32 Gateways will be represented in this list. An empty list means the route has not been attached to any Gateway.
             */
            parents: outputs.policy.v1alpha1.HTTPRouteStatusParents[];
        }

        /**
         * RouteParentStatus describes the status of a route with respect to an associated Parent.
         */
        export interface HTTPRouteStatusParents {
            /**
             * Conditions describes the status of the route with respect to the Gateway. Note that the route's availability is also subject to the Gateway's own status conditions and listener status. 
             *  If the Route's ParentRef specifies an existing Gateway that supports Routes of this kind AND that Gateway's controller has sufficient access, then that Gateway's controller MUST set the "Accepted" condition on the Route, to indicate whether the route has been accepted or rejected by the Gateway, and why. 
             *  A Route MUST be considered "Accepted" if at least one of the Route's rules is implemented by the Gateway. 
             *  There are a number of cases where the "Accepted" condition may not be set due to lack of controller visibility, that includes when: 
             *  * The Route refers to a non-existent parent. * The Route is of a type that the controller does not support. * The Route is in a namespace the the controller does not have access to.
             */
            conditions?: outputs.policy.v1alpha1.HTTPRouteStatusParentsConditions[];
            /**
             * ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. 
             *  Example: "example.net/gateway-controller". 
             *  The format of this field is DOMAIN "/" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). 
             *  Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary.
             */
            controllerName: string;
            /**
             * ParentRef corresponds with a ParentRef in the spec that this RouteParentStatus struct describes the status of.
             */
            parentRef: outputs.policy.v1alpha1.HTTPRouteStatusParentsParentref;
        }
        /**
         * httprouteStatusParentsProvideDefaults sets the appropriate defaults for HTTPRouteStatusParents
         */
        export function httprouteStatusParentsProvideDefaults(val: HTTPRouteStatusParents): HTTPRouteStatusParents {
            return {
                ...val,
                parentRef: outputs.policy.v1alpha1.httprouteStatusParentsParentrefProvideDefaults(val.parentRef),
            };
        }

        /**
         * Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, type FooStatus struct{     // Represents the observations of a foo's current state.     // Known .status.conditions.type are: "Available", "Progressing", and "Degraded"     // +patchMergeKey=type     // +patchStrategy=merge     // +listType=map     // +listMapKey=type     Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
         *      // other fields }
         */
        export interface HTTPRouteStatusParentsConditions {
            /**
             * lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
             */
            lastTransitionTime: string;
            /**
             * message is a human readable message indicating details about the transition. This may be an empty string.
             */
            message: string;
            /**
             * observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
             */
            observedGeneration?: number;
            /**
             * reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
             */
            reason: string;
            /**
             * status of the condition, one of True, False, Unknown.
             */
            status: string;
            /**
             * type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
             */
            type: string;
        }

        /**
         * ParentRef corresponds with a ParentRef in the spec that this RouteParentStatus struct describes the status of.
         */
        export interface HTTPRouteStatusParentsParentref {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name. When both Port (experimental) and SectionName are specified, the name and port of the selected listener must match both specified values. 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * httprouteStatusParentsParentrefProvideDefaults sets the appropriate defaults for HTTPRouteStatusParentsParentref
         */
        export function httprouteStatusParentsParentrefProvideDefaults(val: HTTPRouteStatusParentsParentref): HTTPRouteStatusParentsParentref {
            return {
                ...val,
                group: (val.group) ?? "policy.linkerd.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * NetworkAuthentication defines a list of authenticated client networks to be referenced by an `AuthorizationPolicy`. If a client connection originates from ANY of the of the provided networks, the connection is considered authenticated.
         */
        export interface NetworkAuthenticationSpec {
            networks: outputs.policy.v1alpha1.NetworkAuthenticationSpecNetworks[];
        }

        export interface NetworkAuthenticationSpecNetworks {
            /**
             * The CIDR of the network to be authorized.
             */
            cidr: string;
            /**
             * A list of IP networks/addresses not to be included in the above `cidr`.
             */
            except?: string[];
        }

        /**
         * Authorizes clients to communicate with Linkerd-proxied servers.
         */
        export interface ServerAuthorizationSpec {
            /**
             * Describes clients authorized to access a server.
             */
            client: outputs.policy.v1alpha1.ServerAuthorizationSpecClient;
            /**
             * Identifies servers in the same namespace for which this authorization applies.
             * Only one of `name` or `selector` may be specified.
             */
            server: any;
        }

        /**
         * Describes clients authorized to access a server.
         */
        export interface ServerAuthorizationSpecClient {
            meshTLS?: outputs.policy.v1alpha1.ServerAuthorizationSpecClientMeshtls;
            /**
             * Limits the client IP addresses to which this authorization applies. If unset, the server chooses a default (typically, all IPs or the cluster's pod network).
             */
            networks?: outputs.policy.v1alpha1.ServerAuthorizationSpecClientNetworks[];
            /**
             * Authorizes unauthenticated clients to access a server.
             */
            unauthenticated?: boolean;
        }

        export interface ServerAuthorizationSpecClientMeshtls {
            /**
             * Authorizes clients with the provided proxy identity strings (as provided via MTLS)
             * The `*` prefix can be used to match all identities in a domain. An identity string of `*` indicates that all authentication clients are authorized.
             */
            identities?: string[];
            /**
             * Authorizes clients with the provided proxy identity service accounts (as provided via MTLS)
             */
            serviceAccounts?: outputs.policy.v1alpha1.ServerAuthorizationSpecClientMeshtlsServiceaccounts[];
            /**
             * Indicates that no client identity is required for communication.
             * This is mostly important for the identity controller, which must terminate TLS connections from clients that do not yet have a certificate.
             */
            unauthenticatedTLS?: boolean;
        }

        export interface ServerAuthorizationSpecClientMeshtlsServiceaccounts {
            /**
             * The ServiceAccount's name.
             */
            name: string;
            /**
             * The ServiceAccount's namespace. If unset, the authorization's namespace is used.
             */
            namespace?: string;
        }

        export interface ServerAuthorizationSpecClientNetworks {
            cidr: string;
            except?: string[];
        }

        export interface ServerSpec {
            /**
             * Selects pods in the same namespace.
             */
            podSelector: any;
            /**
             * A port name or number. Must exist in a pod spec.
             */
            port: number | string;
            /**
             * Configures protocol discovery for inbound connections.
             * Supersedes the `config.linkerd.io/opaque-ports` annotation.
             */
            proxyProtocol?: string;
        }
        /**
         * serverSpecProvideDefaults sets the appropriate defaults for ServerSpec
         */
        export function serverSpecProvideDefaults(val: ServerSpec): ServerSpec {
            return {
                ...val,
                proxyProtocol: (val.proxyProtocol) ?? "unknown",
            };
        }

    }

    export namespace v1beta1 {
        /**
         * Spec defines the desired state of HTTPRoute.
         */
        export interface HTTPRouteSpec {
            /**
             * Hostnames defines a set of hostname that should match against the HTTP Host header to select a HTTPRoute to process the request. This matches the RFC 1123 definition of a hostname with 2 notable exceptions: 
             *  1. IPs are not allowed. 2. A hostname may be prefixed with a wildcard label (`*.`). The wildcard    label must appear by itself as the first label. 
             *  If a hostname is specified by both the Listener and HTTPRoute, there must be at least one intersecting hostname for the HTTPRoute to be attached to the Listener. For example: 
             *  * A Listener with `test.example.com` as the hostname matches HTTPRoutes   that have either not specified any hostnames, or have specified at   least one of `test.example.com` or `*.example.com`. * A Listener with `*.example.com` as the hostname matches HTTPRoutes   that have either not specified any hostnames or have specified at least   one hostname that matches the Listener hostname. For example,   `*.example.com`, `test.example.com`, and `foo.test.example.com` would   all match. On the other hand, `example.com` and `test.example.net` would   not match. 
             *  Hostnames that are prefixed with a wildcard label (`*.`) are interpreted as a suffix match. That means that a match for `*.example.com` would match both `test.example.com`, and `foo.test.example.com`, but not `example.com`. 
             *  If both the Listener and HTTPRoute have specified hostnames, any HTTPRoute hostnames that do not match the Listener hostname MUST be ignored. For example, if a Listener specified `*.example.com`, and the HTTPRoute specified `test.example.com` and `test.example.net`, `test.example.net` must not be considered for a match. 
             *  If both the Listener and HTTPRoute have specified hostnames, and none match with the criteria above, then the HTTPRoute is not accepted. The implementation must raise an 'Accepted' Condition with a status of `False` in the corresponding RouteParentStatus. 
             *  Support: Core
             */
            hostnames?: string[];
            /**
             * ParentRefs references the resources (usually Gateways) that a Route wants to be attached to. Note that the referenced parent resource needs to allow this for the attachment to be complete. For Gateways, that means the Gateway needs to allow attachment from Routes of this kind and namespace. 
             *  The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources such as one of the route kinds. 
             *  It is invalid to reference an identical parent more than once. It is valid to reference multiple distinct sections within the same parent resource, such as 2 Listeners within a Gateway. 
             *  It is possible to separately reference multiple distinct objects that may be collapsed by an implementation. For example, some implementations may choose to merge compatible Gateway Listeners together. If that is the case, the list of routes attached to those resources should also be merged.
             */
            parentRefs?: outputs.policy.v1beta1.HTTPRouteSpecParentrefs[];
            /**
             * Rules are a list of HTTP matchers, filters and actions.
             */
            rules?: outputs.policy.v1beta1.HTTPRouteSpecRules[];
        }

        /**
         * ParentReference identifies an API object (usually a Gateway) that can be considered a parent of this resource (usually a route). The only kind of parent resource with "Core" support is Gateway. This API may be extended in the future to support additional kinds of parent resources, such as HTTPRoute. 
         *  The API object must be valid in the cluster; the Group and Kind must be registered in the cluster for this reference to be valid.
         */
        export interface HTTPRouteSpecParentrefs {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name. When both Port (experimental) and SectionName are specified, the name and port of the selected listener must match both specified values. 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * httprouteSpecParentrefsProvideDefaults sets the appropriate defaults for HTTPRouteSpecParentrefs
         */
        export function httprouteSpecParentrefsProvideDefaults(val: HTTPRouteSpecParentrefs): HTTPRouteSpecParentrefs {
            return {
                ...val,
                group: (val.group) ?? "policy.linkerd.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * HTTPRouteRule defines semantics for matching an HTTP request based on conditions (matches) and processing it (filters).
         */
        export interface HTTPRouteSpecRules {
            /**
             * Filters define the filters that are applied to requests that match this rule. 
             *  The effects of ordering of multiple behaviors are currently unspecified. This can change in the future based on feedback during the alpha stage. 
             *  C"onformance-levels at this level are defined based on the type of filter": 
             *  - ALL core filters MUST be supported by all implementations. - Implementers are encouraged to support extended filters. - Implementation-specific custom filters have no API guarantees across   implementations. 
             *  Specifying a core filter multiple times has unspecified or custom conformance. 
             *  All filters are expected to be compatible with each other except for the URLRewrite and RequestRedirect filters, which may not be combined. If an implementation can not support other combinations of filters, they must clearly document that limitation. In all cases where incompatible or unsupported filters are specified, implementations MUST add a warning condition to status. 
             *  Support: Core
             */
            filters?: outputs.policy.v1beta1.HTTPRouteSpecRulesFilters[];
            /**
             * Matches define conditions used for matching the rule against incoming HTTP requests. Each match is independent, i.e. this rule will be matched if **any** one of the matches is satisfied. 
             *  For example, take the following matches configuration: 
             *  ``` matches: - path:     value: "/foo"   headers:   - name: "version"     value: "v2" - path:     value: "/v2/foo" ``` 
             *  For a request to match against this rule, a request must satisfy EITHER of the two conditions: 
             *  - path prefixed with `/foo` AND contains the header `version: v2` - path prefix of `/v2/foo` 
             *  See the documentation for HTTPRouteMatch on how to specify multiple match conditions that should be ANDed together. 
             *  If no matches are specified, the default is a prefix path match on "/", which has the effect of matching every HTTP request. 
             *  Proxy or Load Balancer routing configuration generated from HTTPRoutes MUST prioritize rules based on the following criteria, continuing on ties. Precedence must be given to the the Rule with the largest number of: 
             *  * Characters in a matching non-wildcard hostname. * Characters in a matching hostname. * Characters in a matching path. * Header matches. * Query param matches. 
             *  If ties still exist across multiple Routes, matching precedence MUST be determined in order of the following criteria, continuing on ties: 
             *  * The oldest Route based on creation timestamp. * The Route appearing first in alphabetical order by   "{namespace}/{name}". 
             *  If ties still exist within the Route that has been given precedence, matching precedence MUST be granted to the first matching rule meeting the above criteria. 
             *  When no rules matching a request have been successfully attached to the parent a request is coming from, a HTTP 404 status code MUST be returned.
             */
            matches?: outputs.policy.v1beta1.HTTPRouteSpecRulesMatches[];
        }

        /**
         * HTTPRouteFilter defines processing steps that must be completed during the request or response lifecycle. HTTPRouteFilters are meant as an extension point to express processing that may be done in Gateway implementations. Some examples include request or response modification, implementing authentication strategies, rate-limiting, and traffic shaping. API guarantee/conformance is defined based on the type of the filter.
         */
        export interface HTTPRouteSpecRulesFilters {
            /**
             * RequestHeaderModifier defines a schema for a filter that modifies request headers. 
             *  Support: Core
             */
            requestHeaderModifier?: outputs.policy.v1beta1.HTTPRouteSpecRulesFiltersRequestheadermodifier;
            /**
             * RequestRedirect defines a schema for a filter that responds to the request with an HTTP redirection. 
             *  Support: Core
             */
            requestRedirect?: outputs.policy.v1beta1.HTTPRouteSpecRulesFiltersRequestredirect;
            /**
             * Type identifies the type of filter to apply. As with other API fields, types are classified into three conformance levels: 
             *  - Core: Filter types and their corresponding configuration defined by   "Support: Core" in this package, e.g. "RequestHeaderModifier".
             */
            type: string;
        }
        /**
         * httprouteSpecRulesFiltersProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesFilters
         */
        export function httprouteSpecRulesFiltersProvideDefaults(val: HTTPRouteSpecRulesFilters): HTTPRouteSpecRulesFilters {
            return {
                ...val,
                requestRedirect: (val.requestRedirect ? outputs.policy.v1beta1.httprouteSpecRulesFiltersRequestredirectProvideDefaults(val.requestRedirect) : undefined),
            };
        }

        /**
         * RequestHeaderModifier defines a schema for a filter that modifies request headers. 
         *  Support: Core
         */
        export interface HTTPRouteSpecRulesFiltersRequestheadermodifier {
            /**
             * Add adds the given header(s) (name, value) to the request before the action. It appends to any existing values associated with the header name. 
             *  Input:   GET /foo HTTP/1.1   "my-header": foo 
             *  Config:   add:   - name: ""my-header"     value": "bar" 
             *  Output:   GET /foo HTTP/1.1   "my-header: foo   my-header": bar
             */
            add?: outputs.policy.v1beta1.HTTPRouteSpecRulesFiltersRequestheadermodifierAdd[];
            /**
             * Remove the given header(s) from the HTTP request before the action. The value of Remove is a list of HTTP header names. Note that the header names are "case-insensitive (see https"://datatracker.ietf.org/doc/html/rfc2616#section-4.2). 
             *  Input:   GET /foo HTTP/1.1   my-header1: foo   my-header2: bar   my-header3: baz 
             *  Config:   remove: ["my-header1", "my-header3"] 
             *  Output:   GET /foo HTTP/1.1   my-header2: bar
             */
            remove?: string[];
            /**
             * Set overwrites the request with the given header (name, value) before the action. 
             *  Input:   GET /foo HTTP/1.1   "my-header": foo 
             *  Config:   set:   - name: ""my-header"     value": "bar" 
             *  Output:   GET /foo HTTP/1.1   "my-header": bar
             */
            set?: outputs.policy.v1beta1.HTTPRouteSpecRulesFiltersRequestheadermodifierSet[];
        }

        /**
         * HTTPHeader represents an HTTP Header name and value as defined by RFC 7230.
         */
        export interface HTTPRouteSpecRulesFiltersRequestheadermodifierAdd {
            /**
             * Name is the name of the HTTP Header to be matched. Name matching MUST be case insensitive. (See https://tools.ietf.org/html/rfc7230#section-3.2). 
             *  If multiple entries specify equivalent header names, the first entry with an equivalent name MUST be considered for a match. Subsequent entries with an equivalent header name MUST be ignored. Due to the case-insensitivity of header names, "foo" and "Foo" are considered equivalent.
             */
            name: string;
            /**
             * Value is the value of HTTP Header to be matched.
             */
            value: string;
        }

        /**
         * HTTPHeader represents an HTTP Header name and value as defined by RFC 7230.
         */
        export interface HTTPRouteSpecRulesFiltersRequestheadermodifierSet {
            /**
             * Name is the name of the HTTP Header to be matched. Name matching MUST be case insensitive. (See https://tools.ietf.org/html/rfc7230#section-3.2). 
             *  If multiple entries specify equivalent header names, the first entry with an equivalent name MUST be considered for a match. Subsequent entries with an equivalent header name MUST be ignored. Due to the case-insensitivity of header names, "foo" and "Foo" are considered equivalent.
             */
            name: string;
            /**
             * Value is the value of HTTP Header to be matched.
             */
            value: string;
        }

        /**
         * RequestRedirect defines a schema for a filter that responds to the request with an HTTP redirection. 
         *  Support: Core
         */
        export interface HTTPRouteSpecRulesFiltersRequestredirect {
            /**
             * Hostname is the hostname to be used in the value of the `Location` header in the response. When empty, the hostname of the request is used. 
             *  Support: Core
             */
            hostname?: string;
            /**
             * Port is the port to be used in the value of the `Location` header in the response. When empty, port (if specified) of the request is used. 
             *  Support: Extended
             */
            port?: number;
            /**
             * Scheme is the scheme to be used in the value of the `Location` header in the response. When empty, the scheme of the request is used. 
             *  Support: Extended
             */
            scheme?: string;
            /**
             * StatusCode is the HTTP status code to be used in response. 
             *  Support: Core
             */
            statusCode?: number;
        }
        /**
         * httprouteSpecRulesFiltersRequestredirectProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesFiltersRequestredirect
         */
        export function httprouteSpecRulesFiltersRequestredirectProvideDefaults(val: HTTPRouteSpecRulesFiltersRequestredirect): HTTPRouteSpecRulesFiltersRequestredirect {
            return {
                ...val,
                statusCode: (val.statusCode) ?? 302,
            };
        }

        /**
         * HTTPRouteMatch defines the predicate used to match requests to a given action. Multiple match types are ANDed together, i.e. the match will evaluate to true only if all conditions are satisfied. 
         *  For example, the match below will match a HTTP request only if its path starts with `/foo` AND it contains the `version: v1` header: 
         *  ``` match:   path:     value: "/foo"   headers:   - name: "version"     value "v1" ```
         */
        export interface HTTPRouteSpecRulesMatches {
            /**
             * Headers specifies HTTP request header matchers. Multiple match values are ANDed together, meaning, a request must match all the specified headers to select the route.
             */
            headers?: outputs.policy.v1beta1.HTTPRouteSpecRulesMatchesHeaders[];
            /**
             * Method specifies HTTP method matcher. When specified, this route will be matched only if the request has the specified method. 
             *  Support: Extended
             */
            method?: string;
            /**
             * Path specifies a HTTP request path matcher. If this field is not specified, a default prefix match on the "/" path is provided.
             */
            path?: outputs.policy.v1beta1.HTTPRouteSpecRulesMatchesPath;
            /**
             * QueryParams specifies HTTP query parameter matchers. Multiple match values are ANDed together, meaning, a request must match all the specified query parameters to select the route.
             */
            queryParams?: outputs.policy.v1beta1.HTTPRouteSpecRulesMatchesQueryparams[];
        }
        /**
         * httprouteSpecRulesMatchesProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatches
         */
        export function httprouteSpecRulesMatchesProvideDefaults(val: HTTPRouteSpecRulesMatches): HTTPRouteSpecRulesMatches {
            return {
                ...val,
                path: (val.path ? outputs.policy.v1beta1.httprouteSpecRulesMatchesPathProvideDefaults(val.path) : undefined),
            };
        }

        /**
         * HTTPHeaderMatch describes how to select a HTTP route by matching HTTP request headers.
         */
        export interface HTTPRouteSpecRulesMatchesHeaders {
            /**
             * Name is the name of the HTTP Header to be matched. Name matching MUST be case insensitive. (See https://tools.ietf.org/html/rfc7230#section-3.2). 
             *  If multiple entries specify equivalent header names, only the first entry with an equivalent name MUST be considered for a match. Subsequent entries with an equivalent header name MUST be ignored. Due to the case-insensitivity of header names, "foo" and "Foo" are considered equivalent. 
             *  When a header is repeated in an HTTP request, it is "implementation-specific behavior as to how this is represented. Generally, proxies should follow the guidance from the RFC: https"://www.rfc-editor.org/rfc/rfc7230.html#section-3.2.2 regarding processing a repeated header, with special handling for "Set-Cookie".
             */
            name: string;
            /**
             * Type specifies how to match against the value of the header. 
             *  Support: Core (Exact) 
             *  Support: Custom (RegularExpression) 
             *  Since RegularExpression HeaderMatchType has custom conformance, implementations can support POSIX, PCRE or any other dialects of regular expressions. Please read the implementation's documentation to determine the supported dialect.
             */
            type?: string;
            /**
             * Value is the value of HTTP Header to be matched.
             */
            value: string;
        }
        /**
         * httprouteSpecRulesMatchesHeadersProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatchesHeaders
         */
        export function httprouteSpecRulesMatchesHeadersProvideDefaults(val: HTTPRouteSpecRulesMatchesHeaders): HTTPRouteSpecRulesMatchesHeaders {
            return {
                ...val,
                type: (val.type) ?? "Exact",
            };
        }

        /**
         * Path specifies a HTTP request path matcher. If this field is not specified, a default prefix match on the "/" path is provided.
         */
        export interface HTTPRouteSpecRulesMatchesPath {
            /**
             * Type specifies how to match against the path Value. 
             *  Support: Core (Exact, PathPrefix) 
             *  Support: Custom (RegularExpression)
             */
            type?: string;
            /**
             * Value of the HTTP path to match against.
             */
            value?: string;
        }
        /**
         * httprouteSpecRulesMatchesPathProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatchesPath
         */
        export function httprouteSpecRulesMatchesPathProvideDefaults(val: HTTPRouteSpecRulesMatchesPath): HTTPRouteSpecRulesMatchesPath {
            return {
                ...val,
                type: (val.type) ?? "PathPrefix",
                value: (val.value) ?? "/",
            };
        }

        /**
         * HTTPQueryParamMatch describes how to select a HTTP route by matching HTTP query parameters.
         */
        export interface HTTPRouteSpecRulesMatchesQueryparams {
            /**
             * Name is the name of the HTTP query param to be matched. This must be an exact string match. (See https://tools.ietf.org/html/rfc7230#section-2.7.3).
             */
            name: string;
            /**
             * Type specifies how to match against the value of the query parameter. 
             *  Support: Extended (Exact) 
             *  Support: Custom (RegularExpression) 
             *  Since RegularExpression QueryParamMatchType has custom conformance, implementations can support POSIX, PCRE or any other dialects of regular expressions. Please read the implementation's documentation to determine the supported dialect.
             */
            type?: string;
            /**
             * Value is the value of HTTP query param to be matched.
             */
            value: string;
        }
        /**
         * httprouteSpecRulesMatchesQueryparamsProvideDefaults sets the appropriate defaults for HTTPRouteSpecRulesMatchesQueryparams
         */
        export function httprouteSpecRulesMatchesQueryparamsProvideDefaults(val: HTTPRouteSpecRulesMatchesQueryparams): HTTPRouteSpecRulesMatchesQueryparams {
            return {
                ...val,
                type: (val.type) ?? "Exact",
            };
        }

        /**
         * Status defines the current state of HTTPRoute.
         */
        export interface HTTPRouteStatus {
            /**
             * Parents is a list of parent resources (usually Gateways) that are associated with the route, and the status of the route with respect to each parent. When this route attaches to a parent, the controller that manages the parent must add an entry to this list when the controller first sees the route and should update the entry as appropriate when the route or gateway is modified. 
             *  Note that parent references that cannot be resolved by an implementation of this API will not be added to this list. Implementations of this API can only populate Route status for the Gateways/parent resources they are responsible for. 
             *  A maximum of 32 Gateways will be represented in this list. An empty list means the route has not been attached to any Gateway.
             */
            parents: outputs.policy.v1beta1.HTTPRouteStatusParents[];
        }

        /**
         * RouteParentStatus describes the status of a route with respect to an associated Parent.
         */
        export interface HTTPRouteStatusParents {
            /**
             * Conditions describes the status of the route with respect to the Gateway. Note that the route's availability is also subject to the Gateway's own status conditions and listener status. 
             *  If the Route's ParentRef specifies an existing Gateway that supports Routes of this kind AND that Gateway's controller has sufficient access, then that Gateway's controller MUST set the "Accepted" condition on the Route, to indicate whether the route has been accepted or rejected by the Gateway, and why. 
             *  A Route MUST be considered "Accepted" if at least one of the Route's rules is implemented by the Gateway. 
             *  There are a number of cases where the "Accepted" condition may not be set due to lack of controller visibility, that includes when: 
             *  * The Route refers to a non-existent parent. * The Route is of a type that the controller does not support. * The Route is in a namespace the the controller does not have access to.
             */
            conditions?: outputs.policy.v1beta1.HTTPRouteStatusParentsConditions[];
            /**
             * ControllerName is a domain/path string that indicates the name of the controller that wrote this status. This corresponds with the controllerName field on GatewayClass. 
             *  Example: "example.net/gateway-controller". 
             *  The format of this field is DOMAIN "/" PATH, where DOMAIN and PATH are valid Kubernetes names (https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names). 
             *  Controllers MUST populate this field when writing status. Controllers should ensure that entries to status populated with their ControllerName are cleaned up when they are no longer necessary.
             */
            controllerName: string;
            /**
             * ParentRef corresponds with a ParentRef in the spec that this RouteParentStatus struct describes the status of.
             */
            parentRef: outputs.policy.v1beta1.HTTPRouteStatusParentsParentref;
        }
        /**
         * httprouteStatusParentsProvideDefaults sets the appropriate defaults for HTTPRouteStatusParents
         */
        export function httprouteStatusParentsProvideDefaults(val: HTTPRouteStatusParents): HTTPRouteStatusParents {
            return {
                ...val,
                parentRef: outputs.policy.v1beta1.httprouteStatusParentsParentrefProvideDefaults(val.parentRef),
            };
        }

        /**
         * Condition contains details for one aspect of the current state of this API Resource. --- This struct is intended for direct use as an array at the field path .status.conditions.  For example, type FooStatus struct{     // Represents the observations of a foo's current state.     // Known .status.conditions.type are: "Available", "Progressing", and "Degraded"     // +patchMergeKey=type     // +patchStrategy=merge     // +listType=map     // +listMapKey=type     Conditions []metav1.Condition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,1,rep,name=conditions"` 
         *      // other fields }
         */
        export interface HTTPRouteStatusParentsConditions {
            /**
             * lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
             */
            lastTransitionTime: string;
            /**
             * message is a human readable message indicating details about the transition. This may be an empty string.
             */
            message: string;
            /**
             * observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance.
             */
            observedGeneration?: number;
            /**
             * reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty.
             */
            reason: string;
            /**
             * status of the condition, one of True, False, Unknown.
             */
            status: string;
            /**
             * type of condition in CamelCase or in foo.example.com/CamelCase. --- Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt)
             */
            type: string;
        }

        /**
         * ParentRef corresponds with a ParentRef in the spec that this RouteParentStatus struct describes the status of.
         */
        export interface HTTPRouteStatusParentsParentref {
            /**
             * Group is the group of the referent. 
             *  Support: Core
             */
            group?: string;
            /**
             * Kind is kind of the referent. 
             *  Support: Core (Gateway) Support: Custom (Other Resources)
             */
            kind?: string;
            /**
             * Name is the name of the referent. 
             *  Support: Core
             */
            name: string;
            /**
             * Namespace is the namespace of the referent. When unspecified (or empty string), this refers to the local namespace of the Route. 
             *  Support: Core
             */
            namespace?: string;
            /**
             * SectionName is the name of a section within the target resource. In the following resources, SectionName is interpreted as the following: 
             *  * Gateway: Listener Name. When both Port (experimental) and SectionName are specified, the name and port of the selected listener must match both specified values. 
             *  Implementations MAY choose to support attaching Routes to other resources. If that is the case, they MUST clearly document how SectionName is interpreted. 
             *  When unspecified (empty string), this will reference the entire resource. For the purpose of status, an attachment is considered successful if at least one section in the parent resource accepts it. For example, Gateway listeners can restrict which Routes can attach to them by Route kind, namespace, or hostname. If 1 of 2 Gateway listeners accept attachment from the referencing Route, the Route MUST be considered successfully attached. If no Gateway listeners accept attachment from this Route, the Route MUST be considered detached from the Gateway. 
             *  Support: Core
             */
            sectionName?: string;
        }
        /**
         * httprouteStatusParentsParentrefProvideDefaults sets the appropriate defaults for HTTPRouteStatusParentsParentref
         */
        export function httprouteStatusParentsParentrefProvideDefaults(val: HTTPRouteStatusParentsParentref): HTTPRouteStatusParentsParentref {
            return {
                ...val,
                group: (val.group) ?? "policy.linkerd.io",
                kind: (val.kind) ?? "Gateway",
            };
        }

        /**
         * Authorizes clients to communicate with Linkerd-proxied servers.
         */
        export interface ServerAuthorizationSpec {
            /**
             * Describes clients authorized to access a server.
             */
            client: outputs.policy.v1beta1.ServerAuthorizationSpecClient;
            /**
             * Identifies servers in the same namespace for which this authorization applies.
             * Only one of `name` or `selector` may be specified.
             */
            server: any;
        }

        /**
         * Describes clients authorized to access a server.
         */
        export interface ServerAuthorizationSpecClient {
            meshTLS?: outputs.policy.v1beta1.ServerAuthorizationSpecClientMeshtls;
            /**
             * Limits the client IP addresses to which this authorization applies. If unset, the server chooses a default (typically, all IPs or the cluster's pod network).
             */
            networks?: outputs.policy.v1beta1.ServerAuthorizationSpecClientNetworks[];
            /**
             * Authorizes unauthenticated clients to access a server.
             */
            unauthenticated?: boolean;
        }

        export interface ServerAuthorizationSpecClientMeshtls {
            /**
             * Authorizes clients with the provided proxy identity strings (as provided via MTLS)
             * The `*` prefix can be used to match all identities in a domain. An identity string of `*` indicates that all authentication clients are authorized.
             */
            identities?: string[];
            /**
             * Authorizes clients with the provided proxy identity service accounts (as provided via MTLS)
             */
            serviceAccounts?: outputs.policy.v1beta1.ServerAuthorizationSpecClientMeshtlsServiceaccounts[];
            /**
             * Indicates that no client identity is required for communication.
             * This is mostly important for the identity controller, which must terminate TLS connections from clients that do not yet have a certificate.
             */
            unauthenticatedTLS?: boolean;
        }

        export interface ServerAuthorizationSpecClientMeshtlsServiceaccounts {
            /**
             * The ServiceAccount's name.
             */
            name: string;
            /**
             * The ServiceAccount's namespace. If unset, the authorization's namespace is used.
             */
            namespace?: string;
        }

        export interface ServerAuthorizationSpecClientNetworks {
            cidr: string;
            except?: string[];
        }

        export interface ServerSpec {
            /**
             * Selects pods in the same namespace.
             * The result of matchLabels and matchExpressions are ANDed. Selects all if empty.
             */
            podSelector: outputs.policy.v1beta1.ServerSpecPodselector;
            /**
             * A port name or number. Must exist in a pod spec.
             */
            port: number | string;
            /**
             * Configures protocol discovery for inbound connections.
             * Supersedes the `config.linkerd.io/opaque-ports` annotation.
             */
            proxyProtocol?: string;
        }
        /**
         * serverSpecProvideDefaults sets the appropriate defaults for ServerSpec
         */
        export function serverSpecProvideDefaults(val: ServerSpec): ServerSpec {
            return {
                ...val,
                proxyProtocol: (val.proxyProtocol) ?? "unknown",
            };
        }

        /**
         * Selects pods in the same namespace.
         * The result of matchLabels and matchExpressions are ANDed. Selects all if empty.
         */
        export interface ServerSpecPodselector {
            matchExpressions?: outputs.policy.v1beta1.ServerSpecPodselectorMatchexpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface ServerSpecPodselectorMatchexpressions {
            key: string;
            operator: string;
            values?: string[];
        }
    }
}

export namespace trust {
    export namespace v1alpha1 {
        /**
         * Desired state of the Bundle resource.
         */
        export interface BundleSpec {
            /**
             * Sources is a set of references to data whose data will sync to the target.
             */
            sources: outputs.trust.v1alpha1.BundleSpecSources[];
            /**
             * Target is the target location in all namespaces to sync source data to.
             */
            target: outputs.trust.v1alpha1.BundleSpecTarget;
        }

        /**
         * BundleSource is the set of sources whose data will be appended and synced to the BundleTarget in all Namespaces.
         */
        export interface BundleSpecSources {
            /**
             * ConfigMap is a reference to a ConfigMap's `data` key, in the trust Namespace.
             */
            configMap?: outputs.trust.v1alpha1.BundleSpecSourcesConfigmap;
            /**
             * InLine is a simple string to append as the source data.
             */
            inLine?: string;
            /**
             * Secret is a reference to a Secrets's `data` key, in the trust Namespace.
             */
            secret?: outputs.trust.v1alpha1.BundleSpecSourcesSecret;
        }

        /**
         * ConfigMap is a reference to a ConfigMap's `data` key, in the trust Namespace.
         */
        export interface BundleSpecSourcesConfigmap {
            /**
             * Key is the key of the entry in the object's `data` field to be used.
             */
            key: string;
            /**
             * Name is the name of the source object in the trust Namespace.
             */
            name: string;
        }

        /**
         * Secret is a reference to a Secrets's `data` key, in the trust Namespace.
         */
        export interface BundleSpecSourcesSecret {
            /**
             * Key is the key of the entry in the object's `data` field to be used.
             */
            key: string;
            /**
             * Name is the name of the source object in the trust Namespace.
             */
            name: string;
        }

        /**
         * Target is the target location in all namespaces to sync source data to.
         */
        export interface BundleSpecTarget {
            /**
             * ConfigMap is the target ConfigMap in Namespaces that all Bundle source data will be synced to.
             */
            configMap?: outputs.trust.v1alpha1.BundleSpecTargetConfigmap;
            /**
             * NamespaceSelector will, if set, only sync the target resource in Namespaces which match the selector.
             */
            namespaceSelector?: outputs.trust.v1alpha1.BundleSpecTargetNamespaceselector;
        }

        /**
         * ConfigMap is the target ConfigMap in Namespaces that all Bundle source data will be synced to.
         */
        export interface BundleSpecTargetConfigmap {
            /**
             * Key is the key of the entry in the object's `data` field to be used.
             */
            key: string;
        }

        /**
         * NamespaceSelector will, if set, only sync the target resource in Namespaces which match the selector.
         */
        export interface BundleSpecTargetNamespaceselector {
            /**
             * MatchLabels matches on the set of labels that must be present on a Namespace for the Bundle target to be synced there.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * Status of the Bundle. This is set and managed automatically.
         */
        export interface BundleStatus {
            /**
             * List of status conditions to indicate the status of the Bundle. Known condition types are `Bundle`.
             */
            conditions?: outputs.trust.v1alpha1.BundleStatusConditions[];
            /**
             * Target is the current Target that the Bundle is attempting or has completed syncing the source data to.
             */
            target?: outputs.trust.v1alpha1.BundleStatusTarget;
        }

        /**
         * BundleCondition contains condition information for a Bundle.
         */
        export interface BundleStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * If set, this represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.condition[x].observedGeneration is 9, the condition is out of date with respect to the current state of the Bundle.
             */
            observedGeneration?: number;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are (`Synced`).
             */
            type: string;
        }

        /**
         * Target is the current Target that the Bundle is attempting or has completed syncing the source data to.
         */
        export interface BundleStatusTarget {
            /**
             * ConfigMap is the target ConfigMap in Namespaces that all Bundle source data will be synced to.
             */
            configMap?: outputs.trust.v1alpha1.BundleStatusTargetConfigmap;
            /**
             * NamespaceSelector will, if set, only sync the target resource in Namespaces which match the selector.
             */
            namespaceSelector?: outputs.trust.v1alpha1.BundleStatusTargetNamespaceselector;
        }

        /**
         * ConfigMap is the target ConfigMap in Namespaces that all Bundle source data will be synced to.
         */
        export interface BundleStatusTargetConfigmap {
            /**
             * Key is the key of the entry in the object's `data` field to be used.
             */
            key: string;
        }

        /**
         * NamespaceSelector will, if set, only sync the target resource in Namespaces which match the selector.
         */
        export interface BundleStatusTargetNamespaceselector {
            /**
             * MatchLabels matches on the set of labels that must be present on a Namespace for the Bundle target to be synced there.
             */
            matchLabels?: {[key: string]: string};
        }

    }
}
